{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/NN-project-memorizing-transformers/blob/main/NN_project_Antonelli_DeSantis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports"
      ],
      "metadata": {
        "id": "-4GElPh7HbB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW8KnU4lPkgI",
        "outputId": "ba0e455a-9ca2-47e9-9b69-d73e1f6978fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_transformers import BertTokenizer\n",
        "from pytorch_transformers import BertModel"
      ],
      "metadata": {
        "id": "G5xdOnnKPbxi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata --quiet\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install torchtext --quiet\n",
        "!pip install -U spacy --quiet\n",
        "!python -m spacy download en_core_web_sm --quiet"
      ],
      "metadata": {
        "id": "oZJbIamFP23c",
        "outputId": "e0cae71c-772d-4666-b9be-a0315fa7f8b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from pathlib import Path\n",
        "from filelock import FileLock\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pickle as pkl\n",
        "import torchtext\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import spacy\n",
        "from typing import Iterable, List\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchmetrics.text.perplexity import Perplexity\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "Kd714QnlGIP-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a4BTaVB5Pxs",
        "outputId": "33e63d87-1681-4a6e-a249-07d8dbf53b98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "zAXedSwA5nyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 16\n",
        "SEQ_LEN = 512\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS\n",
        "\n",
        "LEARNING_RATE = 1e-3 #2e-4 prima era così\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 20\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 512\n",
        "CHECKPOINT = 10\n",
        "\n"
      ],
      "metadata": {
        "id": "nIq8h5NB87h4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, test_iter = WikiText2(split = ('train', 'test'))"
      ],
      "metadata": {
        "id": "jag9JLsDbyOB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from itertools import chain\n",
        "data_iter = chain(train_iter, test_iter)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J4Lo0Rsz7fT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "token_transform = get_tokenizer('spacy', language = 'en_core_web_sm')\n",
        "\n",
        "def yield_tokens(data) -> List[str]:\n",
        "    for line in data:\n",
        "        yield token_transform(line)\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "vocabulary_ = build_vocab_from_iterator(yield_tokens(data_iter), min_freq = 1, specials = special_symbols, special_first = True)\n",
        "vocabulary_.set_default_index(UNK_IDX)\n",
        "vocabulary_.__len__()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uvcwcyno7i6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def preprocessing_(dataset):\n",
        "  new_ds = torch.tensor([], dtype = torch.int32)\n",
        "  for line in dataset:\n",
        "    tokenized_line = torch.tensor([vocabulary_[token] for token in token_transform(line)])\n",
        "    new_ds = torch.cat((new_ds, tokenized_line))\n",
        "  return new_ds\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0JbiwRcz8G7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_ds = preprocessing_(train_iter)\n",
        "test_ds = preprocessing_(test_iter)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "R29fLy2G8fIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zlNANpHQiOt",
        "outputId": "b3f5038c-b5c3-4ac8-d63c-072912092ced"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 261967.05B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(dataset):\n",
        "  new_ds = []\n",
        "  for line in dataset:\n",
        "    tokenized_line = tokenizer.tokenize(line)\n",
        "    new_ds.append(tokenized_line)\n",
        "  return new_ds"
      ],
      "metadata": {
        "id": "RnfQlE72RQCR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = preprocessing(train_iter)\n",
        "test_ds = preprocessing(test_iter)"
      ],
      "metadata": {
        "id": "t4ZDCYlDRei8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tokens_to_idxs(dataset):\n",
        "  new_ds = torch.tensor([], dtype = torch.int32)\n",
        "  for line in dataset:\n",
        "    tokenized_line = torch.tensor(tokenizer.convert_tokens_to_ids(line))    \n",
        "    new_ds = torch.cat((new_ds, tokenized_line))\n",
        "  return new_ds"
      ],
      "metadata": {
        "id": "_wQHPc5URusJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = convert_tokens_to_idxs(train_ds)\n",
        "test_ds = convert_tokens_to_idxs(test_ds)"
      ],
      "metadata": {
        "id": "VjlekiRPSahL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCEOkwkgTQiS",
        "outputId": "90f23659-6d98-4a0d-f0f8-a9c859b63743"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2405592])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = 30522"
      ],
      "metadata": {
        "id": "juDl2xbjdzEF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "print(len(train_loader))\n",
        "train_ds = torch.zeros((len(train_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(train_loader):\n",
        "  train_ds[i] = document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zCX45xyL955",
        "outputId": "aadb0b9a-2a59-43a2-e6fa-8849c1139931"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "\n",
        "test_ds = torch.zeros((len(test_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(test_loader):\n",
        "  test_ds[i] = document"
      ],
      "metadata": {
        "id": "KlSGhT9-dCDt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGcfKRdsP98_",
        "outputId": "54ef355d-f0d7-4c26-b357-a176322072ab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([240, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.shape"
      ],
      "metadata": {
        "id": "B0wCMRhZdatc",
        "outputId": "844fd482-b89c-460b-8092-6ca48f236687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Memory"
      ],
      "metadata": {
        "id": "4I2ce2jPLzle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QppURbZ0KL0f",
        "outputId": "8eefd167-8219-4ba2-eeca-04be258b9d8b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krC3-klsLPVa",
        "outputId": "1f2464f6-bf00-44e8-e06f-847f954bb422"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import per la knn memory\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import wraps\n",
        "\n",
        "from contextlib import ExitStack, contextmanager\n",
        "\n",
        "from einops import rearrange, pack, unpack\n",
        "\n",
        "# multiprocessing\n",
        "\n",
        "from joblib import Parallel, delayed, cpu_count"
      ],
      "metadata": {
        "id": "KeHkdSn0KBSP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FAISS_INDEX_GPU_ID = int(os.getenv('FAISS_INDEX_GPU_ID', 0))\n",
        "\n",
        "DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY = './.tmp/knn.memories'\n",
        "\n",
        "# helper functions\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "def cast_list(val):\n",
        "    return val if isinstance(val, list) else [val]\n",
        "\n",
        "def all_el_unique(arr):\n",
        "    return len(set(arr)) == len(arr)\n",
        "\n",
        "@contextmanager\n",
        "def multi_context(*cms):\n",
        "    with ExitStack() as stack:\n",
        "        yield [stack.enter_context(cls) for cls in cms]\n",
        "\n",
        "def count_intersect(x, y):\n",
        "    # returns an array that shows how many times an element in x is contained in tensor y\n",
        "    return np.sum(rearrange(x, 'i -> i 1') == rearrange(y, 'j -> 1 j'), axis = -1)\n",
        "\n",
        "def check_shape(tensor, pattern, **kwargs):\n",
        "    return rearrange(tensor, f\"{pattern} -> {pattern}\", **kwargs)\n",
        "\n",
        "# a wrapper around faiss IndexIVFFlat\n",
        "# taking care of expiring old keys automagically\n",
        "\n",
        "class KNN():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_num_entries,\n",
        "        cap_num_entries = False,\n",
        "        M = 15,\n",
        "        keep_stats = False\n",
        "    ):\n",
        "        index = faiss.IndexHNSWFlat(dim, M, faiss.METRIC_INNER_PRODUCT)\n",
        "        self.index = index\n",
        "        self.max_num_entries = max_num_entries\n",
        "        self.cap_num_entries = cap_num_entries\n",
        "        self.is_trained = False\n",
        "        self.keep_stats = keep_stats\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'index'):\n",
        "            del self.index\n",
        "\n",
        "    def reset(self):\n",
        "        self.ids = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.empty((0,), dtype = np.int32)\n",
        "            self.age_num_iterations = np.empty((0,), dtype = np.int32)\n",
        "            self.ages_since_last_hit = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        self.index.reset()\n",
        "        self.is_trained = False\n",
        "\n",
        "    def train(self, x):\n",
        "        self.index.train(x)\n",
        "        self.is_trained = True\n",
        "\n",
        "    def add(self, x, ids):\n",
        "        if not self.is_trained:\n",
        "            self.train(x)\n",
        "\n",
        "        self.ids = np.concatenate((ids, self.ids))\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.concatenate((np.zeros_like(ids), self.hits))\n",
        "            self.age_num_iterations = np.concatenate((np.zeros_like(ids), self.age_num_iterations))\n",
        "            self.ages_since_last_hit = np.concatenate((np.zeros_like(ids), self.ages_since_last_hit))\n",
        "\n",
        "        if self.cap_num_entries and len(self.ids) > self.max_num_entries:\n",
        "            self.reset()\n",
        "\n",
        "        return self.index.add(x)\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        x,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        return_distances = False,\n",
        "        increment_hits = False,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        if not self.is_trained:\n",
        "            return np.full((x.shape[0], topk), -1)\n",
        "\n",
        "        distances, indices = self.index.search(x, k = topk)\n",
        "\n",
        "        if increment_hits and self.keep_stats:\n",
        "            hits = count_intersect(self.ids, rearrange(indices, '... -> (...)'))\n",
        "            self.hits += hits\n",
        "\n",
        "            self.ages_since_last_hit += 1\n",
        "            self.ages_since_last_hit *= (hits == 0)\n",
        "\n",
        "        if increment_age and self.keep_stats:\n",
        "            self.age_num_iterations += 1\n",
        "\n",
        "        if return_distances:\n",
        "            return indices, distances\n",
        "\n",
        "        return indices\n",
        "\n",
        "# KNN memory layer, where one can store key / value memories\n",
        "# can automatically take care of a collection of faiss indices (across batch dimension)\n",
        "\n",
        "class KNNMemory():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_memories = 16000,\n",
        "        num_indices = 1,\n",
        "        memmap_filename = './knn.memory.memmap',\n",
        "        multiprocessing = True\n",
        "    ):\n",
        "        self.dim = dim\n",
        "        self.num_indices = num_indices\n",
        "        self.scoped_indices = list(range(num_indices))\n",
        "\n",
        "        self.max_memories = max_memories\n",
        "        self.shape = (num_indices, max_memories, 2, dim)\n",
        "        self.db_offsets = np.zeros(num_indices, dtype = np.int32)\n",
        "\n",
        "        self.db = np.memmap(memmap_filename, mode = 'w+', dtype = np.float32, shape = self.shape)\n",
        "        self.knns = [KNN(dim = dim, max_num_entries = max_memories, cap_num_entries = True) for _ in range(num_indices)]\n",
        "    \n",
        "        self.n_jobs = cpu_count() if multiprocessing else 1\n",
        "\n",
        "    def set_scoped_indices(self, indices):\n",
        "        indices = list(indices)\n",
        "        assert all_el_unique(indices), f'all scoped batch indices must be unique, received: {indices}'\n",
        "        assert all([0 <= i < self.num_indices for i in indices]), f'each batch index must be between 0 and less than {self.num_indices}: received {indices}'\n",
        "        self.scoped_indices = indices\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(self, indices):\n",
        "        prev_indices = self.scoped_indices\n",
        "        self.set_scoped_indices(indices)\n",
        "        yield self\n",
        "        self.set_scoped_indices(prev_indices)\n",
        "\n",
        "    def clear(self, batch_indices = None):\n",
        "        if not exists(batch_indices):\n",
        "            batch_indices = list(range(self.num_indices))\n",
        "\n",
        "        batch_indices = cast_list(batch_indices)\n",
        "\n",
        "        for index in batch_indices:\n",
        "            knn = self.knns[index]\n",
        "            knn.reset()\n",
        "\n",
        "        self.db_offsets[batch_indices] = 0\n",
        "\n",
        "    def add(self, memories):\n",
        "        check_shape(memories, 'b n kv d', d = self.dim, kv = 2, b = len(self.scoped_indices))\n",
        "\n",
        "        memories = memories.detach().cpu().numpy()\n",
        "        memories = memories[:, -self.max_memories:]\n",
        "        num_memories = memories.shape[1]\n",
        "\n",
        "        knn_insert_ids = np.arange(num_memories)\n",
        "\n",
        "        keys = np.ascontiguousarray(memories[..., 0, :])\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "        db_offsets = [self.db_offsets[i] for i in self.scoped_indices]\n",
        "\n",
        "        # use joblib to insert new key / value memories into faiss index\n",
        "\n",
        "        @delayed\n",
        "        def knn_add(knn, key, db_offset):\n",
        "            knn.add(key, ids = knn_insert_ids + db_offset)\n",
        "            return knn\n",
        "\n",
        "        updated_knns = Parallel(n_jobs = self.n_jobs)(knn_add(*args) for args in zip(knns, keys, db_offsets))\n",
        "        for knn_idx, scoped_idx in enumerate(self.scoped_indices):\n",
        "            self.knns[scoped_idx] = updated_knns[knn_idx]\n",
        "\n",
        "        # add the new memories to the memmap \"database\"\n",
        "\n",
        "        add_indices = (rearrange(np.arange(num_memories), 'j -> 1 j') + rearrange(self.db_offsets[list(self.scoped_indices)], 'i -> i 1')) % self.max_memories\n",
        "        self.db[rearrange(np.array(self.scoped_indices), 'i -> i 1'), add_indices] = memories\n",
        "        self.db.flush()\n",
        "\n",
        "        self.db_offsets += num_memories\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        queries,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        increment_hits = True,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        check_shape(queries, 'b ... d', d = self.dim, b = len(self.scoped_indices))\n",
        "        queries, ps = pack([queries], 'b * d')\n",
        "\n",
        "        device = queries.device\n",
        "        queries = queries.detach().cpu().numpy()\n",
        "\n",
        "        all_masks = []\n",
        "        all_key_values = []\n",
        "\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "\n",
        "        # parallelize faiss search\n",
        "\n",
        "        @delayed\n",
        "        def knn_search(knn, query):\n",
        "            return knn.search(query, topk, nprobe, increment_hits = increment_hits, increment_age = increment_age)\n",
        "\n",
        "        fetched_indices = Parallel(n_jobs = self.n_jobs)(knn_search(*args) for args in zip(knns, queries))\n",
        "\n",
        "        # get all the memory key / values from memmap 'database'\n",
        "        # todo - remove for loop below\n",
        "\n",
        "        for batch_index, indices in zip(self.scoped_indices, fetched_indices):\n",
        "            mask = indices !=  -1\n",
        "            db_indices = np.where(mask, indices, 0)\n",
        "\n",
        "            all_masks.append(torch.from_numpy(mask))\n",
        "\n",
        "            key_values = self.db[batch_index, db_indices % self.max_memories]\n",
        "            all_key_values.append(torch.from_numpy(key_values))\n",
        "\n",
        "        all_masks = torch.stack(all_masks)\n",
        "        all_key_values = torch.stack(all_key_values)\n",
        "        all_key_values = all_key_values.masked_fill(~rearrange(all_masks, '... -> ... 1 1'), 0.)\n",
        "\n",
        "        all_key_values, = unpack(all_key_values, ps, 'b * n kv d')\n",
        "        all_masks, = unpack(all_masks, ps, 'b * n')\n",
        "\n",
        "        return all_key_values.to(device), all_masks.to(device)\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'knns'):\n",
        "            for knn in self.knns:\n",
        "                del knn\n",
        "        del self.db\n",
        "\n",
        "# extends list with some extra methods for collections of KNN memories\n",
        "\n",
        "class KNNMemoryList(list):\n",
        "    def cleanup(self):\n",
        "        for memory in self:\n",
        "            del memory\n",
        "\n",
        "    @classmethod\n",
        "    def create_memories(\n",
        "        self,\n",
        "        *,\n",
        "        batch_size,\n",
        "        num_memory_layers,\n",
        "        memories_directory = DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY\n",
        "    ):\n",
        "        memories_path = Path(memories_directory)\n",
        "        memories_path.mkdir(exist_ok = True, parents = True)\n",
        "\n",
        "        def inner(*args, **kwargs):\n",
        "            return self([KNNMemory(*args, num_indices = batch_size, memmap_filename = str(memories_path / f'knn.memory.layer.{ind + 1}.memmap'), **kwargs) for ind in range(num_memory_layers)])\n",
        "        return inner\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(\n",
        "        self,\n",
        "        indices\n",
        "    ):\n",
        "        knn_batch_indices_contexts = [memory.at_batch_indices(indices) for memory in self]\n",
        "        with multi_context(*knn_batch_indices_contexts):\n",
        "            yield\n",
        "\n",
        "    def clear_memory(\n",
        "        self,\n",
        "        batch_indices = None,\n",
        "        memory_indices = None\n",
        "    ):\n",
        "        memory_indices = default(memory_indices, tuple(range(len(self))))\n",
        "\n",
        "        for memory_index in memory_indices:\n",
        "            memory = self[memory_index]\n",
        "            memory.clear(batch_indices)"
      ],
      "metadata": {
        "id": "E5Wk2XJSLr-9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memorizing transformers"
      ],
      "metadata": {
        "id": "tWJS8R3fL7RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value, sqrt_q, device, mask = None):\n",
        "    t = torch.matmul(query, key.transpose(-2, -1))/sqrt_q\n",
        "    if mask is not None:\n",
        "      t = t.masked_fill_(mask == 0, -1e-9)\n",
        "    return torch.matmul(F.softmax(t, dim = -1), value)\n",
        "\n",
        "def KNNattention(query, key, value, sqrt_q, mask):\n",
        "    t = torch.einsum('b h i q, b h i j q -> b h i j', query, key)/sqrt_q\n",
        "    return torch.einsum('b h i j, b h i j q -> b h i q', F.softmax(t.masked_fill_(mask, -1e-9), dim = -1), value)"
      ],
      "metadata": {
        "id": "ZK8XwbNMp5vT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d, h, batch_size):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    assert d % h == 0\n",
        "    #assume q = v \n",
        "    self.q = d // h #single head dimension\n",
        "    self.sqrt_q = sqrt(self.q)\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.W_q = nn.Linear(d, d, bias = False) #stack of h matrices of dimension (d, q), one for each head\n",
        "    self.W_k = nn.Linear(d, d, bias = False)\n",
        "    self.W_v = nn.Linear(d, d, bias = False)\n",
        "    self.W_o = nn.Linear(d, d, bias = False)\n",
        "\n",
        "  def forward(self, x, mask = None):\n",
        "    query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    #new_memories = torch.stack((key, value), dim = -2).detach()\n",
        "    attention_value = attention(query, key, value, self.sqrt_q, mask)\n",
        "    return self.W_o(attention_value.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q))"
      ],
      "metadata": {
        "id": "AwoLII4LMvUK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNAttention(nn.Module):\n",
        "   def __init__(self, d, h, batch_size, num_retrieved_memories):\n",
        "      super(KNNAttention, self).__init__()\n",
        "      assert d % h == 0\n",
        "      #assume q = v \n",
        "      self.q = d // h\n",
        "      self.sqrt_q = sqrt(self.q)\n",
        "      self.h = h\n",
        "      self.W_q = nn.Linear(d, d, bias = False)\n",
        "      self.W_k = nn.Linear(d, d, bias = False)\n",
        "      self.W_v = nn.Linear(d, d, bias = False)\n",
        "      self.W_o = nn.Linear(d, d, bias = False)\n",
        "      self.b_g = nn.Parameter(torch.randn((h,))) #one for each head\n",
        "      self.num_retrieved_memories = num_retrieved_memories\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "   def forward(self, x, mask, knn_memory):\n",
        "      # calculate local attention \n",
        "      query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      local_attention = attention(query, key, value, self.sqrt_q, mask)\n",
        "\n",
        "      # calculate knn attention over memory\n",
        "      query = F.normalize(query, dim = -1)\n",
        "      key = F.normalize(key, dim = -1)\n",
        "      mem_kv, mem_mask = knn_memory.search(query, self.num_retrieved_memories)\n",
        "      mem_key, mem_value = mem_kv.unbind(dim = -2)\n",
        "      knn_attention = KNNattention(query, mem_key, mem_value, self.sqrt_q, ~mem_mask)\n",
        "\n",
        "      # memory to be stored\n",
        "      new_kv_memories = torch.stack((key, value), dim = -2).view(self.batch_size, -1, 2, self.q).detach()\n",
        "\n",
        "      # add to knn memory\n",
        "      if new_kv_memories.numel() > 0:\n",
        "        knn_memory.add(new_kv_memories)\n",
        "\n",
        "      # combining local and memory\n",
        "      g = torch.sigmoid(self.b_g)\n",
        "      final_attention = torch.einsum('b h n q, h -> b h n q', knn_attention, g) + \\\n",
        "                        torch.einsum('b h n q, h -> b h n q', local_attention, (1 - g))\n",
        "      \n",
        "      return self.W_o(final_attention.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q))"
      ],
      "metadata": {
        "id": "921DW0jjMyWx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    # Compute the positional encodings once in log space.\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
        "                          -(math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    return x + Variable(self.pe[:, :x.size(1)], requires_grad=False)"
      ],
      "metadata": {
        "id": "9U77GkT0cT4u"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, d, h, batch_size, hidden_size, dropout, is_mem = False, num_retrieved_memories = 32):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.d = d\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = MultiHeadAttention(d, h, batch_size) if not is_mem else KNNAttention(d, h, batch_size, num_retrieved_memories)\n",
        "    self.norm1 = nn.LayerNorm(d)\n",
        "    self.dropout1 = nn.Dropout(dropout)\n",
        "    self.norm2 = nn.LayerNorm(d)\n",
        "    self.dropout2 = nn.Dropout(dropout)\n",
        "    self.ff = nn.Sequential(nn.Linear(d, hidden_size, bias = True), \n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(dropout),\n",
        "                            nn.Linear(hidden_size, d, bias = True))\n",
        "  def forward(self, x, mask, knn_memory = None):\n",
        "    if knn_memory is None:\n",
        "      x = self.attention(x, mask)\n",
        "    else:\n",
        "      x = self.attention(x, mask, knn_memory)\n",
        "    x = self.dropout1(x + self.norm1(x))\n",
        "    x = x + self.ff(x)\n",
        "    x = self.dropout2(self.norm2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "prYm-KEpwLQq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module): #block of the classic transformer decoder (not used)\n",
        "  def __init__(self, d, h, batch_size, hidden_size, dropout):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    self.attention = MultiHeadAttention(d, h, batch_size)\n",
        "    self.norm = nn.LayerNorm(d)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.transformer_block = TransformerBlock(d, h, batch_size, hidden_size, dropout)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = self.attention(x, mask)\n",
        "    x = self.dropout(self.norm(x))\n",
        "    return self.transformer_block(x)"
      ],
      "metadata": {
        "id": "P4fkZ_djysyF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MemorizingTransformer(nn.Module):\n",
        "    def __init__(\n",
        "          self,\n",
        "          num_tokens,\n",
        "          d,\n",
        "          heads = 8,\n",
        "          depth = 4,\n",
        "          knn_attn_idx = 2,\n",
        "          attn_dropout = 0.,\n",
        "          hidden_size = 1000,\n",
        "          dropout = 0.3,\n",
        "          max_knn_memories = 1000,\n",
        "          num_retrieved_memories = 32,\n",
        "          batch_size = 16,\n",
        "          use_bert = True\n",
        "      ):\n",
        "          # asserts\n",
        "          self.d = d if not use_bert else 768\n",
        "          assert self.d % heads == 0\n",
        "          assert knn_attn_idx < depth\n",
        "\n",
        "          super(MemorizingTransformer, self).__init__()\n",
        "          #self.token_emb = nn.Embedding(num_tokens, self.d) #without BERT\n",
        "          self.token_emb = BertModel.from_pretrained('bert-base-uncased')\n",
        "          self.positional_enc = PositionalEncoding(self.d, max_len = 5000)\n",
        "          self.dim_head = self.d // heads\n",
        "          \n",
        "          self.heads = heads\n",
        "          self.knn_attn_idx = knn_attn_idx\n",
        "          self.depth = depth\n",
        "          self.attn_dropout = attn_dropout\n",
        "          self.hidden_size = hidden_size\n",
        "          self.dropout = dropout\n",
        "          self.max_knn_memories = max_knn_memories\n",
        "          self.num_retrieved_memories = num_retrieved_memories\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "          self.layers = nn.ModuleList([])\n",
        "          for idx in range(depth):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(self.d, heads, batch_size, hidden_size, dropout, is_mem = idx == self.knn_attn_idx)\n",
        "            )\n",
        "\n",
        "          self.to_out = nn.Linear(self.d, num_tokens)\n",
        "    \n",
        "    def create_mask(self, x):\n",
        "      batch_size, seq_len = x.shape\n",
        "      mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "          batch_size, 1, seq_len, seq_len)\n",
        "      return mask    \n",
        "          \n",
        "    def forward(self, x, knn_memory):\n",
        "      mask = self.create_mask(x)\n",
        "      #x = self.token_emb(x) #without BERT\n",
        "      x = self.token_emb(x)[0] #with BERT\n",
        "      x = self.positional_enc(x)\n",
        "\n",
        "      for idx in range(self.depth):\n",
        "          x= self.layers[idx](x, mask, knn_memory = knn_memory if idx == self.knn_attn_idx else None)\n",
        "\n",
        "      return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "F5uqCzrVL569"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ihBnTrPhaiDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "SEQ_LEN = 256\n",
        "SEGMENTS = 5\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS \n",
        "DIM_HEAD_BERT = 768 // HEADS #now it's 96 with bert -> 768/8\n",
        "\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 1\n",
        "CHECKPOINT = 1"
      ],
      "metadata": {
        "id": "ncWOJOkFanTK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MemorizingTransformer(\n",
        "    num_tokens = vocabulary,\n",
        "    d = SEQ_LEN,\n",
        "    heads = HEADS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    depth = 10,\n",
        "    knn_attn_idx = 8,\n",
        "    num_retrieved_memories = 32,\n",
        "    use_bert = True #False if you want to try without BERT\n",
        ").to(device)\n",
        "\n",
        "memory = KNNMemory(\n",
        "    dim = DIM_HEAD_BERT,       #substitute with DIM_HEAD if you want to try without BERT\n",
        "    max_memories = 1000,       #maximum number of memories (old ones will be discarded after reaching maximum capacity)\n",
        "    num_indices = BATCH_SIZE   #each batch keeps track of its own memories, expiring when it sees a new document\n",
        ")\n",
        "\n",
        "train_loader_ = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)\n",
        "test_loader_ = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)"
      ],
      "metadata": {
        "id": "1gVvmKCm3J4A",
        "outputId": "96c3e827-cfa6-4fff-e904-2d89c56ec92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 433/433 [00:00<00:00, 236598.96B/s]\n",
            "100%|██████████| 440473133/440473133 [00:36<00:00, 12016222.79B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_string(a):\n",
        "  seq = \"\"\n",
        "  for word in a:\n",
        "    for letter in word:\n",
        "      seq += chr(letter)\n",
        "    seq += \" \"\n",
        "  return seq"
      ],
      "metadata": {
        "id": "e6Apbm_X-ceS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epochs = 5\n",
        "# training\n",
        "\n",
        "perplexity_list = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, data in enumerate(tqdm.tqdm(train_loader_, desc = 'training')):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "\n",
        "    num_seq = 10000 // (SEQ_LEN + 1)\n",
        "    data = data.long().to(device)\n",
        "    for j in range(num_seq):\n",
        "      mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "      seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "      out = model(\n",
        "        seq,\n",
        "        knn_memory = memory\n",
        "      )\n",
        "      loss_item = loss(out, labels)\n",
        "      print(f'training loss: {loss_item}', flush = True)\n",
        "      loss_item.backward() \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "  data = None\n",
        "    \n",
        "\n",
        "  if e % EVAL_EVERY == 0:\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      metric = Perplexity().to(device)\n",
        "      for i, data in enumerate(tqdm.tqdm(test_loader_, desc = 'evaluation')):\n",
        "        num_seq = 10000 // (SEQ_LEN + 1)\n",
        "        data = data.long().to(device)\n",
        "\n",
        "        for j in range(num_seq):\n",
        "          mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "          seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "          out = model(\n",
        "            seq,\n",
        "            knn_memory = memory\n",
        "          )\n",
        "          test_loss = loss(out, labels)\n",
        "          metric(out.transpose(1, 2), labels)\n",
        "          print(f'test loss: {test_loss}', flush = True)\n",
        "\n",
        "      perplexity = metric.compute()\n",
        "      perplexity_list.append(perplexity)\n",
        "      print(f'perplexity: {perplexity}', flush = True)\n",
        "\n",
        "  data = None\n",
        "  if e % CHECKPOINT == 0:\n",
        "    torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, 'model_optimizer.pt')\n",
        "  \"\"\"\n",
        "  #Lorenzo\n",
        "  with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity_moreNN.npy', 'wb') as f:\n",
        "    np.save(f, np.array(perplexity_list))\n",
        "  \"\"\"\n",
        "\n",
        "plt.plot(perplexity_list, label = \"Memorizing Transformer Perplexity Plot\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9sF-vlC6koIo",
        "outputId": "441896f5-0245-403a-d264-eaf7c8de7b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/60 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 10.613636016845703\n",
            "training loss: 10.138771057128906\n",
            "training loss: 9.531482696533203\n",
            "training loss: 9.290334701538086\n",
            "training loss: 9.037982940673828\n",
            "training loss: 8.964811325073242\n",
            "training loss: 8.834417343139648\n",
            "training loss: 8.868087768554688\n",
            "training loss: 8.449191093444824\n",
            "training loss: 8.274097442626953\n",
            "training loss: 8.287134170532227\n",
            "training loss: 8.253252029418945\n",
            "training loss: 8.065546989440918\n",
            "training loss: 7.983259201049805\n",
            "training loss: 7.921478748321533\n",
            "training loss: 7.658079624176025\n",
            "training loss: 7.6776123046875\n",
            "training loss: 7.544704437255859\n",
            "training loss: 7.428136825561523\n",
            "training loss: 7.556718826293945\n",
            "training loss: 7.667337894439697\n",
            "training loss: 7.271917819976807\n",
            "training loss: 7.241058826446533\n",
            "training loss: 7.298427581787109\n",
            "training loss: 7.0697197914123535\n",
            "training loss: 7.1090803146362305\n",
            "training loss: 7.217362403869629\n",
            "training loss: 6.955743789672852\n",
            "training loss: 6.869659900665283\n",
            "training loss: 6.926031112670898\n",
            "training loss: 6.790748596191406\n",
            "training loss: 6.982842922210693\n",
            "training loss: 6.833795547485352\n",
            "training loss: 6.853605270385742\n",
            "training loss: 6.635425567626953\n",
            "training loss: 6.885104179382324\n",
            "training loss: 6.722187519073486\n",
            "training loss: 6.493778705596924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 1/60 [00:43<42:23, 43.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.084143161773682\n",
            "training loss: 7.394591331481934\n",
            "training loss: 7.657687187194824\n",
            "training loss: 7.305431842803955\n",
            "training loss: 7.273122787475586\n",
            "training loss: 7.156654357910156\n",
            "training loss: 7.343154430389404\n",
            "training loss: 6.991386413574219\n",
            "training loss: 7.358992099761963\n",
            "training loss: 7.178823471069336\n",
            "training loss: 7.169069766998291\n",
            "training loss: 6.862148761749268\n",
            "training loss: 7.171343803405762\n",
            "training loss: 7.3018083572387695\n",
            "training loss: 7.156015872955322\n",
            "training loss: 6.985560417175293\n",
            "training loss: 7.023008823394775\n",
            "training loss: 7.0046234130859375\n",
            "training loss: 6.907008647918701\n",
            "training loss: 7.088797569274902\n",
            "training loss: 7.021082878112793\n",
            "training loss: 7.007051467895508\n",
            "training loss: 6.970407009124756\n",
            "training loss: 7.39532995223999\n",
            "training loss: 7.165580749511719\n",
            "training loss: 7.112638473510742\n",
            "training loss: 7.049008369445801\n",
            "training loss: 7.1853437423706055\n",
            "training loss: 6.966651916503906\n",
            "training loss: 7.035217761993408\n",
            "training loss: 6.657567024230957\n",
            "training loss: 6.909394264221191\n",
            "training loss: 6.913949966430664\n",
            "training loss: 6.992056369781494\n",
            "training loss: 7.106975555419922\n",
            "training loss: 6.712094306945801\n",
            "training loss: 6.870136737823486\n",
            "training loss: 7.222833633422852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   3%|▎         | 2/60 [01:21<38:46, 40.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.078865051269531\n",
            "training loss: 7.060799598693848\n",
            "training loss: 7.193464279174805\n",
            "training loss: 7.1889238357543945\n",
            "training loss: 7.151512145996094\n",
            "training loss: 7.017027378082275\n",
            "training loss: 7.268648147583008\n",
            "training loss: 7.3830413818359375\n",
            "training loss: 7.186588764190674\n",
            "training loss: 6.901195526123047\n",
            "training loss: 6.994412422180176\n",
            "training loss: 7.237492561340332\n",
            "training loss: 7.301083564758301\n",
            "training loss: 7.216693878173828\n",
            "training loss: 6.944808006286621\n",
            "training loss: 6.840197563171387\n",
            "training loss: 7.095056533813477\n",
            "training loss: 7.078004837036133\n",
            "training loss: 7.063430309295654\n",
            "training loss: 6.90178108215332\n",
            "training loss: 7.1105828285217285\n",
            "training loss: 6.874146461486816\n",
            "training loss: 7.080276012420654\n",
            "training loss: 6.863290786743164\n",
            "training loss: 6.918060302734375\n",
            "training loss: 6.7738518714904785\n",
            "training loss: 7.038888931274414\n",
            "training loss: 6.742169380187988\n",
            "training loss: 6.645608425140381\n",
            "training loss: 6.800784111022949\n",
            "training loss: 6.951653480529785\n",
            "training loss: 7.008520126342773\n",
            "training loss: 7.134580612182617\n",
            "training loss: 6.83278226852417\n",
            "training loss: 6.964061737060547\n",
            "training loss: 6.809957027435303\n",
            "training loss: 6.967086315155029\n",
            "training loss: 6.872430801391602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   5%|▌         | 3/60 [01:59<37:10, 39.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.825892448425293\n",
            "training loss: 7.082074165344238\n",
            "training loss: 7.292474746704102\n",
            "training loss: 7.1592488288879395\n",
            "training loss: 7.309303283691406\n",
            "training loss: 7.078857421875\n",
            "training loss: 7.298160552978516\n",
            "training loss: 7.097609519958496\n",
            "training loss: 6.8863115310668945\n",
            "training loss: 6.977092742919922\n",
            "training loss: 6.86734676361084\n",
            "training loss: 6.951988220214844\n",
            "training loss: 7.229460716247559\n",
            "training loss: 6.816893577575684\n",
            "training loss: 6.758791923522949\n",
            "training loss: 6.830312252044678\n",
            "training loss: 6.823642730712891\n",
            "training loss: 7.093572616577148\n",
            "training loss: 6.873366355895996\n",
            "training loss: 6.90254020690918\n",
            "training loss: 6.862163543701172\n",
            "training loss: 6.987902641296387\n",
            "training loss: 7.076012134552002\n",
            "training loss: 6.570353031158447\n",
            "training loss: 7.0134501457214355\n",
            "training loss: 6.997167110443115\n",
            "training loss: 7.096169471740723\n",
            "training loss: 6.886145114898682\n",
            "training loss: 6.836856842041016\n",
            "training loss: 7.074459552764893\n",
            "training loss: 6.793364524841309\n",
            "training loss: 6.907717704772949\n",
            "training loss: 6.888669013977051\n",
            "training loss: 6.943101406097412\n",
            "training loss: 7.004215240478516\n",
            "training loss: 6.881417274475098\n",
            "training loss: 6.775006294250488\n",
            "training loss: 6.7852783203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   7%|▋         | 4/60 [02:37<36:06, 38.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.272273540496826\n",
            "training loss: 6.745721817016602\n",
            "training loss: 6.89892578125\n",
            "training loss: 7.012731552124023\n",
            "training loss: 6.670243263244629\n",
            "training loss: 6.968606948852539\n",
            "training loss: 7.081724643707275\n",
            "training loss: 6.848888397216797\n",
            "training loss: 6.632232189178467\n",
            "training loss: 7.32260799407959\n",
            "training loss: 7.2416157722473145\n",
            "training loss: 7.380533218383789\n",
            "training loss: 7.190946102142334\n",
            "training loss: 7.096787929534912\n",
            "training loss: 7.04904842376709\n",
            "training loss: 7.074018478393555\n",
            "training loss: 7.16287899017334\n",
            "training loss: 7.128839015960693\n",
            "training loss: 7.237271308898926\n",
            "training loss: 7.105903625488281\n",
            "training loss: 7.353597640991211\n",
            "training loss: 7.130156993865967\n",
            "training loss: 7.231752395629883\n",
            "training loss: 6.910612106323242\n",
            "training loss: 6.913682460784912\n",
            "training loss: 6.591948509216309\n",
            "training loss: 6.972830772399902\n",
            "training loss: 7.076026916503906\n",
            "training loss: 7.274300575256348\n",
            "training loss: 7.024515151977539\n",
            "training loss: 7.125507354736328\n",
            "training loss: 7.2549052238464355\n",
            "training loss: 6.9342756271362305\n",
            "training loss: 6.719179153442383\n",
            "training loss: 6.894460678100586\n",
            "training loss: 6.704289436340332\n",
            "training loss: 6.454273223876953\n",
            "training loss: 6.887801647186279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   8%|▊         | 5/60 [03:14<35:08, 38.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.933565139770508\n",
            "training loss: 6.95356559753418\n",
            "training loss: 7.490050315856934\n",
            "training loss: 7.350604057312012\n",
            "training loss: 7.142333030700684\n",
            "training loss: 6.6896209716796875\n",
            "training loss: 6.899460792541504\n",
            "training loss: 6.928689956665039\n",
            "training loss: 7.198765277862549\n",
            "training loss: 7.024230003356934\n",
            "training loss: 7.024910926818848\n",
            "training loss: 7.0703558921813965\n",
            "training loss: 6.751494884490967\n",
            "training loss: 6.930469036102295\n",
            "training loss: 6.959268569946289\n",
            "training loss: 6.890024185180664\n",
            "training loss: 6.736353874206543\n",
            "training loss: 6.629390716552734\n",
            "training loss: 6.485001564025879\n",
            "training loss: 6.58930778503418\n",
            "training loss: 6.82376766204834\n",
            "training loss: 6.905578136444092\n",
            "training loss: 6.852627754211426\n",
            "training loss: 6.908886909484863\n",
            "training loss: 6.94565486907959\n",
            "training loss: 6.753915786743164\n",
            "training loss: 6.804279327392578\n",
            "training loss: 6.7591118812561035\n",
            "training loss: 6.7900919914245605\n",
            "training loss: 6.955374240875244\n",
            "training loss: 7.13016414642334\n",
            "training loss: 7.027703285217285\n",
            "training loss: 6.706336498260498\n",
            "training loss: 6.769749164581299\n",
            "training loss: 6.848484516143799\n",
            "training loss: 6.73972225189209\n",
            "training loss: 6.822986125946045\n",
            "training loss: 6.663694381713867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  10%|█         | 6/60 [03:52<34:23, 38.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.276799201965332\n",
            "training loss: 7.325370788574219\n",
            "training loss: 7.2664875984191895\n",
            "training loss: 7.210224628448486\n",
            "training loss: 6.998112201690674\n",
            "training loss: 7.302657604217529\n",
            "training loss: 7.2073283195495605\n",
            "training loss: 7.117082118988037\n",
            "training loss: 7.020355224609375\n",
            "training loss: 6.927463531494141\n",
            "training loss: 7.00570011138916\n",
            "training loss: 6.733159065246582\n",
            "training loss: 6.8763251304626465\n",
            "training loss: 7.209510803222656\n",
            "training loss: 7.254376411437988\n",
            "training loss: 7.037599563598633\n",
            "training loss: 6.713640213012695\n",
            "training loss: 7.083306789398193\n",
            "training loss: 7.19444465637207\n",
            "training loss: 7.101696968078613\n",
            "training loss: 6.839553356170654\n",
            "training loss: 6.886813640594482\n",
            "training loss: 7.18438196182251\n",
            "training loss: 6.962347984313965\n",
            "training loss: 6.862087726593018\n",
            "training loss: 6.954755783081055\n",
            "training loss: 6.992542743682861\n",
            "training loss: 6.7206807136535645\n",
            "training loss: 7.1658172607421875\n",
            "training loss: 6.856204032897949\n",
            "training loss: 6.917021751403809\n",
            "training loss: 7.016058444976807\n",
            "training loss: 7.261839389801025\n",
            "training loss: 6.951358795166016\n",
            "training loss: 6.807687759399414\n",
            "training loss: 7.056518077850342\n",
            "training loss: 6.73771858215332\n",
            "training loss: 6.693604469299316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  12%|█▏        | 7/60 [04:31<33:58, 38.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.122234344482422\n",
            "training loss: 7.066431999206543\n",
            "training loss: 7.157933235168457\n",
            "training loss: 7.136859893798828\n",
            "training loss: 7.191762447357178\n",
            "training loss: 7.2710113525390625\n",
            "training loss: 7.101606845855713\n",
            "training loss: 6.848149299621582\n",
            "training loss: 6.92459774017334\n",
            "training loss: 6.726385116577148\n",
            "training loss: 6.677337646484375\n",
            "training loss: 6.701813697814941\n",
            "training loss: 6.9286370277404785\n",
            "training loss: 6.641932487487793\n",
            "training loss: 6.70519495010376\n",
            "training loss: 6.675601005554199\n",
            "training loss: 6.6327667236328125\n",
            "training loss: 6.768328666687012\n",
            "training loss: 6.411677360534668\n",
            "training loss: 6.753479480743408\n",
            "training loss: 6.725071907043457\n",
            "training loss: 6.826328754425049\n",
            "training loss: 6.859999179840088\n",
            "training loss: 6.804537296295166\n",
            "training loss: 6.64241886138916\n",
            "training loss: 7.016724586486816\n",
            "training loss: 6.624906539916992\n",
            "training loss: 7.011223793029785\n",
            "training loss: 6.836832046508789\n",
            "training loss: 6.929080963134766\n",
            "training loss: 6.635353088378906\n",
            "training loss: 6.999173164367676\n",
            "training loss: 7.078254699707031\n",
            "training loss: 6.795969009399414\n",
            "training loss: 6.811151027679443\n",
            "training loss: 6.750296592712402\n",
            "training loss: 6.591119766235352\n",
            "training loss: 6.810242176055908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  13%|█▎        | 8/60 [05:09<33:11, 38.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.230232238769531\n",
            "training loss: 7.401898384094238\n",
            "training loss: 7.140575408935547\n",
            "training loss: 7.138494491577148\n",
            "training loss: 6.938142776489258\n",
            "training loss: 6.995104789733887\n",
            "training loss: 6.7921576499938965\n",
            "training loss: 7.038303375244141\n",
            "training loss: 7.236082077026367\n",
            "training loss: 7.155353546142578\n",
            "training loss: 7.201041221618652\n",
            "training loss: 7.012529373168945\n",
            "training loss: 6.8622894287109375\n",
            "training loss: 7.025600910186768\n",
            "training loss: 7.028053283691406\n",
            "training loss: 7.2305731773376465\n",
            "training loss: 6.869088649749756\n",
            "training loss: 6.697502136230469\n",
            "training loss: 6.960309982299805\n",
            "training loss: 6.909814834594727\n",
            "training loss: 7.0569167137146\n",
            "training loss: 6.75325870513916\n",
            "training loss: 6.869870185852051\n",
            "training loss: 6.91953182220459\n",
            "training loss: 7.024238586425781\n",
            "training loss: 6.9305009841918945\n",
            "training loss: 6.83516788482666\n",
            "training loss: 7.134149551391602\n",
            "training loss: 7.104081630706787\n",
            "training loss: 6.922067642211914\n",
            "training loss: 6.953916549682617\n",
            "training loss: 6.959024906158447\n",
            "training loss: 6.953654766082764\n",
            "training loss: 6.868034362792969\n",
            "training loss: 6.832767486572266\n",
            "training loss: 7.0704264640808105\n",
            "training loss: 6.908880233764648\n",
            "training loss: 7.077544212341309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  15%|█▌        | 9/60 [05:47<32:25, 38.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.1218695640563965\n",
            "training loss: 7.287310600280762\n",
            "training loss: 6.878499507904053\n",
            "training loss: 6.700962543487549\n",
            "training loss: 6.767308235168457\n",
            "training loss: 7.087644577026367\n",
            "training loss: 6.962769508361816\n",
            "training loss: 6.950863838195801\n",
            "training loss: 6.883501052856445\n",
            "training loss: 6.631229400634766\n",
            "training loss: 6.893355369567871\n",
            "training loss: 6.880991458892822\n",
            "training loss: 6.520962238311768\n",
            "training loss: 6.412832260131836\n",
            "training loss: 6.1856465339660645\n",
            "training loss: 6.400476455688477\n",
            "training loss: 6.707627296447754\n",
            "training loss: 6.652065753936768\n",
            "training loss: 6.940911293029785\n",
            "training loss: 7.120311260223389\n",
            "training loss: 7.014995574951172\n",
            "training loss: 7.059335231781006\n",
            "training loss: 7.264331340789795\n",
            "training loss: 6.934560775756836\n",
            "training loss: 7.024728298187256\n",
            "training loss: 6.932506561279297\n",
            "training loss: 7.235857009887695\n",
            "training loss: 7.225761890411377\n",
            "training loss: 7.209053039550781\n",
            "training loss: 6.917325019836426\n",
            "training loss: 6.812918663024902\n",
            "training loss: 6.9841084480285645\n",
            "training loss: 6.75022029876709\n",
            "training loss: 6.931984901428223\n",
            "training loss: 6.844051837921143\n",
            "training loss: 6.866703033447266\n",
            "training loss: 6.984297275543213\n",
            "training loss: 6.817999839782715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  17%|█▋        | 10/60 [06:25<31:41, 38.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.091666221618652\n",
            "training loss: 7.047573566436768\n",
            "training loss: 7.173423767089844\n",
            "training loss: 7.077314376831055\n",
            "training loss: 7.258548736572266\n",
            "training loss: 6.962238311767578\n",
            "training loss: 6.981310844421387\n",
            "training loss: 7.213936805725098\n",
            "training loss: 6.825651168823242\n",
            "training loss: 7.214226722717285\n",
            "training loss: 6.944949150085449\n",
            "training loss: 7.251262664794922\n",
            "training loss: 7.005843162536621\n",
            "training loss: 6.876096725463867\n",
            "training loss: 7.114564895629883\n",
            "training loss: 6.91652774810791\n",
            "training loss: 6.842278480529785\n",
            "training loss: 6.742606163024902\n",
            "training loss: 6.757969856262207\n",
            "training loss: 6.735848426818848\n",
            "training loss: 6.88299560546875\n",
            "training loss: 6.998140811920166\n",
            "training loss: 7.003684997558594\n",
            "training loss: 7.028613090515137\n",
            "training loss: 7.051494598388672\n",
            "training loss: 7.02492618560791\n",
            "training loss: 6.903160572052002\n",
            "training loss: 6.947887897491455\n",
            "training loss: 6.965079307556152\n",
            "training loss: 6.9401397705078125\n",
            "training loss: 6.925153732299805\n",
            "training loss: 6.715936660766602\n",
            "training loss: 6.9215874671936035\n",
            "training loss: 6.94352388381958\n",
            "training loss: 6.702873229980469\n",
            "training loss: 6.629477500915527\n",
            "training loss: 6.927632808685303\n",
            "training loss: 6.773905277252197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  18%|█▊        | 11/60 [07:03<31:07, 38.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.955634593963623\n",
            "training loss: 7.1803388595581055\n",
            "training loss: 7.072729110717773\n",
            "training loss: 6.7278900146484375\n",
            "training loss: 7.017607688903809\n",
            "training loss: 7.029693126678467\n",
            "training loss: 6.882510185241699\n",
            "training loss: 6.911130428314209\n",
            "training loss: 6.834501266479492\n",
            "training loss: 6.91484260559082\n",
            "training loss: 7.068324089050293\n",
            "training loss: 6.8723859786987305\n",
            "training loss: 6.872129440307617\n",
            "training loss: 6.753278732299805\n",
            "training loss: 6.837377548217773\n",
            "training loss: 6.813639163970947\n",
            "training loss: 6.654955863952637\n",
            "training loss: 6.812917709350586\n",
            "training loss: 6.561501502990723\n",
            "training loss: 6.757495880126953\n",
            "training loss: 6.883272171020508\n",
            "training loss: 6.950472831726074\n",
            "training loss: 6.933416366577148\n",
            "training loss: 6.996332168579102\n",
            "training loss: 7.05186653137207\n",
            "training loss: 6.891727447509766\n",
            "training loss: 6.849225044250488\n",
            "training loss: 6.860954284667969\n",
            "training loss: 7.03660774230957\n",
            "training loss: 6.77847957611084\n",
            "training loss: 6.768409729003906\n",
            "training loss: 6.966142654418945\n",
            "training loss: 7.1207780838012695\n",
            "training loss: 6.799901962280273\n",
            "training loss: 7.1670308113098145\n",
            "training loss: 6.844918251037598\n",
            "training loss: 6.6616668701171875\n",
            "training loss: 6.580121040344238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  20%|██        | 12/60 [07:43<30:52, 38.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.381464004516602\n",
            "training loss: 6.8945512771606445\n",
            "training loss: 6.690036773681641\n",
            "training loss: 7.007118225097656\n",
            "training loss: 7.031467437744141\n",
            "training loss: 6.4006876945495605\n",
            "training loss: 6.732710838317871\n",
            "training loss: 6.964254379272461\n",
            "training loss: 7.1317620277404785\n",
            "training loss: 6.971085548400879\n",
            "training loss: 6.948525428771973\n",
            "training loss: 7.107857704162598\n",
            "training loss: 6.965453147888184\n",
            "training loss: 6.911659240722656\n",
            "training loss: 6.920713424682617\n",
            "training loss: 6.905270576477051\n",
            "training loss: 6.550041198730469\n",
            "training loss: 6.871432304382324\n",
            "training loss: 6.811529159545898\n",
            "training loss: 6.8191351890563965\n",
            "training loss: 7.012104034423828\n",
            "training loss: 7.035736560821533\n",
            "training loss: 6.879207611083984\n",
            "training loss: 6.783276557922363\n",
            "training loss: 7.057758331298828\n",
            "training loss: 6.896347999572754\n",
            "training loss: 6.741536617279053\n",
            "training loss: 6.757274627685547\n",
            "training loss: 6.641307830810547\n",
            "training loss: 6.933543682098389\n",
            "training loss: 6.758333206176758\n",
            "training loss: 6.855603218078613\n",
            "training loss: 6.873900890350342\n",
            "training loss: 6.679929256439209\n",
            "training loss: 6.876307010650635\n",
            "training loss: 6.698517322540283\n",
            "training loss: 6.748020648956299\n",
            "training loss: 6.635705947875977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  22%|██▏       | 13/60 [08:21<30:03, 38.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.13232946395874\n",
            "training loss: 7.105768203735352\n",
            "training loss: 7.083372592926025\n",
            "training loss: 6.994720458984375\n",
            "training loss: 6.975953578948975\n",
            "training loss: 7.074357032775879\n",
            "training loss: 6.947361946105957\n",
            "training loss: 6.68681526184082\n",
            "training loss: 6.623019218444824\n",
            "training loss: 6.9031572341918945\n",
            "training loss: 6.839829444885254\n",
            "training loss: 6.917774200439453\n",
            "training loss: 6.843218803405762\n",
            "training loss: 7.1470441818237305\n",
            "training loss: 6.910722255706787\n",
            "training loss: 6.870024681091309\n",
            "training loss: 6.83977746963501\n",
            "training loss: 7.072990417480469\n",
            "training loss: 7.13715934753418\n",
            "training loss: 6.692280292510986\n",
            "training loss: 6.843554496765137\n",
            "training loss: 6.922203063964844\n",
            "training loss: 6.964837551116943\n",
            "training loss: 6.9279608726501465\n",
            "training loss: 6.788494110107422\n",
            "training loss: 6.7820940017700195\n",
            "training loss: 6.992270469665527\n",
            "training loss: 6.723076820373535\n",
            "training loss: 6.865383625030518\n",
            "training loss: 6.736015319824219\n",
            "training loss: 7.052222728729248\n",
            "training loss: 7.057701587677002\n",
            "training loss: 6.596090793609619\n",
            "training loss: 6.750875473022461\n",
            "training loss: 6.840660095214844\n",
            "training loss: 6.770153999328613\n",
            "training loss: 7.080509185791016\n",
            "training loss: 7.255039691925049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  23%|██▎       | 14/60 [08:59<29:18, 38.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.244021892547607\n",
            "training loss: 7.189414024353027\n",
            "training loss: 7.168315410614014\n",
            "training loss: 7.274123191833496\n",
            "training loss: 7.257654666900635\n",
            "training loss: 7.05896520614624\n",
            "training loss: 7.251628875732422\n",
            "training loss: 7.004082679748535\n",
            "training loss: 7.015024185180664\n",
            "training loss: 7.156121730804443\n",
            "training loss: 7.050822734832764\n",
            "training loss: 6.989840030670166\n",
            "training loss: 6.946094512939453\n",
            "training loss: 6.726750373840332\n",
            "training loss: 6.73920202255249\n",
            "training loss: 6.752025604248047\n",
            "training loss: 6.8838911056518555\n",
            "training loss: 7.047333717346191\n",
            "training loss: 7.111050605773926\n",
            "training loss: 6.919071197509766\n",
            "training loss: 7.135094165802002\n",
            "training loss: 7.007986068725586\n",
            "training loss: 6.885394096374512\n",
            "training loss: 6.9074177742004395\n",
            "training loss: 6.933279991149902\n",
            "training loss: 6.938861846923828\n",
            "training loss: 6.890046119689941\n",
            "training loss: 7.019357204437256\n",
            "training loss: 6.989985466003418\n",
            "training loss: 6.676540374755859\n",
            "training loss: 6.88218879699707\n",
            "training loss: 6.852741718292236\n",
            "training loss: 6.849715232849121\n",
            "training loss: 6.935612678527832\n",
            "training loss: 6.964483737945557\n",
            "training loss: 6.8859052658081055\n",
            "training loss: 6.7805023193359375\n",
            "training loss: 6.714471340179443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  25%|██▌       | 15/60 [09:37<28:39, 38.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.993119716644287\n",
            "training loss: 6.784221649169922\n",
            "training loss: 7.126415729522705\n",
            "training loss: 7.195370674133301\n",
            "training loss: 7.15617561340332\n",
            "training loss: 7.264147758483887\n",
            "training loss: 7.056883335113525\n",
            "training loss: 7.247528553009033\n",
            "training loss: 7.2397332191467285\n",
            "training loss: 7.222484111785889\n",
            "training loss: 7.2690839767456055\n",
            "training loss: 7.034571647644043\n",
            "training loss: 7.0977630615234375\n",
            "training loss: 6.7696380615234375\n",
            "training loss: 7.01775598526001\n",
            "training loss: 6.995601654052734\n",
            "training loss: 6.75364875793457\n",
            "training loss: 6.914153099060059\n",
            "training loss: 7.088861465454102\n",
            "training loss: 6.797702789306641\n",
            "training loss: 6.912065505981445\n",
            "training loss: 6.912803649902344\n",
            "training loss: 7.174559116363525\n",
            "training loss: 7.117282390594482\n",
            "training loss: 7.095465660095215\n",
            "training loss: 6.541790008544922\n",
            "training loss: 6.842745780944824\n",
            "training loss: 7.1712493896484375\n",
            "training loss: 7.127444267272949\n",
            "training loss: 6.603798866271973\n",
            "training loss: 6.898218631744385\n",
            "training loss: 6.94410514831543\n",
            "training loss: 6.940148830413818\n",
            "training loss: 6.782498359680176\n",
            "training loss: 6.7265706062316895\n",
            "training loss: 6.59981107711792\n",
            "training loss: 6.684084892272949\n",
            "training loss: 7.019142150878906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  27%|██▋       | 16/60 [10:15<28:00, 38.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.995940208435059\n",
            "training loss: 7.082773208618164\n",
            "training loss: 7.305164337158203\n",
            "training loss: 7.161197662353516\n",
            "training loss: 7.269604682922363\n",
            "training loss: 7.057260990142822\n",
            "training loss: 7.041745185852051\n",
            "training loss: 6.9116129875183105\n",
            "training loss: 7.012732028961182\n",
            "training loss: 6.924648761749268\n",
            "training loss: 6.9260783195495605\n",
            "training loss: 7.066951274871826\n",
            "training loss: 6.945458889007568\n",
            "training loss: 7.137029647827148\n",
            "training loss: 6.992270469665527\n",
            "training loss: 7.037405014038086\n",
            "training loss: 7.032413005828857\n",
            "training loss: 7.048299312591553\n",
            "training loss: 7.010881423950195\n",
            "training loss: 6.879522323608398\n",
            "training loss: 6.845816612243652\n",
            "training loss: 7.069371223449707\n",
            "training loss: 7.0687761306762695\n",
            "training loss: 7.199522018432617\n",
            "training loss: 7.182771682739258\n",
            "training loss: 7.122307777404785\n",
            "training loss: 6.9342498779296875\n",
            "training loss: 6.838376522064209\n",
            "training loss: 6.903219223022461\n",
            "training loss: 6.763131141662598\n",
            "training loss: 6.545318603515625\n",
            "training loss: 6.8499908447265625\n",
            "training loss: 6.913968086242676\n",
            "training loss: 6.875759124755859\n",
            "training loss: 6.98960018157959\n",
            "training loss: 6.807761192321777\n",
            "training loss: 6.930976390838623\n",
            "training loss: 6.930872917175293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  28%|██▊       | 17/60 [10:58<28:21, 39.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.12001895904541\n",
            "training loss: 7.266022682189941\n",
            "training loss: 7.047516822814941\n",
            "training loss: 7.0406389236450195\n",
            "training loss: 6.897774696350098\n",
            "training loss: 6.815616607666016\n",
            "training loss: 7.008540153503418\n",
            "training loss: 6.860357284545898\n",
            "training loss: 6.795193672180176\n",
            "training loss: 6.812383651733398\n",
            "training loss: 6.7417778968811035\n",
            "training loss: 6.879680633544922\n",
            "training loss: 6.854953765869141\n",
            "training loss: 6.882869720458984\n",
            "training loss: 7.134745121002197\n",
            "training loss: 7.05328893661499\n",
            "training loss: 7.036424160003662\n",
            "training loss: 6.804134368896484\n",
            "training loss: 6.966885566711426\n",
            "training loss: 7.036844253540039\n",
            "training loss: 6.986448764801025\n",
            "training loss: 6.684329032897949\n",
            "training loss: 6.9523396492004395\n",
            "training loss: 7.10272216796875\n",
            "training loss: 6.87905216217041\n",
            "training loss: 6.9057159423828125\n",
            "training loss: 7.012053489685059\n",
            "training loss: 6.9983015060424805\n",
            "training loss: 6.762081623077393\n",
            "training loss: 6.548131942749023\n",
            "training loss: 6.919318675994873\n",
            "training loss: 6.934061050415039\n",
            "training loss: 6.980881214141846\n",
            "training loss: 6.737183570861816\n",
            "training loss: 6.74821662902832\n",
            "training loss: 6.756376266479492\n",
            "training loss: 6.902407169342041\n",
            "training loss: 6.70389461517334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  30%|███       | 18/60 [11:41<28:27, 40.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.261334419250488\n",
            "training loss: 7.118507385253906\n",
            "training loss: 7.239687919616699\n",
            "training loss: 6.87838888168335\n",
            "training loss: 7.214639186859131\n",
            "training loss: 7.240421295166016\n",
            "training loss: 7.151341438293457\n",
            "training loss: 7.2515363693237305\n",
            "training loss: 6.784528732299805\n",
            "training loss: 7.0007476806640625\n",
            "training loss: 7.153294563293457\n",
            "training loss: 6.932985782623291\n",
            "training loss: 7.027744293212891\n",
            "training loss: 6.96490478515625\n",
            "training loss: 7.021378517150879\n",
            "training loss: 6.996851444244385\n",
            "training loss: 7.000884056091309\n",
            "training loss: 6.751984596252441\n",
            "training loss: 7.058529853820801\n",
            "training loss: 7.111053943634033\n",
            "training loss: 7.272870063781738\n",
            "training loss: 7.077937126159668\n",
            "training loss: 7.01859188079834\n",
            "training loss: 6.947611331939697\n",
            "training loss: 6.953092098236084\n",
            "training loss: 6.842789173126221\n",
            "training loss: 6.86737585067749\n",
            "training loss: 6.959402084350586\n",
            "training loss: 6.901716232299805\n",
            "training loss: 6.663630485534668\n",
            "training loss: 6.874181747436523\n",
            "training loss: 6.913818359375\n",
            "training loss: 6.840296268463135\n",
            "training loss: 6.812086582183838\n",
            "training loss: 6.908450126647949\n",
            "training loss: 7.164374351501465\n",
            "training loss: 6.965519905090332\n",
            "training loss: 6.912980556488037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  32%|███▏      | 19/60 [12:19<27:14, 39.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.853694915771484\n",
            "training loss: 7.049633979797363\n",
            "training loss: 7.307528972625732\n",
            "training loss: 7.142012596130371\n",
            "training loss: 7.105103969573975\n",
            "training loss: 7.113703727722168\n",
            "training loss: 7.003873825073242\n",
            "training loss: 6.8922576904296875\n",
            "training loss: 6.9274468421936035\n",
            "training loss: 7.039277076721191\n",
            "training loss: 7.133861541748047\n",
            "training loss: 7.052985668182373\n",
            "training loss: 7.100751876831055\n",
            "training loss: 7.447279930114746\n",
            "training loss: 7.212275505065918\n",
            "training loss: 7.225264072418213\n",
            "training loss: 6.845485210418701\n",
            "training loss: 6.972207069396973\n",
            "training loss: 6.962765693664551\n",
            "training loss: 6.58221960067749\n",
            "training loss: 6.867555618286133\n",
            "training loss: 6.8560638427734375\n",
            "training loss: 7.110095977783203\n",
            "training loss: 6.9389801025390625\n",
            "training loss: 7.145419120788574\n",
            "training loss: 6.809142112731934\n",
            "training loss: 6.9658613204956055\n",
            "training loss: 6.652544021606445\n",
            "training loss: 6.691473007202148\n",
            "training loss: 6.996174335479736\n",
            "training loss: 6.897029399871826\n",
            "training loss: 7.068700790405273\n",
            "training loss: 6.791924476623535\n",
            "training loss: 6.916877746582031\n",
            "training loss: 6.696822166442871\n",
            "training loss: 6.9389753341674805\n",
            "training loss: 6.793879508972168\n",
            "training loss: 6.623954772949219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  33%|███▎      | 20/60 [12:57<26:19, 39.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.920068264007568\n",
            "training loss: 7.2850751876831055\n",
            "training loss: 7.002172470092773\n",
            "training loss: 7.062807083129883\n",
            "training loss: 6.8733649253845215\n",
            "training loss: 6.888821601867676\n",
            "training loss: 6.999100685119629\n",
            "training loss: 7.06151819229126\n",
            "training loss: 6.949859142303467\n",
            "training loss: 7.087446212768555\n",
            "training loss: 7.071084976196289\n",
            "training loss: 7.103525161743164\n",
            "training loss: 7.05394172668457\n",
            "training loss: 6.955443859100342\n",
            "training loss: 6.997477054595947\n",
            "training loss: 6.822092056274414\n",
            "training loss: 6.8947882652282715\n",
            "training loss: 7.095067977905273\n",
            "training loss: 7.008118152618408\n",
            "training loss: 6.844754219055176\n",
            "training loss: 6.74705171585083\n",
            "training loss: 6.781914234161377\n",
            "training loss: 7.0517988204956055\n",
            "training loss: 6.751018524169922\n",
            "training loss: 6.884237289428711\n",
            "training loss: 6.793133735656738\n",
            "training loss: 6.919988632202148\n",
            "training loss: 6.7969970703125\n",
            "training loss: 6.903903484344482\n",
            "training loss: 7.0257768630981445\n",
            "training loss: 6.73630428314209\n",
            "training loss: 6.849456787109375\n",
            "training loss: 6.955581188201904\n",
            "training loss: 6.83829402923584\n",
            "training loss: 6.780490875244141\n",
            "training loss: 6.992141246795654\n",
            "training loss: 6.892579078674316\n",
            "training loss: 6.851374626159668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  35%|███▌      | 21/60 [13:39<26:03, 40.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.129133224487305\n",
            "training loss: 7.05056095123291\n",
            "training loss: 6.834190368652344\n",
            "training loss: 6.841165542602539\n",
            "training loss: 6.942766189575195\n",
            "training loss: 6.994068622589111\n",
            "training loss: 6.782136917114258\n",
            "training loss: 6.922613620758057\n",
            "training loss: 6.55466365814209\n",
            "training loss: 6.720989227294922\n",
            "training loss: 6.8983869552612305\n",
            "training loss: 6.895124435424805\n",
            "training loss: 6.602025032043457\n",
            "training loss: 7.140628337860107\n",
            "training loss: 6.949765205383301\n",
            "training loss: 6.891237735748291\n",
            "training loss: 6.773731708526611\n",
            "training loss: 6.862243175506592\n",
            "training loss: 7.251828670501709\n",
            "training loss: 7.062057971954346\n",
            "training loss: 7.0432233810424805\n",
            "training loss: 7.202770233154297\n",
            "training loss: 7.15321159362793\n",
            "training loss: 7.026019096374512\n",
            "training loss: 6.908143997192383\n",
            "training loss: 6.924454689025879\n",
            "training loss: 6.50697135925293\n",
            "training loss: 6.93831205368042\n",
            "training loss: 6.678504467010498\n",
            "training loss: 6.70719051361084\n",
            "training loss: 6.659867286682129\n",
            "training loss: 6.909845352172852\n",
            "training loss: 6.897231101989746\n",
            "training loss: 6.957583427429199\n",
            "training loss: 6.963893890380859\n",
            "training loss: 7.234585762023926\n",
            "training loss: 6.775700092315674\n",
            "training loss: 6.755329132080078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  37%|███▋      | 22/60 [14:18<25:16, 39.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.210700035095215\n",
            "training loss: 7.280634880065918\n",
            "training loss: 7.1201863288879395\n",
            "training loss: 6.921036243438721\n",
            "training loss: 6.899633407592773\n",
            "training loss: 6.9862518310546875\n",
            "training loss: 6.829773902893066\n",
            "training loss: 6.903101921081543\n",
            "training loss: 6.9680914878845215\n",
            "training loss: 6.660061836242676\n",
            "training loss: 6.790430545806885\n",
            "training loss: 6.796070575714111\n",
            "training loss: 6.892922878265381\n",
            "training loss: 6.853414535522461\n",
            "training loss: 7.020436763763428\n",
            "training loss: 6.913593769073486\n",
            "training loss: 6.700383186340332\n",
            "training loss: 6.890918731689453\n",
            "training loss: 7.216863632202148\n",
            "training loss: 7.251250743865967\n",
            "training loss: 7.029544830322266\n",
            "training loss: 7.122547149658203\n",
            "training loss: 6.744854927062988\n",
            "training loss: 6.936036586761475\n",
            "training loss: 6.73862886428833\n",
            "training loss: 6.958298683166504\n",
            "training loss: 6.93310546875\n",
            "training loss: 7.10394287109375\n",
            "training loss: 6.998194694519043\n",
            "training loss: 6.963395595550537\n",
            "training loss: 6.674705505371094\n",
            "training loss: 6.811498165130615\n",
            "training loss: 6.9069366455078125\n",
            "training loss: 6.8187055587768555\n",
            "training loss: 6.693538188934326\n",
            "training loss: 6.8820343017578125\n",
            "training loss: 6.711319446563721\n",
            "training loss: 6.595837593078613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  38%|███▊      | 23/60 [15:00<24:51, 40.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.967005252838135\n",
            "training loss: 6.981806755065918\n",
            "training loss: 7.071987152099609\n",
            "training loss: 7.023414611816406\n",
            "training loss: 7.019271373748779\n",
            "training loss: 7.0901336669921875\n",
            "training loss: 7.2707061767578125\n",
            "training loss: 6.9417572021484375\n",
            "training loss: 7.117517471313477\n",
            "training loss: 7.102762699127197\n",
            "training loss: 7.119544982910156\n",
            "training loss: 6.947575092315674\n",
            "training loss: 7.181549072265625\n",
            "training loss: 6.944566249847412\n",
            "training loss: 7.056298732757568\n",
            "training loss: 7.154702186584473\n",
            "training loss: 7.208966255187988\n",
            "training loss: 7.180850028991699\n",
            "training loss: 7.126945495605469\n",
            "training loss: 6.683711051940918\n",
            "training loss: 7.014088153839111\n",
            "training loss: 6.9841413497924805\n",
            "training loss: 6.7829999923706055\n",
            "training loss: 6.788902282714844\n",
            "training loss: 7.024994373321533\n",
            "training loss: 6.516168594360352\n",
            "training loss: 7.038945198059082\n",
            "training loss: 7.10408353805542\n",
            "training loss: 6.851431846618652\n",
            "training loss: 6.937643051147461\n",
            "training loss: 6.847699165344238\n",
            "training loss: 6.727448463439941\n",
            "training loss: 6.7528157234191895\n",
            "training loss: 6.761521816253662\n",
            "training loss: 6.73660135269165\n",
            "training loss: 7.157357215881348\n",
            "training loss: 7.122265338897705\n",
            "training loss: 6.884180068969727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  40%|████      | 24/60 [15:42<24:34, 40.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.421243667602539\n",
            "training loss: 7.269808769226074\n",
            "training loss: 7.039865493774414\n",
            "training loss: 7.058836936950684\n",
            "training loss: 7.00519323348999\n",
            "training loss: 7.070455074310303\n",
            "training loss: 6.850800037384033\n",
            "training loss: 6.832045078277588\n",
            "training loss: 6.956993103027344\n",
            "training loss: 7.138591766357422\n",
            "training loss: 6.7815093994140625\n",
            "training loss: 6.771083831787109\n",
            "training loss: 6.83294677734375\n",
            "training loss: 6.774871826171875\n",
            "training loss: 6.943699359893799\n",
            "training loss: 6.9907989501953125\n",
            "training loss: 6.752702713012695\n",
            "training loss: 6.59585428237915\n",
            "training loss: 6.6158857345581055\n",
            "training loss: 6.767922401428223\n",
            "training loss: 6.972226142883301\n",
            "training loss: 6.731522560119629\n",
            "training loss: 6.804130554199219\n",
            "training loss: 6.740606784820557\n",
            "training loss: 6.673515319824219\n",
            "training loss: 6.698068141937256\n",
            "training loss: 6.814960479736328\n",
            "training loss: 6.9288554191589355\n",
            "training loss: 6.787388801574707\n",
            "training loss: 6.817103862762451\n",
            "training loss: 6.733172416687012\n",
            "training loss: 6.762621879577637\n",
            "training loss: 6.844867706298828\n",
            "training loss: 6.950913906097412\n",
            "training loss: 6.702458381652832\n",
            "training loss: 6.510937690734863\n",
            "training loss: 6.6945648193359375\n",
            "training loss: 6.820845603942871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  42%|████▏     | 25/60 [16:24<24:02, 41.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.401314735412598\n",
            "training loss: 7.368028163909912\n",
            "training loss: 7.219272613525391\n",
            "training loss: 7.171321868896484\n",
            "training loss: 7.064629554748535\n",
            "training loss: 7.234758377075195\n",
            "training loss: 7.095154285430908\n",
            "training loss: 7.045161724090576\n",
            "training loss: 7.030550956726074\n",
            "training loss: 6.931060314178467\n",
            "training loss: 7.068812370300293\n",
            "training loss: 6.851714134216309\n",
            "training loss: 7.0809831619262695\n",
            "training loss: 6.873610496520996\n",
            "training loss: 7.03376579284668\n",
            "training loss: 7.032923221588135\n",
            "training loss: 7.061609268188477\n",
            "training loss: 7.033758640289307\n",
            "training loss: 6.880650520324707\n",
            "training loss: 7.145517826080322\n",
            "training loss: 6.830728530883789\n",
            "training loss: 6.733518123626709\n",
            "training loss: 6.863198757171631\n",
            "training loss: 6.734868049621582\n",
            "training loss: 6.614126205444336\n",
            "training loss: 6.886929512023926\n",
            "training loss: 6.914676666259766\n",
            "training loss: 6.62677001953125\n",
            "training loss: 6.955503940582275\n",
            "training loss: 6.792917251586914\n",
            "training loss: 6.730862617492676\n",
            "training loss: 6.849893569946289\n",
            "training loss: 6.804025173187256\n",
            "training loss: 6.905571937561035\n",
            "training loss: 7.019976615905762\n",
            "training loss: 6.826420307159424\n",
            "training loss: 6.701595783233643\n",
            "training loss: 6.629143238067627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  43%|████▎     | 26/60 [17:04<23:13, 40.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.962173938751221\n",
            "training loss: 6.852904796600342\n",
            "training loss: 6.738122940063477\n",
            "training loss: 6.8200602531433105\n",
            "training loss: 6.705994129180908\n",
            "training loss: 6.872243404388428\n",
            "training loss: 6.901106834411621\n",
            "training loss: 7.0039191246032715\n",
            "training loss: 7.20576810836792\n",
            "training loss: 7.1443915367126465\n",
            "training loss: 6.869661808013916\n",
            "training loss: 7.017078399658203\n",
            "training loss: 6.6072540283203125\n",
            "training loss: 6.683966636657715\n",
            "training loss: 7.058378219604492\n",
            "training loss: 6.935709476470947\n",
            "training loss: 6.906546592712402\n",
            "training loss: 6.825387954711914\n",
            "training loss: 6.871500015258789\n",
            "training loss: 6.818963050842285\n",
            "training loss: 6.7365875244140625\n",
            "training loss: 6.795596599578857\n",
            "training loss: 6.664106845855713\n",
            "training loss: 7.020573139190674\n",
            "training loss: 6.676201820373535\n",
            "training loss: 6.721006393432617\n",
            "training loss: 6.7430596351623535\n",
            "training loss: 6.622585773468018\n",
            "training loss: 6.872058868408203\n",
            "training loss: 6.669313430786133\n",
            "training loss: 7.025912284851074\n",
            "training loss: 7.193481922149658\n",
            "training loss: 7.0010480880737305\n",
            "training loss: 6.651986122131348\n",
            "training loss: 6.8897905349731445\n",
            "training loss: 6.821523666381836\n",
            "training loss: 6.855202674865723\n",
            "training loss: 6.761392593383789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  45%|████▌     | 27/60 [17:44<22:23, 40.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.139708518981934\n",
            "training loss: 7.152618408203125\n",
            "training loss: 6.830611228942871\n",
            "training loss: 7.105809211730957\n",
            "training loss: 7.311925888061523\n",
            "training loss: 7.136909008026123\n",
            "training loss: 7.120815277099609\n",
            "training loss: 6.988974571228027\n",
            "training loss: 7.233615398406982\n",
            "training loss: 7.381376266479492\n",
            "training loss: 7.219614028930664\n",
            "training loss: 7.024274826049805\n",
            "training loss: 7.146202564239502\n",
            "training loss: 7.015267372131348\n",
            "training loss: 6.911043167114258\n",
            "training loss: 6.836211681365967\n",
            "training loss: 6.881999492645264\n",
            "training loss: 7.0062665939331055\n",
            "training loss: 7.0801849365234375\n",
            "training loss: 7.312714099884033\n",
            "training loss: 6.844305515289307\n",
            "training loss: 7.060397148132324\n",
            "training loss: 6.850588798522949\n",
            "training loss: 6.944245338439941\n",
            "training loss: 7.125059604644775\n",
            "training loss: 6.897775650024414\n",
            "training loss: 6.850660800933838\n",
            "training loss: 6.822606086730957\n",
            "training loss: 6.932969570159912\n",
            "training loss: 6.9275054931640625\n",
            "training loss: 6.836608409881592\n",
            "training loss: 7.049716472625732\n",
            "training loss: 6.932374477386475\n",
            "training loss: 6.775815486907959\n",
            "training loss: 6.800465106964111\n",
            "training loss: 6.7634735107421875\n",
            "training loss: 6.823533535003662\n",
            "training loss: 6.740392684936523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  47%|████▋     | 28/60 [18:27<22:02, 41.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.911458492279053\n",
            "training loss: 7.167852401733398\n",
            "training loss: 7.250931739807129\n",
            "training loss: 7.061855316162109\n",
            "training loss: 7.221195220947266\n",
            "training loss: 7.227445602416992\n",
            "training loss: 7.036398410797119\n",
            "training loss: 7.260634422302246\n",
            "training loss: 6.880131244659424\n",
            "training loss: 6.895473003387451\n",
            "training loss: 7.300324440002441\n",
            "training loss: 7.173616409301758\n",
            "training loss: 7.188650608062744\n",
            "training loss: 7.026001453399658\n",
            "training loss: 6.845729827880859\n",
            "training loss: 6.808071613311768\n",
            "training loss: 6.695998191833496\n",
            "training loss: 6.703861236572266\n",
            "training loss: 6.909549713134766\n",
            "training loss: 6.880414009094238\n",
            "training loss: 6.974421501159668\n",
            "training loss: 6.732666492462158\n",
            "training loss: 7.052647113800049\n",
            "training loss: 6.760253429412842\n",
            "training loss: 6.808526992797852\n",
            "training loss: 7.02366304397583\n",
            "training loss: 6.967124938964844\n",
            "training loss: 7.081411361694336\n",
            "training loss: 6.977113723754883\n",
            "training loss: 6.994259357452393\n",
            "training loss: 6.79569673538208\n",
            "training loss: 6.865442752838135\n",
            "training loss: 6.995935440063477\n",
            "training loss: 6.701013565063477\n",
            "training loss: 6.542749404907227\n",
            "training loss: 6.873149871826172\n",
            "training loss: 6.895007610321045\n",
            "training loss: 6.733356952667236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  48%|████▊     | 29/60 [19:10<21:39, 41.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.133114337921143\n",
            "training loss: 7.050425052642822\n",
            "training loss: 7.099512100219727\n",
            "training loss: 6.983795166015625\n",
            "training loss: 7.020831108093262\n",
            "training loss: 6.8739471435546875\n",
            "training loss: 6.9931840896606445\n",
            "training loss: 6.825597763061523\n",
            "training loss: 7.043747901916504\n",
            "training loss: 6.9589409828186035\n",
            "training loss: 6.811433792114258\n",
            "training loss: 6.997710227966309\n",
            "training loss: 6.972165107727051\n",
            "training loss: 7.03231954574585\n",
            "training loss: 6.9914703369140625\n",
            "training loss: 6.828236103057861\n",
            "training loss: 6.806924819946289\n",
            "training loss: 6.800111293792725\n",
            "training loss: 6.93238639831543\n",
            "training loss: 6.97063684463501\n",
            "training loss: 7.021893501281738\n",
            "training loss: 6.8985490798950195\n",
            "training loss: 6.549151420593262\n",
            "training loss: 6.905938148498535\n",
            "training loss: 6.74891996383667\n",
            "training loss: 6.688366889953613\n",
            "training loss: 6.931638717651367\n",
            "training loss: 6.997582912445068\n",
            "training loss: 6.647592067718506\n",
            "training loss: 6.752797603607178\n",
            "training loss: 6.9483842849731445\n",
            "training loss: 6.672937393188477\n",
            "training loss: 6.880492687225342\n",
            "training loss: 6.701117038726807\n",
            "training loss: 6.973557949066162\n",
            "training loss: 6.81359338760376\n",
            "training loss: 6.792597770690918\n",
            "training loss: 6.821652889251709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  50%|█████     | 30/60 [19:52<20:57, 41.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.8212714195251465\n",
            "training loss: 6.764730453491211\n",
            "training loss: 6.725367546081543\n",
            "training loss: 6.887825012207031\n",
            "training loss: 6.715161323547363\n",
            "training loss: 6.771946907043457\n",
            "training loss: 6.940449237823486\n",
            "training loss: 7.091448783874512\n",
            "training loss: 6.931498050689697\n",
            "training loss: 6.86189079284668\n",
            "training loss: 6.997869491577148\n",
            "training loss: 6.908679962158203\n",
            "training loss: 7.204097270965576\n",
            "training loss: 7.157667636871338\n",
            "training loss: 6.861541748046875\n",
            "training loss: 6.902307987213135\n",
            "training loss: 6.971625328063965\n",
            "training loss: 6.790732383728027\n",
            "training loss: 7.108127593994141\n",
            "training loss: 7.3162841796875\n",
            "training loss: 7.206477165222168\n",
            "training loss: 7.200911998748779\n",
            "training loss: 7.023731708526611\n",
            "training loss: 6.966726303100586\n",
            "training loss: 6.817623615264893\n",
            "training loss: 6.777573585510254\n",
            "training loss: 6.746795654296875\n",
            "training loss: 6.75086784362793\n",
            "training loss: 6.892228126525879\n",
            "training loss: 6.952155113220215\n",
            "training loss: 7.042295455932617\n",
            "training loss: 7.151309013366699\n",
            "training loss: 6.796648025512695\n",
            "training loss: 6.788883686065674\n",
            "training loss: 6.837638854980469\n",
            "training loss: 7.105119705200195\n",
            "training loss: 6.803800106048584\n",
            "training loss: 6.870357036590576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  52%|█████▏    | 31/60 [20:31<19:46, 40.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.292149543762207\n",
            "training loss: 7.204703330993652\n",
            "training loss: 7.244307041168213\n",
            "training loss: 6.884922027587891\n",
            "training loss: 7.088516712188721\n",
            "training loss: 6.885936737060547\n",
            "training loss: 7.211063385009766\n",
            "training loss: 7.146909713745117\n",
            "training loss: 6.953399658203125\n",
            "training loss: 7.0038604736328125\n",
            "training loss: 6.990359783172607\n",
            "training loss: 6.953783988952637\n",
            "training loss: 6.746720314025879\n",
            "training loss: 6.835567474365234\n",
            "training loss: 6.843662738800049\n",
            "training loss: 6.951727867126465\n",
            "training loss: 6.922396659851074\n",
            "training loss: 6.8877482414245605\n",
            "training loss: 7.169456958770752\n",
            "training loss: 7.1708598136901855\n",
            "training loss: 6.883047580718994\n",
            "training loss: 7.036777973175049\n",
            "training loss: 6.928094863891602\n",
            "training loss: 6.9118452072143555\n",
            "training loss: 6.711467742919922\n",
            "training loss: 6.986089706420898\n",
            "training loss: 6.520428657531738\n",
            "training loss: 7.002335071563721\n",
            "training loss: 6.905559539794922\n",
            "training loss: 6.928773880004883\n",
            "training loss: 7.117447376251221\n",
            "training loss: 7.063006401062012\n",
            "training loss: 6.822264671325684\n",
            "training loss: 6.8738226890563965\n",
            "training loss: 6.914836883544922\n",
            "training loss: 6.998863220214844\n",
            "training loss: 6.940561294555664\n",
            "training loss: 7.002712249755859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  53%|█████▎    | 32/60 [21:15<19:29, 41.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.113369464874268\n",
            "training loss: 6.7763471603393555\n",
            "training loss: 7.0381364822387695\n",
            "training loss: 6.910553932189941\n",
            "training loss: 7.022812366485596\n",
            "training loss: 7.175882339477539\n",
            "training loss: 6.834461212158203\n",
            "training loss: 6.797261714935303\n",
            "training loss: 6.90859842300415\n",
            "training loss: 7.188333988189697\n",
            "training loss: 7.256718635559082\n",
            "training loss: 6.899344444274902\n",
            "training loss: 7.080148696899414\n",
            "training loss: 7.217352390289307\n",
            "training loss: 7.308115482330322\n",
            "training loss: 6.983438968658447\n",
            "training loss: 7.06253719329834\n",
            "training loss: 6.7734174728393555\n",
            "training loss: 6.961435317993164\n",
            "training loss: 6.864205837249756\n",
            "training loss: 6.796506881713867\n",
            "training loss: 6.791177749633789\n",
            "training loss: 6.85125207901001\n",
            "training loss: 6.733469009399414\n",
            "training loss: 6.689598560333252\n",
            "training loss: 6.783219814300537\n",
            "training loss: 6.9071044921875\n",
            "training loss: 7.030813217163086\n",
            "training loss: 6.933259010314941\n",
            "training loss: 7.001421928405762\n",
            "training loss: 6.917323589324951\n",
            "training loss: 6.800753593444824\n",
            "training loss: 7.0990142822265625\n",
            "training loss: 6.904048442840576\n",
            "training loss: 6.997826099395752\n",
            "training loss: 6.946144104003906\n",
            "training loss: 6.8330078125\n",
            "training loss: 6.859935760498047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  55%|█████▌    | 33/60 [21:58<18:57, 42.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.101260185241699\n",
            "training loss: 6.896404266357422\n",
            "training loss: 6.8835859298706055\n",
            "training loss: 6.72445821762085\n",
            "training loss: 7.025865077972412\n",
            "training loss: 7.087245464324951\n",
            "training loss: 7.09315299987793\n",
            "training loss: 7.083807945251465\n",
            "training loss: 6.915246486663818\n",
            "training loss: 6.872603416442871\n",
            "training loss: 6.7911272048950195\n",
            "training loss: 6.699531555175781\n",
            "training loss: 6.856633186340332\n",
            "training loss: 6.570242881774902\n",
            "training loss: 6.909488677978516\n",
            "training loss: 6.9728593826293945\n",
            "training loss: 7.119016170501709\n",
            "training loss: 7.08501672744751\n",
            "training loss: 6.957798004150391\n",
            "training loss: 6.731223106384277\n",
            "training loss: 6.782588958740234\n",
            "training loss: 6.832921028137207\n",
            "training loss: 6.731109619140625\n",
            "training loss: 6.874026298522949\n",
            "training loss: 6.715761184692383\n",
            "training loss: 6.77656364440918\n",
            "training loss: 6.98942232131958\n",
            "training loss: 7.0401153564453125\n",
            "training loss: 6.651709079742432\n",
            "training loss: 6.68278694152832\n",
            "training loss: 6.806448936462402\n",
            "training loss: 6.855730056762695\n",
            "training loss: 6.733331203460693\n",
            "training loss: 6.947088718414307\n",
            "training loss: 6.856598854064941\n",
            "training loss: 6.84291934967041\n",
            "training loss: 6.649458408355713\n",
            "training loss: 6.659344673156738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  57%|█████▋    | 34/60 [22:38<18:01, 41.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.043281078338623\n",
            "training loss: 6.699589252471924\n",
            "training loss: 7.102599620819092\n",
            "training loss: 6.9862847328186035\n",
            "training loss: 6.742808818817139\n",
            "training loss: 6.879265785217285\n",
            "training loss: 6.954916477203369\n",
            "training loss: 6.888062477111816\n",
            "training loss: 6.745850563049316\n",
            "training loss: 6.829051971435547\n",
            "training loss: 6.968921184539795\n",
            "training loss: 6.804952621459961\n",
            "training loss: 6.562823295593262\n",
            "training loss: 6.892798900604248\n",
            "training loss: 6.841395378112793\n",
            "training loss: 7.040117263793945\n",
            "training loss: 6.628936767578125\n",
            "training loss: 6.813971996307373\n",
            "training loss: 6.746009826660156\n",
            "training loss: 6.793973445892334\n",
            "training loss: 7.042572021484375\n",
            "training loss: 6.94075870513916\n",
            "training loss: 6.766495704650879\n",
            "training loss: 6.792651653289795\n",
            "training loss: 6.762007713317871\n",
            "training loss: 6.524658679962158\n",
            "training loss: 6.753813743591309\n",
            "training loss: 6.844446182250977\n",
            "training loss: 6.816854000091553\n",
            "training loss: 6.422143936157227\n",
            "training loss: 6.556718826293945\n",
            "training loss: 6.410017013549805\n",
            "training loss: 6.559953689575195\n",
            "training loss: 6.877803325653076\n",
            "training loss: 6.7257866859436035\n",
            "training loss: 6.780361175537109\n",
            "training loss: 6.69345760345459\n",
            "training loss: 6.7250165939331055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  58%|█████▊    | 35/60 [23:16<16:55, 40.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.965790748596191\n",
            "training loss: 7.022829055786133\n",
            "training loss: 6.952366828918457\n",
            "training loss: 6.985260009765625\n",
            "training loss: 6.7866363525390625\n",
            "training loss: 7.131647109985352\n",
            "training loss: 6.936105728149414\n",
            "training loss: 6.978084564208984\n",
            "training loss: 6.669103622436523\n",
            "training loss: 7.107715129852295\n",
            "training loss: 7.074100494384766\n",
            "training loss: 7.104179382324219\n",
            "training loss: 7.129859924316406\n",
            "training loss: 6.953244209289551\n",
            "training loss: 7.062285423278809\n",
            "training loss: 6.9683380126953125\n",
            "training loss: 6.876542568206787\n",
            "training loss: 6.899820804595947\n",
            "training loss: 6.877043724060059\n",
            "training loss: 6.897702693939209\n",
            "training loss: 6.975685119628906\n",
            "training loss: 6.914694786071777\n",
            "training loss: 7.01796817779541\n",
            "training loss: 6.683037757873535\n",
            "training loss: 6.825315475463867\n",
            "training loss: 6.830256462097168\n",
            "training loss: 6.844299793243408\n",
            "training loss: 6.835940361022949\n",
            "training loss: 6.927045822143555\n",
            "training loss: 6.784677505493164\n",
            "training loss: 6.806920051574707\n",
            "training loss: 6.727297782897949\n",
            "training loss: 6.835116863250732\n",
            "training loss: 6.91290283203125\n",
            "training loss: 7.104226112365723\n",
            "training loss: 6.781699180603027\n",
            "training loss: 6.7473602294921875\n",
            "training loss: 6.6346940994262695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  60%|██████    | 36/60 [23:59<16:32, 41.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.117923736572266\n",
            "training loss: 7.226819038391113\n",
            "training loss: 7.218867778778076\n",
            "training loss: 7.036655902862549\n",
            "training loss: 7.262550354003906\n",
            "training loss: 7.120205879211426\n",
            "training loss: 6.791353702545166\n",
            "training loss: 7.062856674194336\n",
            "training loss: 6.952867031097412\n",
            "training loss: 6.769472122192383\n",
            "training loss: 7.111830234527588\n",
            "training loss: 7.044515132904053\n",
            "training loss: 6.816788196563721\n",
            "training loss: 6.66595458984375\n",
            "training loss: 7.000547409057617\n",
            "training loss: 6.767331123352051\n",
            "training loss: 6.838537216186523\n",
            "training loss: 6.638797283172607\n",
            "training loss: 6.346933841705322\n",
            "training loss: 6.933211326599121\n",
            "training loss: 6.737359046936035\n",
            "training loss: 6.800264358520508\n",
            "training loss: 6.834880828857422\n",
            "training loss: 6.935596942901611\n",
            "training loss: 6.766960144042969\n",
            "training loss: 6.847511291503906\n",
            "training loss: 6.892815113067627\n",
            "training loss: 6.501015663146973\n",
            "training loss: 6.5030598640441895\n",
            "training loss: 6.435967445373535\n",
            "training loss: 6.574537754058838\n",
            "training loss: 6.782469272613525\n",
            "training loss: 6.873040676116943\n",
            "training loss: 6.239686965942383\n",
            "training loss: 6.538723945617676\n",
            "training loss: 6.872730255126953\n",
            "training loss: 6.465277194976807\n",
            "training loss: 6.839414596557617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  62%|██████▏   | 37/60 [24:45<16:20, 42.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.919414520263672\n",
            "training loss: 6.9226393699646\n",
            "training loss: 7.248287677764893\n",
            "training loss: 7.062946796417236\n",
            "training loss: 7.092006683349609\n",
            "training loss: 7.181527614593506\n",
            "training loss: 6.890020370483398\n",
            "training loss: 6.922396183013916\n",
            "training loss: 6.989387035369873\n",
            "training loss: 7.037824630737305\n",
            "training loss: 6.807980537414551\n",
            "training loss: 6.584768295288086\n",
            "training loss: 6.788690567016602\n",
            "training loss: 6.8813371658325195\n",
            "training loss: 7.027100563049316\n",
            "training loss: 6.8467302322387695\n",
            "training loss: 6.82641077041626\n",
            "training loss: 6.728393077850342\n",
            "training loss: 6.848246097564697\n",
            "training loss: 6.84118127822876\n",
            "training loss: 6.80881404876709\n",
            "training loss: 6.568391799926758\n",
            "training loss: 6.618978500366211\n",
            "training loss: 6.816072940826416\n",
            "training loss: 6.646206855773926\n",
            "training loss: 6.840579986572266\n",
            "training loss: 6.641261100769043\n",
            "training loss: 6.638314247131348\n",
            "training loss: 6.576393127441406\n",
            "training loss: 6.5380096435546875\n",
            "training loss: 6.712545871734619\n",
            "training loss: 6.826359748840332\n",
            "training loss: 6.70611572265625\n",
            "training loss: 6.355704307556152\n",
            "training loss: 6.762350082397461\n",
            "training loss: 6.715359687805176\n",
            "training loss: 6.9130682945251465\n",
            "training loss: 7.177363395690918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  63%|██████▎   | 38/60 [25:32<16:06, 43.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.934433937072754\n",
            "training loss: 6.898536682128906\n",
            "training loss: 6.808198928833008\n",
            "training loss: 6.9782915115356445\n",
            "training loss: 6.920366287231445\n",
            "training loss: 7.0411481857299805\n",
            "training loss: 7.054568290710449\n",
            "training loss: 6.931557655334473\n",
            "training loss: 7.0639119148254395\n",
            "training loss: 6.828105926513672\n",
            "training loss: 6.945499420166016\n",
            "training loss: 6.870432376861572\n",
            "training loss: 6.753078460693359\n",
            "training loss: 7.070413589477539\n",
            "training loss: 6.933205604553223\n",
            "training loss: 7.278802394866943\n",
            "training loss: 7.062312126159668\n",
            "training loss: 7.073018550872803\n",
            "training loss: 6.744641304016113\n",
            "training loss: 6.729402542114258\n",
            "training loss: 7.060437202453613\n",
            "training loss: 6.740846157073975\n",
            "training loss: 7.042596817016602\n",
            "training loss: 6.803237438201904\n",
            "training loss: 6.749241828918457\n",
            "training loss: 6.986400127410889\n",
            "training loss: 6.893743991851807\n",
            "training loss: 7.148583889007568\n",
            "training loss: 6.7225470542907715\n",
            "training loss: 6.788441181182861\n",
            "training loss: 6.79757833480835\n",
            "training loss: 6.718785285949707\n",
            "training loss: 6.740736961364746\n",
            "training loss: 6.966397285461426\n",
            "training loss: 6.979964256286621\n",
            "training loss: 6.786764144897461\n",
            "training loss: 6.802473068237305\n",
            "training loss: 6.686882019042969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  65%|██████▌   | 39/60 [26:15<15:15, 43.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.178587436676025\n",
            "training loss: 7.1096343994140625\n",
            "training loss: 6.940501689910889\n",
            "training loss: 6.989036560058594\n",
            "training loss: 6.716065406799316\n",
            "training loss: 6.8289690017700195\n",
            "training loss: 6.673750400543213\n",
            "training loss: 6.950797080993652\n",
            "training loss: 6.866969108581543\n",
            "training loss: 6.904532432556152\n",
            "training loss: 6.988480567932129\n",
            "training loss: 7.068222999572754\n",
            "training loss: 6.63906192779541\n",
            "training loss: 6.767806053161621\n",
            "training loss: 7.000345706939697\n",
            "training loss: 6.781737327575684\n",
            "training loss: 6.848203659057617\n",
            "training loss: 6.964639186859131\n",
            "training loss: 6.850214004516602\n",
            "training loss: 7.021191596984863\n",
            "training loss: 7.114097595214844\n",
            "training loss: 6.820188999176025\n",
            "training loss: 6.794812202453613\n",
            "training loss: 6.881522178649902\n",
            "training loss: 6.987009048461914\n",
            "training loss: 7.043966293334961\n",
            "training loss: 7.160066604614258\n",
            "training loss: 7.185762405395508\n",
            "training loss: 7.113447189331055\n",
            "training loss: 6.9388933181762695\n",
            "training loss: 6.960567474365234\n",
            "training loss: 6.7614312171936035\n",
            "training loss: 6.912949562072754\n",
            "training loss: 7.208483695983887\n",
            "training loss: 7.200040817260742\n",
            "training loss: 7.083024978637695\n",
            "training loss: 6.821059226989746\n",
            "training loss: 6.5701398849487305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  67%|██████▋   | 40/60 [27:00<14:43, 44.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.003750324249268\n",
            "training loss: 7.110909461975098\n",
            "training loss: 7.047339916229248\n",
            "training loss: 7.125768661499023\n",
            "training loss: 6.827507972717285\n",
            "training loss: 7.151259422302246\n",
            "training loss: 7.157426834106445\n",
            "training loss: 6.892258644104004\n",
            "training loss: 6.822879791259766\n",
            "training loss: 6.845468521118164\n",
            "training loss: 6.700138092041016\n",
            "training loss: 6.84277868270874\n",
            "training loss: 6.956117630004883\n",
            "training loss: 6.778172969818115\n",
            "training loss: 7.095162391662598\n",
            "training loss: 7.194928169250488\n",
            "training loss: 7.306990623474121\n",
            "training loss: 7.183976173400879\n",
            "training loss: 7.2236199378967285\n",
            "training loss: 7.063648223876953\n",
            "training loss: 7.135997772216797\n",
            "training loss: 7.09336519241333\n",
            "training loss: 7.22463321685791\n",
            "training loss: 7.084333896636963\n",
            "training loss: 6.816492080688477\n",
            "training loss: 7.022472381591797\n",
            "training loss: 7.1186041831970215\n",
            "training loss: 7.005960464477539\n",
            "training loss: 7.02247953414917\n",
            "training loss: 7.076310634613037\n",
            "training loss: 6.9370832443237305\n",
            "training loss: 7.0130767822265625\n",
            "training loss: 7.150998592376709\n",
            "training loss: 6.89988899230957\n",
            "training loss: 6.854341506958008\n",
            "training loss: 6.703137397766113\n",
            "training loss: 6.871359825134277\n",
            "training loss: 6.889277458190918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  68%|██████▊   | 41/60 [27:45<14:01, 44.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.027322769165039\n",
            "training loss: 7.032837867736816\n",
            "training loss: 7.105852127075195\n",
            "training loss: 7.041328430175781\n",
            "training loss: 7.1048383712768555\n",
            "training loss: 7.120072364807129\n",
            "training loss: 6.95474100112915\n",
            "training loss: 6.8345537185668945\n",
            "training loss: 6.982664108276367\n",
            "training loss: 6.6439714431762695\n",
            "training loss: 6.8135809898376465\n",
            "training loss: 6.764884948730469\n",
            "training loss: 6.864709854125977\n",
            "training loss: 6.993946075439453\n",
            "training loss: 6.837306976318359\n",
            "training loss: 6.844601154327393\n",
            "training loss: 6.903204917907715\n",
            "training loss: 6.845005035400391\n",
            "training loss: 7.0056328773498535\n",
            "training loss: 7.016412734985352\n",
            "training loss: 7.021759510040283\n",
            "training loss: 6.862929344177246\n",
            "training loss: 6.844910621643066\n",
            "training loss: 6.757772445678711\n",
            "training loss: 6.994526386260986\n",
            "training loss: 6.746738433837891\n",
            "training loss: 6.472890853881836\n",
            "training loss: 6.8041300773620605\n",
            "training loss: 6.679629325866699\n",
            "training loss: 6.73625373840332\n",
            "training loss: 6.642787456512451\n",
            "training loss: 6.633602142333984\n",
            "training loss: 6.841348648071289\n",
            "training loss: 6.58579158782959\n",
            "training loss: 6.77828311920166\n",
            "training loss: 6.865318298339844\n",
            "training loss: 6.950191497802734\n",
            "training loss: 6.728540897369385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  70%|███████   | 42/60 [28:30<13:19, 44.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.02916145324707\n",
            "training loss: 6.481180191040039\n",
            "training loss: 6.748702526092529\n",
            "training loss: 6.856381416320801\n",
            "training loss: 7.137921333312988\n",
            "training loss: 7.148090362548828\n",
            "training loss: 7.247872829437256\n",
            "training loss: 6.869364261627197\n",
            "training loss: 6.94017219543457\n",
            "training loss: 7.178753852844238\n",
            "training loss: 7.004393100738525\n",
            "training loss: 7.078588962554932\n",
            "training loss: 6.92655611038208\n",
            "training loss: 6.988033294677734\n",
            "training loss: 7.180068016052246\n",
            "training loss: 6.883925437927246\n",
            "training loss: 6.938642978668213\n",
            "training loss: 6.849741458892822\n",
            "training loss: 6.8405914306640625\n",
            "training loss: 6.7532453536987305\n",
            "training loss: 6.995453834533691\n",
            "training loss: 6.891719818115234\n",
            "training loss: 6.787199974060059\n",
            "training loss: 6.879476547241211\n",
            "training loss: 6.764952659606934\n",
            "training loss: 6.808064937591553\n",
            "training loss: 6.85080099105835\n",
            "training loss: 6.74936580657959\n",
            "training loss: 6.831853866577148\n",
            "training loss: 6.899214267730713\n",
            "training loss: 6.696852207183838\n",
            "training loss: 6.718457221984863\n",
            "training loss: 6.973357677459717\n",
            "training loss: 6.850363731384277\n",
            "training loss: 6.756392478942871\n",
            "training loss: 6.8533735275268555\n",
            "training loss: 6.884117126464844\n",
            "training loss: 6.8718438148498535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  72%|███████▏  | 43/60 [29:09<12:08, 42.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.8942952156066895\n",
            "training loss: 6.76713752746582\n",
            "training loss: 6.979563236236572\n",
            "training loss: 7.013392448425293\n",
            "training loss: 7.0631422996521\n",
            "training loss: 7.2421112060546875\n",
            "training loss: 7.17085075378418\n",
            "training loss: 7.17325496673584\n",
            "training loss: 7.073551654815674\n",
            "training loss: 7.1790771484375\n",
            "training loss: 7.097987651824951\n",
            "training loss: 6.783639430999756\n",
            "training loss: 6.998534202575684\n",
            "training loss: 6.818470001220703\n",
            "training loss: 6.987346649169922\n",
            "training loss: 6.753842353820801\n",
            "training loss: 6.930508613586426\n",
            "training loss: 6.8908281326293945\n",
            "training loss: 6.854557037353516\n",
            "training loss: 6.6673502922058105\n",
            "training loss: 6.712836265563965\n",
            "training loss: 6.822785377502441\n",
            "training loss: 6.949986457824707\n",
            "training loss: 6.8056840896606445\n",
            "training loss: 6.884349822998047\n",
            "training loss: 6.889626502990723\n",
            "training loss: 6.685563564300537\n",
            "training loss: 6.969882011413574\n",
            "training loss: 6.73930549621582\n",
            "training loss: 6.842929840087891\n",
            "training loss: 6.7364654541015625\n",
            "training loss: 6.687798500061035\n",
            "training loss: 6.760074138641357\n",
            "training loss: 7.011450290679932\n",
            "training loss: 7.137051582336426\n",
            "training loss: 6.942511558532715\n",
            "training loss: 7.112015247344971\n",
            "training loss: 6.996095657348633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  73%|███████▎  | 44/60 [29:49<11:13, 42.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.005613327026367\n",
            "training loss: 7.017428398132324\n",
            "training loss: 6.9037580490112305\n",
            "training loss: 6.756385803222656\n",
            "training loss: 6.975977897644043\n",
            "training loss: 6.907375812530518\n",
            "training loss: 6.7664031982421875\n",
            "training loss: 6.912998676300049\n",
            "training loss: 6.96013879776001\n",
            "training loss: 6.894576072692871\n",
            "training loss: 7.101441383361816\n",
            "training loss: 7.033761501312256\n",
            "training loss: 6.908899307250977\n",
            "training loss: 6.580211162567139\n",
            "training loss: 6.8067121505737305\n",
            "training loss: 6.945301532745361\n",
            "training loss: 6.932814121246338\n",
            "training loss: 6.841136932373047\n",
            "training loss: 7.039873123168945\n",
            "training loss: 6.5604095458984375\n",
            "training loss: 6.625002861022949\n",
            "training loss: 6.906741142272949\n",
            "training loss: 6.859396934509277\n",
            "training loss: 6.858224868774414\n",
            "training loss: 6.76070499420166\n",
            "training loss: 6.755297660827637\n",
            "training loss: 6.888726234436035\n",
            "training loss: 6.88199520111084\n",
            "training loss: 6.676119804382324\n",
            "training loss: 6.830535411834717\n",
            "training loss: 6.666620254516602\n",
            "training loss: 6.968838691711426\n",
            "training loss: 6.737807750701904\n",
            "training loss: 6.683623313903809\n",
            "training loss: 7.018084526062012\n",
            "training loss: 6.779829025268555\n",
            "training loss: 6.85401725769043\n",
            "training loss: 6.607024669647217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  75%|███████▌  | 45/60 [30:32<10:34, 42.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.848123073577881\n",
            "training loss: 7.048044681549072\n",
            "training loss: 6.941422462463379\n",
            "training loss: 6.86728572845459\n",
            "training loss: 6.923757553100586\n",
            "training loss: 7.053522109985352\n",
            "training loss: 6.963357925415039\n",
            "training loss: 6.677380084991455\n",
            "training loss: 6.936017036437988\n",
            "training loss: 6.815948009490967\n",
            "training loss: 6.682538986206055\n",
            "training loss: 6.813055992126465\n",
            "training loss: 7.013096809387207\n",
            "training loss: 6.641905784606934\n",
            "training loss: 7.078094005584717\n",
            "training loss: 6.928123474121094\n",
            "training loss: 6.779670715332031\n",
            "training loss: 6.989049434661865\n",
            "training loss: 6.846494674682617\n",
            "training loss: 6.916855335235596\n",
            "training loss: 6.773082256317139\n",
            "training loss: 6.827142715454102\n",
            "training loss: 6.903648376464844\n",
            "training loss: 6.761298179626465\n",
            "training loss: 6.76626443862915\n",
            "training loss: 6.7647504806518555\n",
            "training loss: 6.776849746704102\n",
            "training loss: 7.154715538024902\n",
            "training loss: 6.845992088317871\n",
            "training loss: 6.8626580238342285\n",
            "training loss: 6.657448768615723\n",
            "training loss: 6.639438152313232\n",
            "training loss: 6.766697883605957\n",
            "training loss: 6.7684736251831055\n",
            "training loss: 6.37087869644165\n",
            "training loss: 6.480051040649414\n",
            "training loss: 6.751479625701904\n",
            "training loss: 6.566233158111572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  77%|███████▋  | 46/60 [31:11<09:36, 41.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.856990814208984\n",
            "training loss: 6.859879493713379\n",
            "training loss: 7.019880294799805\n",
            "training loss: 6.886839866638184\n",
            "training loss: 7.096941947937012\n",
            "training loss: 7.029726505279541\n",
            "training loss: 6.909963607788086\n",
            "training loss: 6.830902099609375\n",
            "training loss: 6.778964519500732\n",
            "training loss: 6.823537826538086\n",
            "training loss: 7.016666889190674\n",
            "training loss: 7.110006809234619\n",
            "training loss: 7.02040958404541\n",
            "training loss: 6.643542289733887\n",
            "training loss: 6.655840873718262\n",
            "training loss: 6.783176422119141\n",
            "training loss: 6.589098930358887\n",
            "training loss: 6.845576286315918\n",
            "training loss: 6.770864009857178\n",
            "training loss: 6.774096488952637\n",
            "training loss: 7.0183539390563965\n",
            "training loss: 6.911188125610352\n",
            "training loss: 7.014562129974365\n",
            "training loss: 6.936785697937012\n",
            "training loss: 6.838346481323242\n",
            "training loss: 6.823090553283691\n",
            "training loss: 6.892617225646973\n",
            "training loss: 6.8424153327941895\n",
            "training loss: 6.840822219848633\n",
            "training loss: 6.530702590942383\n",
            "training loss: 6.821427822113037\n",
            "training loss: 6.688366889953613\n",
            "training loss: 6.792716979980469\n",
            "training loss: 6.841213226318359\n",
            "training loss: 6.794275760650635\n",
            "training loss: 6.760347843170166\n",
            "training loss: 6.886513710021973\n",
            "training loss: 6.739688873291016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  78%|███████▊  | 47/60 [31:49<08:43, 40.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.034060955047607\n",
            "training loss: 7.005055904388428\n",
            "training loss: 7.251678466796875\n",
            "training loss: 6.920297622680664\n",
            "training loss: 7.050578594207764\n",
            "training loss: 7.075156211853027\n",
            "training loss: 6.980830192565918\n",
            "training loss: 6.797945499420166\n",
            "training loss: 6.914335250854492\n",
            "training loss: 7.130931854248047\n",
            "training loss: 6.970883369445801\n",
            "training loss: 6.737733364105225\n",
            "training loss: 6.785300254821777\n",
            "training loss: 6.949734687805176\n",
            "training loss: 7.167939186096191\n",
            "training loss: 7.200155735015869\n",
            "training loss: 7.08840274810791\n",
            "training loss: 7.0912370681762695\n",
            "training loss: 7.023825168609619\n",
            "training loss: 6.919209957122803\n",
            "training loss: 6.979971885681152\n",
            "training loss: 6.828131675720215\n",
            "training loss: 6.955454349517822\n",
            "training loss: 6.838028430938721\n",
            "training loss: 6.978487491607666\n",
            "training loss: 6.899468421936035\n",
            "training loss: 6.763708114624023\n",
            "training loss: 6.719206809997559\n",
            "training loss: 6.663122653961182\n",
            "training loss: 6.857725143432617\n",
            "training loss: 6.706446170806885\n",
            "training loss: 6.761436462402344\n",
            "training loss: 6.891009330749512\n",
            "training loss: 6.896706581115723\n",
            "training loss: 6.989477157592773\n",
            "training loss: 6.956700325012207\n",
            "training loss: 6.732905387878418\n",
            "training loss: 6.711862564086914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  80%|████████  | 48/60 [32:29<08:03, 40.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.080045700073242\n",
            "training loss: 6.9628376960754395\n",
            "training loss: 7.0937676429748535\n",
            "training loss: 6.944624423980713\n",
            "training loss: 7.030898094177246\n",
            "training loss: 7.113102436065674\n",
            "training loss: 7.046095371246338\n",
            "training loss: 7.0118608474731445\n",
            "training loss: 6.719156742095947\n",
            "training loss: 6.835293769836426\n",
            "training loss: 6.821111679077148\n",
            "training loss: 6.966916561126709\n",
            "training loss: 6.969202041625977\n",
            "training loss: 7.006818771362305\n",
            "training loss: 6.804940223693848\n",
            "training loss: 6.8506317138671875\n",
            "training loss: 6.598779678344727\n",
            "training loss: 6.693556308746338\n",
            "training loss: 6.842154026031494\n",
            "training loss: 6.893239498138428\n",
            "training loss: 6.859592914581299\n",
            "training loss: 6.858983516693115\n",
            "training loss: 6.975126266479492\n",
            "training loss: 6.824840545654297\n",
            "training loss: 6.965322494506836\n",
            "training loss: 6.8891072273254395\n",
            "training loss: 6.921114921569824\n",
            "training loss: 6.852206707000732\n",
            "training loss: 7.022212982177734\n",
            "training loss: 7.011894702911377\n",
            "training loss: 7.006448268890381\n",
            "training loss: 6.933897495269775\n",
            "training loss: 6.790002346038818\n",
            "training loss: 6.818737983703613\n",
            "training loss: 6.842288494110107\n",
            "training loss: 6.763524055480957\n",
            "training loss: 6.918156623840332\n",
            "training loss: 6.737622261047363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  82%|████████▏ | 49/60 [33:12<07:33, 41.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.074853420257568\n",
            "training loss: 6.892539978027344\n",
            "training loss: 6.612090110778809\n",
            "training loss: 7.206552505493164\n",
            "training loss: 7.3601837158203125\n",
            "training loss: 7.025367736816406\n",
            "training loss: 6.986208438873291\n",
            "training loss: 6.812765598297119\n",
            "training loss: 6.960595607757568\n",
            "training loss: 6.983193874359131\n",
            "training loss: 7.035058975219727\n",
            "training loss: 6.98058557510376\n",
            "training loss: 6.911440849304199\n",
            "training loss: 6.74100399017334\n",
            "training loss: 6.908391952514648\n",
            "training loss: 7.12481689453125\n",
            "training loss: 7.041566848754883\n",
            "training loss: 6.990774154663086\n",
            "training loss: 7.016029357910156\n",
            "training loss: 6.87929105758667\n",
            "training loss: 6.858792781829834\n",
            "training loss: 6.766002655029297\n",
            "training loss: 6.870944023132324\n",
            "training loss: 6.868777275085449\n",
            "training loss: 7.048524856567383\n",
            "training loss: 7.2069783210754395\n",
            "training loss: 6.780525207519531\n",
            "training loss: 7.077570915222168\n",
            "training loss: 6.9807538986206055\n",
            "training loss: 6.8885626792907715\n",
            "training loss: 6.984288215637207\n",
            "training loss: 6.9454345703125\n",
            "training loss: 6.738564491271973\n",
            "training loss: 6.9540324211120605\n",
            "training loss: 7.0402398109436035\n",
            "training loss: 6.628969192504883\n",
            "training loss: 6.843790054321289\n",
            "training loss: 6.835248947143555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  83%|████████▎ | 50/60 [33:54<06:51, 41.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.961207389831543\n",
            "training loss: 7.299092769622803\n",
            "training loss: 7.058543682098389\n",
            "training loss: 7.071043968200684\n",
            "training loss: 6.8397064208984375\n",
            "training loss: 6.793144702911377\n",
            "training loss: 7.110195159912109\n",
            "training loss: 6.983532905578613\n",
            "training loss: 6.836915969848633\n",
            "training loss: 6.9064717292785645\n",
            "training loss: 6.906460762023926\n",
            "training loss: 6.53508186340332\n",
            "training loss: 6.790180206298828\n",
            "training loss: 6.689918041229248\n",
            "training loss: 6.577989101409912\n",
            "training loss: 6.96583366394043\n",
            "training loss: 7.140448093414307\n",
            "training loss: 6.852768898010254\n",
            "training loss: 6.974226474761963\n",
            "training loss: 6.843387603759766\n",
            "training loss: 7.004236221313477\n",
            "training loss: 6.889192581176758\n",
            "training loss: 6.598190784454346\n",
            "training loss: 6.965121269226074\n",
            "training loss: 6.922082901000977\n",
            "training loss: 6.762287139892578\n",
            "training loss: 6.832656383514404\n",
            "training loss: 7.068869590759277\n",
            "training loss: 6.887366771697998\n",
            "training loss: 6.687057971954346\n",
            "training loss: 6.619673252105713\n",
            "training loss: 6.518678665161133\n",
            "training loss: 6.573519706726074\n",
            "training loss: 6.914892196655273\n",
            "training loss: 7.025081157684326\n",
            "training loss: 6.673425674438477\n",
            "training loss: 6.582547664642334\n",
            "training loss: 6.809624671936035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  85%|████████▌ | 51/60 [34:36<06:14, 41.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.892455101013184\n",
            "training loss: 6.954013824462891\n",
            "training loss: 6.802385330200195\n",
            "training loss: 7.03770637512207\n",
            "training loss: 6.971781253814697\n",
            "training loss: 6.936123847961426\n",
            "training loss: 6.820364952087402\n",
            "training loss: 6.705624580383301\n",
            "training loss: 6.73643684387207\n",
            "training loss: 6.9023637771606445\n",
            "training loss: 6.862699508666992\n",
            "training loss: 6.78006649017334\n",
            "training loss: 7.091548442840576\n",
            "training loss: 6.995379447937012\n",
            "training loss: 6.716534614562988\n",
            "training loss: 6.841850280761719\n",
            "training loss: 6.824645519256592\n",
            "training loss: 6.591805458068848\n",
            "training loss: 6.786615371704102\n",
            "training loss: 6.809243202209473\n",
            "training loss: 6.760986328125\n",
            "training loss: 6.554662227630615\n",
            "training loss: 6.663980960845947\n",
            "training loss: 6.53082799911499\n",
            "training loss: 6.532759189605713\n",
            "training loss: 6.722834587097168\n",
            "training loss: 6.593376636505127\n",
            "training loss: 6.519508361816406\n",
            "training loss: 6.628721714019775\n",
            "training loss: 6.862020015716553\n",
            "training loss: 6.568166255950928\n",
            "training loss: 6.746765613555908\n",
            "training loss: 6.907495021820068\n",
            "training loss: 6.687892436981201\n",
            "training loss: 6.778938293457031\n",
            "training loss: 6.759900093078613\n",
            "training loss: 6.922903060913086\n",
            "training loss: 6.774873733520508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  87%|████████▋ | 52/60 [35:14<05:24, 40.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.972963333129883\n",
            "training loss: 7.006219387054443\n",
            "training loss: 7.004993438720703\n",
            "training loss: 6.89321756362915\n",
            "training loss: 7.205975532531738\n",
            "training loss: 6.953799724578857\n",
            "training loss: 6.923456192016602\n",
            "training loss: 7.004785537719727\n",
            "training loss: 7.046639442443848\n",
            "training loss: 7.197731971740723\n",
            "training loss: 6.970616817474365\n",
            "training loss: 6.975913047790527\n",
            "training loss: 6.884139060974121\n",
            "training loss: 7.076604843139648\n",
            "training loss: 6.853437423706055\n",
            "training loss: 6.556398391723633\n",
            "training loss: 6.697775363922119\n",
            "training loss: 6.86292839050293\n",
            "training loss: 6.829602241516113\n",
            "training loss: 6.917086601257324\n",
            "training loss: 6.9602251052856445\n",
            "training loss: 7.079653739929199\n",
            "training loss: 6.704606056213379\n",
            "training loss: 6.814319610595703\n",
            "training loss: 6.883748531341553\n",
            "training loss: 6.824796199798584\n",
            "training loss: 6.748466491699219\n",
            "training loss: 6.76089334487915\n",
            "training loss: 6.878705024719238\n",
            "training loss: 6.939857482910156\n",
            "training loss: 7.016848564147949\n",
            "training loss: 7.157442092895508\n",
            "training loss: 7.04112434387207\n",
            "training loss: 6.82607889175415\n",
            "training loss: 6.736961841583252\n",
            "training loss: 6.774969100952148\n",
            "training loss: 6.758896827697754\n",
            "training loss: 7.023096561431885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  88%|████████▊ | 53/60 [35:53<04:39, 39.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.8229241371154785\n",
            "training loss: 6.978436470031738\n",
            "training loss: 6.905290603637695\n",
            "training loss: 7.157358169555664\n",
            "training loss: 6.873775482177734\n",
            "training loss: 7.031538486480713\n",
            "training loss: 6.736562252044678\n",
            "training loss: 6.770174980163574\n",
            "training loss: 6.816176414489746\n",
            "training loss: 6.841639518737793\n",
            "training loss: 6.879429340362549\n",
            "training loss: 6.583896160125732\n",
            "training loss: 6.810758590698242\n",
            "training loss: 7.089756488800049\n",
            "training loss: 6.944772720336914\n",
            "training loss: 6.884036064147949\n",
            "training loss: 6.916372776031494\n",
            "training loss: 6.85581636428833\n",
            "training loss: 6.959402084350586\n",
            "training loss: 6.939637184143066\n",
            "training loss: 6.86070442199707\n",
            "training loss: 6.723086357116699\n",
            "training loss: 6.917492866516113\n",
            "training loss: 7.029820919036865\n",
            "training loss: 6.925222396850586\n",
            "training loss: 6.735731601715088\n",
            "training loss: 6.839869022369385\n",
            "training loss: 6.914552211761475\n",
            "training loss: 6.874425411224365\n",
            "training loss: 7.031776428222656\n",
            "training loss: 6.922146320343018\n",
            "training loss: 6.9344563484191895\n",
            "training loss: 6.962658882141113\n",
            "training loss: 6.943243980407715\n",
            "training loss: 6.961794853210449\n",
            "training loss: 6.708713054656982\n",
            "training loss: 6.814689636230469\n",
            "training loss: 6.776373863220215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  90%|█████████ | 54/60 [36:31<03:56, 39.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.903870105743408\n",
            "training loss: 7.03617525100708\n",
            "training loss: 6.925224781036377\n",
            "training loss: 6.964849472045898\n",
            "training loss: 6.930069923400879\n",
            "training loss: 7.079952239990234\n",
            "training loss: 7.055519104003906\n",
            "training loss: 7.1697587966918945\n",
            "training loss: 6.756884574890137\n",
            "training loss: 7.060019016265869\n",
            "training loss: 7.070013046264648\n",
            "training loss: 7.071118354797363\n",
            "training loss: 6.819187641143799\n",
            "training loss: 6.9886932373046875\n",
            "training loss: 6.926514625549316\n",
            "training loss: 6.8291144371032715\n",
            "training loss: 6.671139240264893\n",
            "training loss: 6.9706220626831055\n",
            "training loss: 6.889263153076172\n",
            "training loss: 6.711435317993164\n",
            "training loss: 6.701684951782227\n",
            "training loss: 6.641923904418945\n",
            "training loss: 6.681867599487305\n",
            "training loss: 6.864557266235352\n",
            "training loss: 6.802175998687744\n",
            "training loss: 6.7433929443359375\n",
            "training loss: 6.712922096252441\n",
            "training loss: 6.976167678833008\n",
            "training loss: 6.881327152252197\n",
            "training loss: 6.787415027618408\n",
            "training loss: 6.640896320343018\n",
            "training loss: 7.244105339050293\n",
            "training loss: 7.192046642303467\n",
            "training loss: 7.160735130310059\n",
            "training loss: 6.780179977416992\n",
            "training loss: 6.907106876373291\n",
            "training loss: 6.611821174621582\n",
            "training loss: 6.728417873382568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  92%|█████████▏| 55/60 [37:09<03:15, 39.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.08101749420166\n",
            "training loss: 6.765387535095215\n",
            "training loss: 6.803796768188477\n",
            "training loss: 6.649214744567871\n",
            "training loss: 6.867998123168945\n",
            "training loss: 6.689599990844727\n",
            "training loss: 6.966554164886475\n",
            "training loss: 6.933890342712402\n",
            "training loss: 6.802604675292969\n",
            "training loss: 6.692333698272705\n",
            "training loss: 6.841772556304932\n",
            "training loss: 6.910487651824951\n",
            "training loss: 6.823941230773926\n",
            "training loss: 6.811901092529297\n",
            "training loss: 6.59879207611084\n",
            "training loss: 6.779997825622559\n",
            "training loss: 6.907293796539307\n",
            "training loss: 6.743054389953613\n",
            "training loss: 6.920454025268555\n",
            "training loss: 6.624956130981445\n",
            "training loss: 6.832566261291504\n",
            "training loss: 6.826194763183594\n",
            "training loss: 6.686408042907715\n",
            "training loss: 6.762887001037598\n",
            "training loss: 6.72812557220459\n",
            "training loss: 6.826191425323486\n",
            "training loss: 6.618575096130371\n",
            "training loss: 6.276834487915039\n",
            "training loss: 6.78187370300293\n",
            "training loss: 6.563266754150391\n",
            "training loss: 6.719230651855469\n",
            "training loss: 6.839003562927246\n",
            "training loss: 6.817522048950195\n",
            "training loss: 6.756740570068359\n",
            "training loss: 6.7721757888793945\n",
            "training loss: 6.824431419372559\n",
            "training loss: 6.750961780548096\n",
            "training loss: 6.934781074523926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  93%|█████████▎| 56/60 [37:47<02:34, 38.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9846601486206055\n",
            "training loss: 7.011218070983887\n",
            "training loss: 7.064876556396484\n",
            "training loss: 6.883882522583008\n",
            "training loss: 7.124920845031738\n",
            "training loss: 6.770108222961426\n",
            "training loss: 6.621429443359375\n",
            "training loss: 6.972975254058838\n",
            "training loss: 6.750853538513184\n",
            "training loss: 6.966207504272461\n",
            "training loss: 6.8374176025390625\n",
            "training loss: 6.98281192779541\n",
            "training loss: 6.714694976806641\n",
            "training loss: 6.869410514831543\n",
            "training loss: 6.746819496154785\n",
            "training loss: 7.040042877197266\n",
            "training loss: 6.925085544586182\n",
            "training loss: 6.552797794342041\n",
            "training loss: 6.778534889221191\n",
            "training loss: 6.732008457183838\n",
            "training loss: 6.9260759353637695\n",
            "training loss: 6.918918132781982\n",
            "training loss: 6.900082588195801\n",
            "training loss: 6.800029754638672\n",
            "training loss: 6.856566429138184\n",
            "training loss: 7.066244125366211\n",
            "training loss: 6.83090877532959\n",
            "training loss: 6.890505790710449\n",
            "training loss: 6.925195693969727\n",
            "training loss: 6.900659561157227\n",
            "training loss: 6.978701114654541\n",
            "training loss: 6.837608337402344\n",
            "training loss: 6.8840436935424805\n",
            "training loss: 6.692757606506348\n",
            "training loss: 6.933830261230469\n",
            "training loss: 6.792752742767334\n",
            "training loss: 6.6129655838012695\n",
            "training loss: 6.678953170776367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  95%|█████████▌| 57/60 [38:24<01:54, 38.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.929502487182617\n",
            "training loss: 6.952098369598389\n",
            "training loss: 7.079798698425293\n",
            "training loss: 6.996832370758057\n",
            "training loss: 6.9196319580078125\n",
            "training loss: 6.789000988006592\n",
            "training loss: 6.937988758087158\n",
            "training loss: 6.749717712402344\n",
            "training loss: 6.935294151306152\n",
            "training loss: 6.799313545227051\n",
            "training loss: 6.938831329345703\n",
            "training loss: 6.669700622558594\n",
            "training loss: 6.761606216430664\n",
            "training loss: 6.572564125061035\n",
            "training loss: 6.637040615081787\n",
            "training loss: 6.791947364807129\n",
            "training loss: 6.868388652801514\n",
            "training loss: 6.597573280334473\n",
            "training loss: 6.688454627990723\n",
            "training loss: 6.733639240264893\n",
            "training loss: 6.73105525970459\n",
            "training loss: 7.139049530029297\n",
            "training loss: 6.779618263244629\n",
            "training loss: 6.918128967285156\n",
            "training loss: 6.941906929016113\n",
            "training loss: 6.91469669342041\n",
            "training loss: 6.94931697845459\n",
            "training loss: 6.80741548538208\n",
            "training loss: 6.799193382263184\n",
            "training loss: 6.917716026306152\n",
            "training loss: 7.150325298309326\n",
            "training loss: 6.979082107543945\n",
            "training loss: 6.792324066162109\n",
            "training loss: 6.764486789703369\n",
            "training loss: 6.863630771636963\n",
            "training loss: 6.754549026489258\n",
            "training loss: 6.731943130493164\n",
            "training loss: 6.718473434448242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  97%|█████████▋| 58/60 [39:03<01:16, 38.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.066157817840576\n",
            "training loss: 7.137030601501465\n",
            "training loss: 7.172163009643555\n",
            "training loss: 7.135046005249023\n",
            "training loss: 6.900139808654785\n",
            "training loss: 7.133241653442383\n",
            "training loss: 6.948760032653809\n",
            "training loss: 6.8655548095703125\n",
            "training loss: 6.889986515045166\n",
            "training loss: 7.151792049407959\n",
            "training loss: 6.885984897613525\n",
            "training loss: 7.170320510864258\n",
            "training loss: 6.987954139709473\n",
            "training loss: 6.862856864929199\n",
            "training loss: 6.945980548858643\n",
            "training loss: 6.976326942443848\n",
            "training loss: 6.841049671173096\n",
            "training loss: 6.904173851013184\n",
            "training loss: 6.6841230392456055\n",
            "training loss: 6.736208915710449\n",
            "training loss: 6.649050712585449\n",
            "training loss: 6.984831809997559\n",
            "training loss: 6.670422554016113\n",
            "training loss: 6.657787322998047\n",
            "training loss: 6.811396598815918\n",
            "training loss: 6.890162467956543\n",
            "training loss: 6.792038917541504\n",
            "training loss: 6.610005855560303\n",
            "training loss: 6.585543155670166\n",
            "training loss: 6.67478084564209\n",
            "training loss: 6.697709560394287\n",
            "training loss: 6.777954578399658\n",
            "training loss: 6.749656677246094\n",
            "training loss: 6.660843849182129\n",
            "training loss: 6.9267730712890625\n",
            "training loss: 6.877137184143066\n",
            "training loss: 6.381804466247559\n",
            "training loss: 6.70680046081543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  98%|█████████▊| 59/60 [39:45<00:39, 39.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.867955684661865\n",
            "training loss: 6.863644123077393\n",
            "training loss: 6.586173057556152\n",
            "training loss: 6.775561332702637\n",
            "training loss: 6.786322593688965\n",
            "training loss: 7.073610782623291\n",
            "training loss: 6.910619258880615\n",
            "training loss: 6.948147773742676\n",
            "training loss: 6.825116157531738\n",
            "training loss: 6.942386627197266\n",
            "training loss: 6.742774486541748\n",
            "training loss: 6.690346717834473\n",
            "training loss: 6.724635124206543\n",
            "training loss: 7.0649871826171875\n",
            "training loss: 6.812384605407715\n",
            "training loss: 6.681206703186035\n",
            "training loss: 6.850029945373535\n",
            "training loss: 6.863544464111328\n",
            "training loss: 6.973284721374512\n",
            "training loss: 6.838501930236816\n",
            "training loss: 7.076774597167969\n",
            "training loss: 6.996997833251953\n",
            "training loss: 7.024664878845215\n",
            "training loss: 6.967512130737305\n",
            "training loss: 6.941823959350586\n",
            "training loss: 6.687323570251465\n",
            "training loss: 6.609575271606445\n",
            "training loss: 6.820954322814941\n",
            "training loss: 6.584874629974365\n",
            "training loss: 6.8259968757629395\n",
            "training loss: 6.812878608703613\n",
            "training loss: 6.800973892211914\n",
            "training loss: 6.906501293182373\n",
            "training loss: 6.915088653564453\n",
            "training loss: 6.571170806884766\n",
            "training loss: 6.648250102996826\n",
            "training loss: 6.513418197631836\n",
            "training loss: 6.611039638519287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training: 100%|██████████| 60/60 [40:33<00:00, 40.56s/it]\n",
            "evaluation:   0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 6.380160331726074\n",
            "test loss: 6.480676651000977\n",
            "test loss: 6.497026443481445\n",
            "test loss: 6.230057239532471\n",
            "test loss: 6.115499496459961\n",
            "test loss: 6.822117328643799\n",
            "test loss: 6.626629829406738\n",
            "test loss: 6.618889808654785\n",
            "test loss: 6.751934051513672\n",
            "test loss: 6.54987096786499\n",
            "test loss: 6.658675193786621\n",
            "test loss: 6.783965110778809\n",
            "test loss: 6.637799263000488\n",
            "test loss: 6.505499839782715\n",
            "test loss: 6.550259590148926\n",
            "test loss: 6.468724727630615\n",
            "test loss: 6.644973278045654\n",
            "test loss: 6.70798397064209\n",
            "test loss: 6.21978235244751\n",
            "test loss: 6.699718475341797\n",
            "test loss: 6.628298759460449\n",
            "test loss: 6.594137668609619\n",
            "test loss: 6.453885555267334\n",
            "test loss: 6.188283920288086\n",
            "test loss: 6.135392189025879\n",
            "test loss: 6.108329772949219\n",
            "test loss: 6.507291316986084\n",
            "test loss: 6.461855888366699\n",
            "test loss: 6.321689605712891\n",
            "test loss: 6.486210823059082\n",
            "test loss: 6.46595573425293\n",
            "test loss: 6.537853717803955\n",
            "test loss: 6.5302042961120605\n",
            "test loss: 6.74535608291626\n",
            "test loss: 6.671630859375\n",
            "test loss: 6.539770126342773\n",
            "test loss: 6.5552144050598145\n",
            "test loss: 6.64372444152832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\revaluation:  14%|█▍        | 1/7 [01:18<07:50, 78.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 6.439296722412109\n",
            "test loss: 6.553375244140625\n",
            "test loss: 6.674346923828125\n",
            "test loss: 6.267533779144287\n",
            "test loss: 6.147438049316406\n",
            "test loss: 6.342528343200684\n",
            "test loss: 6.246972560882568\n",
            "test loss: 5.8421220779418945\n",
            "test loss: 6.373047351837158\n",
            "test loss: 6.4444966316223145\n",
            "test loss: 6.389947414398193\n",
            "test loss: 6.472725868225098\n",
            "test loss: 6.519606590270996\n",
            "test loss: 6.185854911804199\n",
            "test loss: 6.279632568359375\n",
            "test loss: 6.631122589111328\n",
            "test loss: 6.31562614440918\n",
            "test loss: 6.3653411865234375\n",
            "test loss: 6.351363182067871\n",
            "test loss: 6.111860752105713\n",
            "test loss: 6.318002700805664\n",
            "test loss: 6.231016635894775\n",
            "test loss: 6.429991722106934\n",
            "test loss: 6.321893215179443\n",
            "test loss: 6.227779865264893\n",
            "test loss: 6.339696407318115\n",
            "test loss: 6.5119829177856445\n",
            "test loss: 6.512181282043457\n",
            "test loss: 6.632713317871094\n",
            "test loss: 6.240187168121338\n",
            "test loss: 6.4771223068237305\n",
            "test loss: 6.204690933227539\n",
            "test loss: 6.162685871124268\n",
            "test loss: 6.094160556793213\n",
            "test loss: 6.400665283203125\n",
            "test loss: 6.306252479553223\n",
            "test loss: 6.124606609344482\n",
            "test loss: 6.238950729370117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\revaluation:  29%|██▊       | 2/7 [02:42<06:48, 81.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 6.3608245849609375\n",
            "test loss: 6.349618911743164\n",
            "test loss: 6.567682266235352\n",
            "test loss: 6.480257511138916\n",
            "test loss: 6.60488224029541\n",
            "test loss: 6.307799816131592\n",
            "test loss: 6.469132423400879\n",
            "test loss: 6.296040058135986\n",
            "test loss: 6.189703464508057\n",
            "test loss: 6.240938663482666\n",
            "test loss: 6.310966968536377\n",
            "test loss: 6.239990234375\n",
            "test loss: 6.254400730133057\n",
            "test loss: 6.129912853240967\n",
            "test loss: 6.080662727355957\n",
            "test loss: 6.193846702575684\n",
            "test loss: 6.504307746887207\n",
            "test loss: 6.411277770996094\n",
            "test loss: 6.448947906494141\n",
            "test loss: 6.4133124351501465\n",
            "test loss: 6.482701301574707\n",
            "test loss: 6.768148422241211\n",
            "test loss: 6.763309478759766\n",
            "test loss: 6.5488152503967285\n",
            "test loss: 6.613430023193359\n",
            "test loss: 6.680771827697754\n",
            "test loss: 6.511777877807617\n",
            "test loss: 6.815282821655273\n",
            "test loss: 6.561505317687988\n",
            "test loss: 6.565224647521973\n",
            "test loss: 6.762995719909668\n",
            "test loss: 6.501250267028809\n",
            "test loss: 6.590506553649902\n",
            "test loss: 6.351314544677734\n",
            "test loss: 6.2437849044799805\n",
            "test loss: 6.137923240661621\n",
            "test loss: 6.121456146240234\n",
            "test loss: 6.201558589935303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\revaluation:  43%|████▎     | 3/7 [04:09<05:36, 84.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 6.167935371398926\n",
            "test loss: 6.104860305786133\n",
            "test loss: 6.080105781555176\n",
            "test loss: 5.7744879722595215\n",
            "test loss: 5.84895133972168\n",
            "test loss: 6.060746192932129\n",
            "test loss: 6.157236099243164\n",
            "test loss: 6.256106376647949\n",
            "test loss: 6.531893253326416\n",
            "test loss: 6.600546360015869\n",
            "test loss: 6.436025142669678\n",
            "test loss: 6.240921497344971\n",
            "test loss: 6.194777488708496\n",
            "test loss: 6.187515735626221\n",
            "test loss: 6.474811553955078\n",
            "test loss: 6.296968460083008\n",
            "test loss: 6.501775741577148\n",
            "test loss: 6.436164379119873\n",
            "test loss: 6.36590051651001\n",
            "test loss: 6.165201187133789\n",
            "test loss: 6.0482072830200195\n",
            "test loss: 6.143720626831055\n",
            "test loss: 6.252758979797363\n",
            "test loss: 6.129891395568848\n",
            "test loss: 6.301535129547119\n",
            "test loss: 6.214991569519043\n",
            "test loss: 6.064948558807373\n",
            "test loss: 6.274023056030273\n",
            "test loss: 6.3111796379089355\n",
            "test loss: 6.1070990562438965\n",
            "test loss: 6.3482561111450195\n",
            "test loss: 6.357983589172363\n",
            "test loss: 6.270170211791992\n",
            "test loss: 6.0232462882995605\n",
            "test loss: 6.57083797454834\n",
            "test loss: 6.5914106369018555\n",
            "test loss: 6.570127487182617\n",
            "test loss: 6.1182451248168945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\revaluation:  57%|█████▋    | 4/7 [05:26<04:03, 81.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 6.466969966888428\n",
            "test loss: 6.566732406616211\n",
            "test loss: 6.409769535064697\n",
            "test loss: 6.556762218475342\n",
            "test loss: 6.404936790466309\n",
            "test loss: 6.342927932739258\n",
            "test loss: 6.617951393127441\n",
            "test loss: 6.494373321533203\n",
            "test loss: 6.369955062866211\n",
            "test loss: 6.377032279968262\n",
            "test loss: 6.30531644821167\n",
            "test loss: 6.500199317932129\n",
            "test loss: 6.3300323486328125\n",
            "test loss: 6.450268745422363\n",
            "test loss: 6.346978187561035\n",
            "test loss: 6.523630142211914\n",
            "test loss: 6.552602291107178\n",
            "test loss: 6.530992031097412\n",
            "test loss: 6.543129920959473\n",
            "test loss: 6.671599388122559\n",
            "test loss: 6.757313251495361\n",
            "test loss: 6.520491600036621\n",
            "test loss: 6.650744915008545\n",
            "test loss: 6.51661491394043\n",
            "test loss: 6.6399335861206055\n",
            "test loss: 6.476777076721191\n",
            "test loss: 6.741415977478027\n",
            "test loss: 6.739166736602783\n",
            "test loss: 6.440938949584961\n",
            "test loss: 6.652795314788818\n",
            "test loss: 6.566893577575684\n",
            "test loss: 6.646049976348877\n",
            "test loss: 6.317508220672607\n",
            "test loss: 6.480961799621582\n",
            "test loss: 6.538074016571045\n",
            "test loss: 6.49407434463501\n",
            "test loss: 6.509963035583496\n",
            "test loss: 6.677108287811279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\revaluation:  71%|███████▏  | 5/7 [06:49<02:44, 82.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 6.257102012634277\n",
            "test loss: 6.5416259765625\n",
            "test loss: 6.569528579711914\n",
            "test loss: 6.364010810852051\n",
            "test loss: 6.386063098907471\n",
            "test loss: 5.986822128295898\n",
            "test loss: 6.304279804229736\n",
            "test loss: 6.275804042816162\n",
            "test loss: 6.201563835144043\n",
            "test loss: 6.071472644805908\n",
            "test loss: 6.043830871582031\n",
            "test loss: 6.2242817878723145\n",
            "test loss: 5.931904315948486\n",
            "test loss: 6.33253288269043\n",
            "test loss: 6.103945732116699\n",
            "test loss: 5.951487064361572\n",
            "test loss: 6.056273460388184\n",
            "test loss: 6.031005859375\n",
            "test loss: 5.96504020690918\n",
            "test loss: 6.478963851928711\n",
            "test loss: 6.304556846618652\n",
            "test loss: 6.364922523498535\n",
            "test loss: 5.970907688140869\n",
            "test loss: 6.3294477462768555\n",
            "test loss: 6.0897979736328125\n",
            "test loss: 5.967047691345215\n",
            "test loss: 6.074197292327881\n",
            "test loss: 6.026233673095703\n",
            "test loss: 6.075042247772217\n",
            "test loss: 6.15176248550415\n",
            "test loss: 6.192207336425781\n",
            "test loss: 6.056919097900391\n",
            "test loss: 6.290553092956543\n",
            "test loss: 6.201517105102539\n",
            "test loss: 6.0234527587890625\n",
            "test loss: 6.017437934875488\n",
            "test loss: 6.212186813354492\n",
            "test loss: 5.917534828186035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\revaluation:  86%|████████▌ | 6/7 [08:18<01:24, 84.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 6.4425048828125\n",
            "test loss: 6.3119659423828125\n",
            "test loss: 6.326564788818359\n",
            "test loss: 6.337813854217529\n",
            "test loss: 6.208460807800293\n",
            "test loss: 6.435208797454834\n",
            "test loss: 6.268249988555908\n",
            "test loss: 6.383284568786621\n",
            "test loss: 6.2944722175598145\n",
            "test loss: 6.146888256072998\n",
            "test loss: 6.404781818389893\n",
            "test loss: 6.402615547180176\n",
            "test loss: 6.366527557373047\n",
            "test loss: 6.206051349639893\n",
            "test loss: 6.15446662902832\n",
            "test loss: 6.05387020111084\n",
            "test loss: 6.120372772216797\n",
            "test loss: 6.33803129196167\n",
            "test loss: 6.451013088226318\n",
            "test loss: 6.368541717529297\n",
            "test loss: 6.443199157714844\n",
            "test loss: 6.439249038696289\n",
            "test loss: 6.558123588562012\n",
            "test loss: 6.0740647315979\n",
            "test loss: 6.210759162902832\n",
            "test loss: 6.436697483062744\n",
            "test loss: 6.187721252441406\n",
            "test loss: 6.344787120819092\n",
            "test loss: 6.346390247344971\n",
            "test loss: 6.572155952453613\n",
            "test loss: 6.388609886169434\n",
            "test loss: 6.110015392303467\n",
            "test loss: 6.084353446960449\n",
            "test loss: 6.091987609863281\n",
            "test loss: 6.548061370849609\n",
            "test loss: 6.447137832641602\n",
            "test loss: 6.421504497528076\n",
            "test loss: 6.473211765289307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "evaluation: 100%|██████████| 7/7 [09:38<00:00, 82.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 647.580322265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training:   0%|          | 0/60 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.946478843688965\n",
            "training loss: 6.9727864265441895\n",
            "training loss: 6.804868698120117\n",
            "training loss: 6.813070774078369\n",
            "training loss: 6.686347961425781\n",
            "training loss: 6.99963903427124\n",
            "training loss: 6.937539100646973\n",
            "training loss: 7.129488945007324\n",
            "training loss: 6.7009077072143555\n",
            "training loss: 6.704884052276611\n",
            "training loss: 6.752254486083984\n",
            "training loss: 6.858561992645264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/60 [00:12<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-197dfd46e125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mloss_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_GRAD_CLIP_NORM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer decoder training"
      ],
      "metadata": {
        "id": "ayPdgmodFg4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module): #decoder-only architecture of the transformer\n",
        "  def __init__(\n",
        "        self,\n",
        "        num_tokens,\n",
        "        d,\n",
        "        heads = 8,\n",
        "        depth = 4,\n",
        "        hidden_size = 1000,\n",
        "        dropout = 0.3,\n",
        "        batch_size = 16,\n",
        "        use_bert = True\n",
        "    ):\n",
        "      # asserts\n",
        "      self.d = d if not use_bert else 768\n",
        "      assert self.d % heads == 0\n",
        " \n",
        "      super(TransformerDecoder, self).__init__()\n",
        "      self.token_emb = nn.Embedding(num_tokens, self.d)\n",
        "      self.positional_enc = PositionalEncoding(self.d, max_len = 5000)\n",
        "      self.dim_head = self.d // heads\n",
        "      self.heads = heads\n",
        "      self.depth = depth\n",
        "      self.hidden_size = hidden_size\n",
        "      self.dropout = dropout\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      self.layers = nn.ModuleList([])\n",
        "      for idx in range(depth):\n",
        "          self.layers.append(\n",
        "              TransformerBlock(d, heads, batch_size, hidden_size, dropout)\n",
        "          )\n",
        "\n",
        "      self.to_out = nn.Linear(d, num_tokens)\n",
        "    \n",
        "  def create_mask(self, x):\n",
        "    batch_size, seq_len = x.shape\n",
        "    mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "        batch_size, 1, seq_len, seq_len\n",
        "    )\n",
        "    return mask \n",
        "          \n",
        "  def forward(self, x):\n",
        "    mask = self.create_mask(x)\n",
        "\n",
        "    x = self.token_emb(x)\n",
        "    x = self.positional_enc(x)\n",
        "\n",
        "    for idx in range(self.depth):\n",
        "        x= self.layers[idx](x, mask)\n",
        "\n",
        "    return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "lBz91btCHjXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "SEQ_LEN = 256\n",
        "SEGMENTS = 5\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS\n",
        "DIM_HEAD_BERT = 768 // HEADS\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 20\n",
        "CHECKPOINT = 5"
      ],
      "metadata": {
        "id": "sF-Xk7gtKMA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tr_decoder = TransformerDecoder(\n",
        "    num_tokens = vocabulary,\n",
        "    d = SEQ_LEN,\n",
        "    depth = 10,\n",
        "    heads = HEADS,\n",
        "    hidden_size = 5000,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    use_bert = True\n",
        ").to(device)\n",
        "\n",
        "train_loader_ = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)\n",
        "test_loader_ = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)"
      ],
      "metadata": {
        "id": "GOz3oBuiGkYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "optimizer = torch.optim.Adam(tr_decoder.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epochs = 5\n",
        "# training\n",
        "\n",
        "perplexity_tr_decoder = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, data in enumerate(tqdm.tqdm(train_loader_, desc = 'training')):\n",
        "    tr_decoder.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "\n",
        "    num_seq = 10000 // (SEQ_LEN + 1)\n",
        "    data = data.long().to(device)\n",
        "    for j in range(num_seq):\n",
        "      mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "      seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "\n",
        "      out = tr_decoder(seq)\n",
        "\n",
        "      loss_item = loss(out, labels)\n",
        "      print(f'training loss: {loss_item}', flush = True)\n",
        "      loss_item.backward() \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "  data = None\n",
        "    \n",
        "\n",
        "  if e % EVAL_EVERY == 0:\n",
        "    tr_decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      metric = Perplexity().to(device)\n",
        "      for i, data in enumerate(tqdm.tqdm(test_loader_, desc = 'evaluation')):\n",
        "        num_seq = 10000 // (SEQ_LEN + 1)\n",
        "        data = data.long().to(device)\n",
        "\n",
        "        for j in range(num_seq):\n",
        "          mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "          seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "\n",
        "          out = tr_decoder(seq)\n",
        "\n",
        "          test_loss = loss(out, labels)\n",
        "          metric(out.transpose(1, 2), labels)\n",
        "          print(f'test loss: {test_loss}', flush = True)\n",
        "\n",
        "      perplexity = metric.compute()\n",
        "      perplexity_tr_decoder.append(perplexity)\n",
        "      print(f'perplexity: {perplexity}', flush = True)\n",
        "\n",
        "  data = None\n",
        "  if e % CHECKPOINT == 0:\n",
        "    torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, 'model_optimizer.pt')\n",
        "  \"\"\"\n",
        "  #Lorenzo\n",
        "  with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity_moreNN.npy', 'wb') as f:\n",
        "    np.save(f, np.array(perplexity_list))\n",
        "  \"\"\"\n",
        "\n",
        "plt.plot(perplexity_list, label = \"Memorizing Transformer Perplexity Plot\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "outputId": "441896f5-0245-403a-d264-eaf7c8de7b7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqKuP2z1BeFI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/60 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 10.613636016845703\n",
            "training loss: 10.138771057128906\n",
            "training loss: 9.531482696533203\n",
            "training loss: 9.290334701538086\n",
            "training loss: 9.037982940673828\n",
            "training loss: 8.964811325073242\n",
            "training loss: 8.834417343139648\n",
            "training loss: 8.868087768554688\n",
            "training loss: 8.449191093444824\n",
            "training loss: 8.274097442626953\n",
            "training loss: 8.287134170532227\n",
            "training loss: 8.253252029418945\n",
            "training loss: 8.065546989440918\n",
            "training loss: 7.983259201049805\n",
            "training loss: 7.921478748321533\n",
            "training loss: 7.658079624176025\n",
            "training loss: 7.6776123046875\n",
            "training loss: 7.544704437255859\n",
            "training loss: 7.428136825561523\n",
            "training loss: 7.556718826293945\n",
            "training loss: 7.667337894439697\n",
            "training loss: 7.271917819976807\n",
            "training loss: 7.241058826446533\n",
            "training loss: 7.298427581787109\n",
            "training loss: 7.0697197914123535\n",
            "training loss: 7.1090803146362305\n",
            "training loss: 7.217362403869629\n",
            "training loss: 6.955743789672852\n",
            "training loss: 6.869659900665283\n",
            "training loss: 6.926031112670898\n",
            "training loss: 6.790748596191406\n",
            "training loss: 6.982842922210693\n",
            "training loss: 6.833795547485352\n",
            "training loss: 6.853605270385742\n",
            "training loss: 6.635425567626953\n",
            "training loss: 6.885104179382324\n",
            "training loss: 6.722187519073486\n",
            "training loss: 6.493778705596924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 1/60 [00:43<42:23, 43.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.084143161773682\n",
            "training loss: 7.394591331481934\n",
            "training loss: 7.657687187194824\n",
            "training loss: 7.305431842803955\n",
            "training loss: 7.273122787475586\n",
            "training loss: 7.156654357910156\n",
            "training loss: 7.343154430389404\n",
            "training loss: 6.991386413574219\n",
            "training loss: 7.358992099761963\n",
            "training loss: 7.178823471069336\n",
            "training loss: 7.169069766998291\n",
            "training loss: 6.862148761749268\n",
            "training loss: 7.171343803405762\n",
            "training loss: 7.3018083572387695\n",
            "training loss: 7.156015872955322\n",
            "training loss: 6.985560417175293\n",
            "training loss: 7.023008823394775\n",
            "training loss: 7.0046234130859375\n",
            "training loss: 6.907008647918701\n",
            "training loss: 7.088797569274902\n",
            "training loss: 7.021082878112793\n",
            "training loss: 7.007051467895508\n",
            "training loss: 6.970407009124756\n",
            "training loss: 7.39532995223999\n",
            "training loss: 7.165580749511719\n",
            "training loss: 7.112638473510742\n",
            "training loss: 7.049008369445801\n",
            "training loss: 7.1853437423706055\n",
            "training loss: 6.966651916503906\n",
            "training loss: 7.035217761993408\n",
            "training loss: 6.657567024230957\n",
            "training loss: 6.909394264221191\n",
            "training loss: 6.913949966430664\n",
            "training loss: 6.992056369781494\n",
            "training loss: 7.106975555419922\n",
            "training loss: 6.712094306945801\n",
            "training loss: 6.870136737823486\n",
            "training loss: 7.222833633422852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   3%|▎         | 2/60 [01:21<38:46, 40.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.078865051269531\n",
            "training loss: 7.060799598693848\n",
            "training loss: 7.193464279174805\n",
            "training loss: 7.1889238357543945\n",
            "training loss: 7.151512145996094\n",
            "training loss: 7.017027378082275\n",
            "training loss: 7.268648147583008\n",
            "training loss: 7.3830413818359375\n",
            "training loss: 7.186588764190674\n",
            "training loss: 6.901195526123047\n",
            "training loss: 6.994412422180176\n",
            "training loss: 7.237492561340332\n",
            "training loss: 7.301083564758301\n",
            "training loss: 7.216693878173828\n",
            "training loss: 6.944808006286621\n",
            "training loss: 6.840197563171387\n",
            "training loss: 7.095056533813477\n",
            "training loss: 7.078004837036133\n",
            "training loss: 7.063430309295654\n",
            "training loss: 6.90178108215332\n",
            "training loss: 7.1105828285217285\n",
            "training loss: 6.874146461486816\n",
            "training loss: 7.080276012420654\n",
            "training loss: 6.863290786743164\n",
            "training loss: 6.918060302734375\n",
            "training loss: 6.7738518714904785\n",
            "training loss: 7.038888931274414\n",
            "training loss: 6.742169380187988\n",
            "training loss: 6.645608425140381\n",
            "training loss: 6.800784111022949\n",
            "training loss: 6.951653480529785\n",
            "training loss: 7.008520126342773\n",
            "training loss: 7.134580612182617\n",
            "training loss: 6.83278226852417\n",
            "training loss: 6.964061737060547\n",
            "training loss: 6.809957027435303\n",
            "training loss: 6.967086315155029\n",
            "training loss: 6.872430801391602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   5%|▌         | 3/60 [01:59<37:10, 39.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.825892448425293\n",
            "training loss: 7.082074165344238\n",
            "training loss: 7.292474746704102\n",
            "training loss: 7.1592488288879395\n",
            "training loss: 7.309303283691406\n",
            "training loss: 7.078857421875\n",
            "training loss: 7.298160552978516\n",
            "training loss: 7.097609519958496\n",
            "training loss: 6.8863115310668945\n",
            "training loss: 6.977092742919922\n",
            "training loss: 6.86734676361084\n",
            "training loss: 6.951988220214844\n",
            "training loss: 7.229460716247559\n",
            "training loss: 6.816893577575684\n",
            "training loss: 6.758791923522949\n",
            "training loss: 6.830312252044678\n",
            "training loss: 6.823642730712891\n",
            "training loss: 7.093572616577148\n",
            "training loss: 6.873366355895996\n",
            "training loss: 6.90254020690918\n",
            "training loss: 6.862163543701172\n",
            "training loss: 6.987902641296387\n",
            "training loss: 7.076012134552002\n",
            "training loss: 6.570353031158447\n",
            "training loss: 7.0134501457214355\n",
            "training loss: 6.997167110443115\n",
            "training loss: 7.096169471740723\n",
            "training loss: 6.886145114898682\n",
            "training loss: 6.836856842041016\n",
            "training loss: 7.074459552764893\n",
            "training loss: 6.793364524841309\n",
            "training loss: 6.907717704772949\n",
            "training loss: 6.888669013977051\n",
            "training loss: 6.943101406097412\n",
            "training loss: 7.004215240478516\n",
            "training loss: 6.881417274475098\n",
            "training loss: 6.775006294250488\n",
            "training loss: 6.7852783203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   7%|▋         | 4/60 [02:37<36:06, 38.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.272273540496826\n",
            "training loss: 6.745721817016602\n",
            "training loss: 6.89892578125\n",
            "training loss: 7.012731552124023\n",
            "training loss: 6.670243263244629\n",
            "training loss: 6.968606948852539\n",
            "training loss: 7.081724643707275\n",
            "training loss: 6.848888397216797\n",
            "training loss: 6.632232189178467\n",
            "training loss: 7.32260799407959\n",
            "training loss: 7.2416157722473145\n",
            "training loss: 7.380533218383789\n",
            "training loss: 7.190946102142334\n",
            "training loss: 7.096787929534912\n",
            "training loss: 7.04904842376709\n",
            "training loss: 7.074018478393555\n",
            "training loss: 7.16287899017334\n",
            "training loss: 7.128839015960693\n",
            "training loss: 7.237271308898926\n",
            "training loss: 7.105903625488281\n",
            "training loss: 7.353597640991211\n",
            "training loss: 7.130156993865967\n",
            "training loss: 7.231752395629883\n",
            "training loss: 6.910612106323242\n",
            "training loss: 6.913682460784912\n",
            "training loss: 6.591948509216309\n",
            "training loss: 6.972830772399902\n",
            "training loss: 7.076026916503906\n",
            "training loss: 7.274300575256348\n",
            "training loss: 7.024515151977539\n",
            "training loss: 7.125507354736328\n",
            "training loss: 7.2549052238464355\n",
            "training loss: 6.9342756271362305\n",
            "training loss: 6.719179153442383\n",
            "training loss: 6.894460678100586\n",
            "training loss: 6.704289436340332\n",
            "training loss: 6.454273223876953\n",
            "training loss: 6.887801647186279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   8%|▊         | 5/60 [03:14<35:08, 38.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.933565139770508\n",
            "training loss: 6.95356559753418\n",
            "training loss: 7.490050315856934\n",
            "training loss: 7.350604057312012\n",
            "training loss: 7.142333030700684\n",
            "training loss: 6.6896209716796875\n",
            "training loss: 6.899460792541504\n",
            "training loss: 6.928689956665039\n",
            "training loss: 7.198765277862549\n",
            "training loss: 7.024230003356934\n",
            "training loss: 7.024910926818848\n",
            "training loss: 7.0703558921813965\n",
            "training loss: 6.751494884490967\n",
            "training loss: 6.930469036102295\n",
            "training loss: 6.959268569946289\n",
            "training loss: 6.890024185180664\n",
            "training loss: 6.736353874206543\n",
            "training loss: 6.629390716552734\n",
            "training loss: 6.485001564025879\n",
            "training loss: 6.58930778503418\n",
            "training loss: 6.82376766204834\n",
            "training loss: 6.905578136444092\n",
            "training loss: 6.852627754211426\n",
            "training loss: 6.908886909484863\n",
            "training loss: 6.94565486907959\n",
            "training loss: 6.753915786743164\n",
            "training loss: 6.804279327392578\n",
            "training loss: 6.7591118812561035\n",
            "training loss: 6.7900919914245605\n",
            "training loss: 6.955374240875244\n",
            "training loss: 7.13016414642334\n",
            "training loss: 7.027703285217285\n",
            "training loss: 6.706336498260498\n",
            "training loss: 6.769749164581299\n",
            "training loss: 6.848484516143799\n",
            "training loss: 6.73972225189209\n",
            "training loss: 6.822986125946045\n",
            "training loss: 6.663694381713867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  10%|█         | 6/60 [03:52<34:23, 38.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.276799201965332\n",
            "training loss: 7.325370788574219\n",
            "training loss: 7.2664875984191895\n",
            "training loss: 7.210224628448486\n",
            "training loss: 6.998112201690674\n",
            "training loss: 7.302657604217529\n",
            "training loss: 7.2073283195495605\n",
            "training loss: 7.117082118988037\n",
            "training loss: 7.020355224609375\n",
            "training loss: 6.927463531494141\n",
            "training loss: 7.00570011138916\n",
            "training loss: 6.733159065246582\n",
            "training loss: 6.8763251304626465\n",
            "training loss: 7.209510803222656\n",
            "training loss: 7.254376411437988\n",
            "training loss: 7.037599563598633\n",
            "training loss: 6.713640213012695\n",
            "training loss: 7.083306789398193\n",
            "training loss: 7.19444465637207\n",
            "training loss: 7.101696968078613\n",
            "training loss: 6.839553356170654\n",
            "training loss: 6.886813640594482\n",
            "training loss: 7.18438196182251\n",
            "training loss: 6.962347984313965\n",
            "training loss: 6.862087726593018\n",
            "training loss: 6.954755783081055\n",
            "training loss: 6.992542743682861\n",
            "training loss: 6.7206807136535645\n",
            "training loss: 7.1658172607421875\n",
            "training loss: 6.856204032897949\n",
            "training loss: 6.917021751403809\n",
            "training loss: 7.016058444976807\n",
            "training loss: 7.261839389801025\n",
            "training loss: 6.951358795166016\n",
            "training loss: 6.807687759399414\n",
            "training loss: 7.056518077850342\n",
            "training loss: 6.73771858215332\n",
            "training loss: 6.693604469299316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  12%|█▏        | 7/60 [04:31<33:58, 38.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.122234344482422\n",
            "training loss: 7.066431999206543\n",
            "training loss: 7.157933235168457\n",
            "training loss: 7.136859893798828\n",
            "training loss: 7.191762447357178\n",
            "training loss: 7.2710113525390625\n",
            "training loss: 7.101606845855713\n",
            "training loss: 6.848149299621582\n",
            "training loss: 6.92459774017334\n",
            "training loss: 6.726385116577148\n",
            "training loss: 6.677337646484375\n",
            "training loss: 6.701813697814941\n",
            "training loss: 6.9286370277404785\n",
            "training loss: 6.641932487487793\n",
            "training loss: 6.70519495010376\n",
            "training loss: 6.675601005554199\n",
            "training loss: 6.6327667236328125\n",
            "training loss: 6.768328666687012\n",
            "training loss: 6.411677360534668\n",
            "training loss: 6.753479480743408\n",
            "training loss: 6.725071907043457\n",
            "training loss: 6.826328754425049\n",
            "training loss: 6.859999179840088\n",
            "training loss: 6.804537296295166\n",
            "training loss: 6.64241886138916\n",
            "training loss: 7.016724586486816\n",
            "training loss: 6.624906539916992\n",
            "training loss: 7.011223793029785\n",
            "training loss: 6.836832046508789\n",
            "training loss: 6.929080963134766\n",
            "training loss: 6.635353088378906\n",
            "training loss: 6.999173164367676\n",
            "training loss: 7.078254699707031\n",
            "training loss: 6.795969009399414\n",
            "training loss: 6.811151027679443\n",
            "training loss: 6.750296592712402\n",
            "training loss: 6.591119766235352\n",
            "training loss: 6.810242176055908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  13%|█▎        | 8/60 [05:09<33:11, 38.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.230232238769531\n",
            "training loss: 7.401898384094238\n",
            "training loss: 7.140575408935547\n",
            "training loss: 7.138494491577148\n",
            "training loss: 6.938142776489258\n",
            "training loss: 6.995104789733887\n",
            "training loss: 6.7921576499938965\n",
            "training loss: 7.038303375244141\n",
            "training loss: 7.236082077026367\n",
            "training loss: 7.155353546142578\n",
            "training loss: 7.201041221618652\n",
            "training loss: 7.012529373168945\n",
            "training loss: 6.8622894287109375\n",
            "training loss: 7.025600910186768\n",
            "training loss: 7.028053283691406\n",
            "training loss: 7.2305731773376465\n",
            "training loss: 6.869088649749756\n",
            "training loss: 6.697502136230469\n",
            "training loss: 6.960309982299805\n",
            "training loss: 6.909814834594727\n",
            "training loss: 7.0569167137146\n",
            "training loss: 6.75325870513916\n",
            "training loss: 6.869870185852051\n",
            "training loss: 6.91953182220459\n",
            "training loss: 7.024238586425781\n",
            "training loss: 6.9305009841918945\n",
            "training loss: 6.83516788482666\n",
            "training loss: 7.134149551391602\n",
            "training loss: 7.104081630706787\n",
            "training loss: 6.922067642211914\n",
            "training loss: 6.953916549682617\n",
            "training loss: 6.959024906158447\n",
            "training loss: 6.953654766082764\n",
            "training loss: 6.868034362792969\n",
            "training loss: 6.832767486572266\n",
            "training loss: 7.0704264640808105\n",
            "training loss: 6.908880233764648\n",
            "training loss: 7.077544212341309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  15%|█▌        | 9/60 [05:47<32:25, 38.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.1218695640563965\n",
            "training loss: 7.287310600280762\n",
            "training loss: 6.878499507904053\n",
            "training loss: 6.700962543487549\n",
            "training loss: 6.767308235168457\n",
            "training loss: 7.087644577026367\n",
            "training loss: 6.962769508361816\n",
            "training loss: 6.950863838195801\n",
            "training loss: 6.883501052856445\n",
            "training loss: 6.631229400634766\n",
            "training loss: 6.893355369567871\n",
            "training loss: 6.880991458892822\n",
            "training loss: 6.520962238311768\n",
            "training loss: 6.412832260131836\n",
            "training loss: 6.1856465339660645\n",
            "training loss: 6.400476455688477\n",
            "training loss: 6.707627296447754\n",
            "training loss: 6.652065753936768\n",
            "training loss: 6.940911293029785\n",
            "training loss: 7.120311260223389\n",
            "training loss: 7.014995574951172\n",
            "training loss: 7.059335231781006\n",
            "training loss: 7.264331340789795\n",
            "training loss: 6.934560775756836\n",
            "training loss: 7.024728298187256\n",
            "training loss: 6.932506561279297\n",
            "training loss: 7.235857009887695\n",
            "training loss: 7.225761890411377\n",
            "training loss: 7.209053039550781\n",
            "training loss: 6.917325019836426\n",
            "training loss: 6.812918663024902\n",
            "training loss: 6.9841084480285645\n",
            "training loss: 6.75022029876709\n",
            "training loss: 6.931984901428223\n",
            "training loss: 6.844051837921143\n",
            "training loss: 6.866703033447266\n",
            "training loss: 6.984297275543213\n",
            "training loss: 6.817999839782715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  17%|█▋        | 10/60 [06:25<31:41, 38.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.091666221618652\n",
            "training loss: 7.047573566436768\n",
            "training loss: 7.173423767089844\n",
            "training loss: 7.077314376831055\n",
            "training loss: 7.258548736572266\n",
            "training loss: 6.962238311767578\n",
            "training loss: 6.981310844421387\n",
            "training loss: 7.213936805725098\n",
            "training loss: 6.825651168823242\n",
            "training loss: 7.214226722717285\n",
            "training loss: 6.944949150085449\n",
            "training loss: 7.251262664794922\n",
            "training loss: 7.005843162536621\n",
            "training loss: 6.876096725463867\n",
            "training loss: 7.114564895629883\n",
            "training loss: 6.91652774810791\n",
            "training loss: 6.842278480529785\n",
            "training loss: 6.742606163024902\n",
            "training loss: 6.757969856262207\n",
            "training loss: 6.735848426818848\n",
            "training loss: 6.88299560546875\n",
            "training loss: 6.998140811920166\n",
            "training loss: 7.003684997558594\n",
            "training loss: 7.028613090515137\n",
            "training loss: 7.051494598388672\n",
            "training loss: 7.02492618560791\n",
            "training loss: 6.903160572052002\n",
            "training loss: 6.947887897491455\n",
            "training loss: 6.965079307556152\n",
            "training loss: 6.9401397705078125\n",
            "training loss: 6.925153732299805\n",
            "training loss: 6.715936660766602\n",
            "training loss: 6.9215874671936035\n",
            "training loss: 6.94352388381958\n",
            "training loss: 6.702873229980469\n",
            "training loss: 6.629477500915527\n",
            "training loss: 6.927632808685303\n",
            "training loss: 6.773905277252197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  18%|█▊        | 11/60 [07:03<31:07, 38.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.955634593963623\n",
            "training loss: 7.1803388595581055\n",
            "training loss: 7.072729110717773\n",
            "training loss: 6.7278900146484375\n",
            "training loss: 7.017607688903809\n",
            "training loss: 7.029693126678467\n",
            "training loss: 6.882510185241699\n",
            "training loss: 6.911130428314209\n",
            "training loss: 6.834501266479492\n",
            "training loss: 6.91484260559082\n",
            "training loss: 7.068324089050293\n",
            "training loss: 6.8723859786987305\n",
            "training loss: 6.872129440307617\n",
            "training loss: 6.753278732299805\n",
            "training loss: 6.837377548217773\n",
            "training loss: 6.813639163970947\n",
            "training loss: 6.654955863952637\n",
            "training loss: 6.812917709350586\n",
            "training loss: 6.561501502990723\n",
            "training loss: 6.757495880126953\n",
            "training loss: 6.883272171020508\n",
            "training loss: 6.950472831726074\n",
            "training loss: 6.933416366577148\n",
            "training loss: 6.996332168579102\n",
            "training loss: 7.05186653137207\n",
            "training loss: 6.891727447509766\n",
            "training loss: 6.849225044250488\n",
            "training loss: 6.860954284667969\n",
            "training loss: 7.03660774230957\n",
            "training loss: 6.77847957611084\n",
            "training loss: 6.768409729003906\n",
            "training loss: 6.966142654418945\n",
            "training loss: 7.1207780838012695\n",
            "training loss: 6.799901962280273\n",
            "training loss: 7.1670308113098145\n",
            "training loss: 6.844918251037598\n",
            "training loss: 6.6616668701171875\n",
            "training loss: 6.580121040344238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  20%|██        | 12/60 [07:43<30:52, 38.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.381464004516602\n",
            "training loss: 6.8945512771606445\n",
            "training loss: 6.690036773681641\n",
            "training loss: 7.007118225097656\n",
            "training loss: 7.031467437744141\n",
            "training loss: 6.4006876945495605\n",
            "training loss: 6.732710838317871\n",
            "training loss: 6.964254379272461\n",
            "training loss: 7.1317620277404785\n",
            "training loss: 6.971085548400879\n",
            "training loss: 6.948525428771973\n",
            "training loss: 7.107857704162598\n",
            "training loss: 6.965453147888184\n",
            "training loss: 6.911659240722656\n",
            "training loss: 6.920713424682617\n",
            "training loss: 6.905270576477051\n",
            "training loss: 6.550041198730469\n",
            "training loss: 6.871432304382324\n",
            "training loss: 6.811529159545898\n",
            "training loss: 6.8191351890563965\n",
            "training loss: 7.012104034423828\n",
            "training loss: 7.035736560821533\n",
            "training loss: 6.879207611083984\n",
            "training loss: 6.783276557922363\n",
            "training loss: 7.057758331298828\n",
            "training loss: 6.896347999572754\n",
            "training loss: 6.741536617279053\n",
            "training loss: 6.757274627685547\n",
            "training loss: 6.641307830810547\n",
            "training loss: 6.933543682098389\n",
            "training loss: 6.758333206176758\n",
            "training loss: 6.855603218078613\n",
            "training loss: 6.873900890350342\n",
            "training loss: 6.679929256439209\n",
            "training loss: 6.876307010650635\n",
            "training loss: 6.698517322540283\n",
            "training loss: 6.748020648956299\n",
            "training loss: 6.635705947875977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  22%|██▏       | 13/60 [08:21<30:03, 38.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.13232946395874\n",
            "training loss: 7.105768203735352\n",
            "training loss: 7.083372592926025\n",
            "training loss: 6.994720458984375\n",
            "training loss: 6.975953578948975\n",
            "training loss: 7.074357032775879\n",
            "training loss: 6.947361946105957\n",
            "training loss: 6.68681526184082\n",
            "training loss: 6.623019218444824\n",
            "training loss: 6.9031572341918945\n",
            "training loss: 6.839829444885254\n",
            "training loss: 6.917774200439453\n",
            "training loss: 6.843218803405762\n",
            "training loss: 7.1470441818237305\n",
            "training loss: 6.910722255706787\n",
            "training loss: 6.870024681091309\n",
            "training loss: 6.83977746963501\n",
            "training loss: 7.072990417480469\n",
            "training loss: 7.13715934753418\n",
            "training loss: 6.692280292510986\n",
            "training loss: 6.843554496765137\n",
            "training loss: 6.922203063964844\n",
            "training loss: 6.964837551116943\n",
            "training loss: 6.9279608726501465\n",
            "training loss: 6.788494110107422\n",
            "training loss: 6.7820940017700195\n",
            "training loss: 6.992270469665527\n",
            "training loss: 6.723076820373535\n",
            "training loss: 6.865383625030518\n",
            "training loss: 6.736015319824219\n",
            "training loss: 7.052222728729248\n",
            "training loss: 7.057701587677002\n",
            "training loss: 6.596090793609619\n",
            "training loss: 6.750875473022461\n",
            "training loss: 6.840660095214844\n",
            "training loss: 6.770153999328613\n",
            "training loss: 7.080509185791016\n",
            "training loss: 7.255039691925049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  23%|██▎       | 14/60 [08:59<29:18, 38.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.244021892547607\n",
            "training loss: 7.189414024353027\n",
            "training loss: 7.168315410614014\n",
            "training loss: 7.274123191833496\n",
            "training loss: 7.257654666900635\n",
            "training loss: 7.05896520614624\n",
            "training loss: 7.251628875732422\n",
            "training loss: 7.004082679748535\n",
            "training loss: 7.015024185180664\n",
            "training loss: 7.156121730804443\n",
            "training loss: 7.050822734832764\n",
            "training loss: 6.989840030670166\n",
            "training loss: 6.946094512939453\n",
            "training loss: 6.726750373840332\n",
            "training loss: 6.73920202255249\n",
            "training loss: 6.752025604248047\n",
            "training loss: 6.8838911056518555\n",
            "training loss: 7.047333717346191\n",
            "training loss: 7.111050605773926\n",
            "training loss: 6.919071197509766\n",
            "training loss: 7.135094165802002\n",
            "training loss: 7.007986068725586\n",
            "training loss: 6.885394096374512\n",
            "training loss: 6.9074177742004395\n",
            "training loss: 6.933279991149902\n",
            "training loss: 6.938861846923828\n",
            "training loss: 6.890046119689941\n",
            "training loss: 7.019357204437256\n",
            "training loss: 6.989985466003418\n",
            "training loss: 6.676540374755859\n",
            "training loss: 6.88218879699707\n",
            "training loss: 6.852741718292236\n",
            "training loss: 6.849715232849121\n",
            "training loss: 6.935612678527832\n",
            "training loss: 6.964483737945557\n",
            "training loss: 6.8859052658081055\n",
            "training loss: 6.7805023193359375\n",
            "training loss: 6.714471340179443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  25%|██▌       | 15/60 [09:37<28:39, 38.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.993119716644287\n",
            "training loss: 6.784221649169922\n",
            "training loss: 7.126415729522705\n",
            "training loss: 7.195370674133301\n",
            "training loss: 7.15617561340332\n",
            "training loss: 7.264147758483887\n",
            "training loss: 7.056883335113525\n",
            "training loss: 7.247528553009033\n",
            "training loss: 7.2397332191467285\n",
            "training loss: 7.222484111785889\n",
            "training loss: 7.2690839767456055\n",
            "training loss: 7.034571647644043\n",
            "training loss: 7.0977630615234375\n",
            "training loss: 6.7696380615234375\n",
            "training loss: 7.01775598526001\n",
            "training loss: 6.995601654052734\n",
            "training loss: 6.75364875793457\n",
            "training loss: 6.914153099060059\n",
            "training loss: 7.088861465454102\n",
            "training loss: 6.797702789306641\n",
            "training loss: 6.912065505981445\n",
            "training loss: 6.912803649902344\n",
            "training loss: 7.174559116363525\n",
            "training loss: 7.117282390594482\n",
            "training loss: 7.095465660095215\n",
            "training loss: 6.541790008544922\n",
            "training loss: 6.842745780944824\n",
            "training loss: 7.1712493896484375\n",
            "training loss: 7.127444267272949\n",
            "training loss: 6.603798866271973\n",
            "training loss: 6.898218631744385\n",
            "training loss: 6.94410514831543\n",
            "training loss: 6.940148830413818\n",
            "training loss: 6.782498359680176\n",
            "training loss: 6.7265706062316895\n",
            "training loss: 6.59981107711792\n",
            "training loss: 6.684084892272949\n",
            "training loss: 7.019142150878906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  27%|██▋       | 16/60 [10:15<28:00, 38.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.995940208435059\n",
            "training loss: 7.082773208618164\n",
            "training loss: 7.305164337158203\n",
            "training loss: 7.161197662353516\n",
            "training loss: 7.269604682922363\n",
            "training loss: 7.057260990142822\n",
            "training loss: 7.041745185852051\n",
            "training loss: 6.9116129875183105\n",
            "training loss: 7.012732028961182\n",
            "training loss: 6.924648761749268\n",
            "training loss: 6.9260783195495605\n",
            "training loss: 7.066951274871826\n",
            "training loss: 6.945458889007568\n",
            "training loss: 7.137029647827148\n",
            "training loss: 6.992270469665527\n",
            "training loss: 7.037405014038086\n",
            "training loss: 7.032413005828857\n",
            "training loss: 7.048299312591553\n",
            "training loss: 7.010881423950195\n",
            "training loss: 6.879522323608398\n",
            "training loss: 6.845816612243652\n",
            "training loss: 7.069371223449707\n",
            "training loss: 7.0687761306762695\n",
            "training loss: 7.199522018432617\n",
            "training loss: 7.182771682739258\n",
            "training loss: 7.122307777404785\n",
            "training loss: 6.9342498779296875\n",
            "training loss: 6.838376522064209\n",
            "training loss: 6.903219223022461\n",
            "training loss: 6.763131141662598\n",
            "training loss: 6.545318603515625\n",
            "training loss: 6.8499908447265625\n",
            "training loss: 6.913968086242676\n",
            "training loss: 6.875759124755859\n",
            "training loss: 6.98960018157959\n",
            "training loss: 6.807761192321777\n",
            "training loss: 6.930976390838623\n",
            "training loss: 6.930872917175293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  28%|██▊       | 17/60 [10:58<28:21, 39.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.12001895904541\n",
            "training loss: 7.266022682189941\n",
            "training loss: 7.047516822814941\n",
            "training loss: 7.0406389236450195\n",
            "training loss: 6.897774696350098\n",
            "training loss: 6.815616607666016\n",
            "training loss: 7.008540153503418\n",
            "training loss: 6.860357284545898\n",
            "training loss: 6.795193672180176\n",
            "training loss: 6.812383651733398\n",
            "training loss: 6.7417778968811035\n",
            "training loss: 6.879680633544922\n",
            "training loss: 6.854953765869141\n",
            "training loss: 6.882869720458984\n",
            "training loss: 7.134745121002197\n",
            "training loss: 7.05328893661499\n",
            "training loss: 7.036424160003662\n",
            "training loss: 6.804134368896484\n",
            "training loss: 6.966885566711426\n",
            "training loss: 7.036844253540039\n",
            "training loss: 6.986448764801025\n",
            "training loss: 6.684329032897949\n",
            "training loss: 6.9523396492004395\n",
            "training loss: 7.10272216796875\n",
            "training loss: 6.87905216217041\n",
            "training loss: 6.9057159423828125\n",
            "training loss: 7.012053489685059\n",
            "training loss: 6.9983015060424805\n",
            "training loss: 6.762081623077393\n",
            "training loss: 6.548131942749023\n",
            "training loss: 6.919318675994873\n",
            "training loss: 6.934061050415039\n",
            "training loss: 6.980881214141846\n",
            "training loss: 6.737183570861816\n",
            "training loss: 6.74821662902832\n",
            "training loss: 6.756376266479492\n",
            "training loss: 6.902407169342041\n",
            "training loss: 6.70389461517334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  30%|███       | 18/60 [11:41<28:27, 40.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.261334419250488\n",
            "training loss: 7.118507385253906\n",
            "training loss: 7.239687919616699\n",
            "training loss: 6.87838888168335\n",
            "training loss: 7.214639186859131\n",
            "training loss: 7.240421295166016\n",
            "training loss: 7.151341438293457\n",
            "training loss: 7.2515363693237305\n",
            "training loss: 6.784528732299805\n",
            "training loss: 7.0007476806640625\n",
            "training loss: 7.153294563293457\n",
            "training loss: 6.932985782623291\n",
            "training loss: 7.027744293212891\n",
            "training loss: 6.96490478515625\n",
            "training loss: 7.021378517150879\n",
            "training loss: 6.996851444244385\n",
            "training loss: 7.000884056091309\n",
            "training loss: 6.751984596252441\n",
            "training loss: 7.058529853820801\n",
            "training loss: 7.111053943634033\n",
            "training loss: 7.272870063781738\n",
            "training loss: 7.077937126159668\n",
            "training loss: 7.01859188079834\n",
            "training loss: 6.947611331939697\n",
            "training loss: 6.953092098236084\n",
            "training loss: 6.842789173126221\n",
            "training loss: 6.86737585067749\n",
            "training loss: 6.959402084350586\n",
            "training loss: 6.901716232299805\n",
            "training loss: 6.663630485534668\n",
            "training loss: 6.874181747436523\n",
            "training loss: 6.913818359375\n",
            "training loss: 6.840296268463135\n",
            "training loss: 6.812086582183838\n",
            "training loss: 6.908450126647949\n",
            "training loss: 7.164374351501465\n",
            "training loss: 6.965519905090332\n",
            "training loss: 6.912980556488037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  32%|███▏      | 19/60 [12:19<27:14, 39.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.853694915771484\n",
            "training loss: 7.049633979797363\n",
            "training loss: 7.307528972625732\n",
            "training loss: 7.142012596130371\n",
            "training loss: 7.105103969573975\n",
            "training loss: 7.113703727722168\n",
            "training loss: 7.003873825073242\n",
            "training loss: 6.8922576904296875\n",
            "training loss: 6.9274468421936035\n",
            "training loss: 7.039277076721191\n",
            "training loss: 7.133861541748047\n",
            "training loss: 7.052985668182373\n",
            "training loss: 7.100751876831055\n",
            "training loss: 7.447279930114746\n",
            "training loss: 7.212275505065918\n",
            "training loss: 7.225264072418213\n",
            "training loss: 6.845485210418701\n",
            "training loss: 6.972207069396973\n",
            "training loss: 6.962765693664551\n",
            "training loss: 6.58221960067749\n",
            "training loss: 6.867555618286133\n",
            "training loss: 6.8560638427734375\n",
            "training loss: 7.110095977783203\n",
            "training loss: 6.9389801025390625\n",
            "training loss: 7.145419120788574\n",
            "training loss: 6.809142112731934\n",
            "training loss: 6.9658613204956055\n",
            "training loss: 6.652544021606445\n",
            "training loss: 6.691473007202148\n",
            "training loss: 6.996174335479736\n",
            "training loss: 6.897029399871826\n",
            "training loss: 7.068700790405273\n",
            "training loss: 6.791924476623535\n",
            "training loss: 6.916877746582031\n",
            "training loss: 6.696822166442871\n",
            "training loss: 6.9389753341674805\n",
            "training loss: 6.793879508972168\n",
            "training loss: 6.623954772949219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  33%|███▎      | 20/60 [12:57<26:19, 39.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.920068264007568\n",
            "training loss: 7.2850751876831055\n",
            "training loss: 7.002172470092773\n",
            "training loss: 7.062807083129883\n",
            "training loss: 6.8733649253845215\n",
            "training loss: 6.888821601867676\n",
            "training loss: 6.999100685119629\n",
            "training loss: 7.06151819229126\n",
            "training loss: 6.949859142303467\n",
            "training loss: 7.087446212768555\n",
            "training loss: 7.071084976196289\n",
            "training loss: 7.103525161743164\n",
            "training loss: 7.05394172668457\n",
            "training loss: 6.955443859100342\n",
            "training loss: 6.997477054595947\n",
            "training loss: 6.822092056274414\n",
            "training loss: 6.8947882652282715\n",
            "training loss: 7.095067977905273\n",
            "training loss: 7.008118152618408\n",
            "training loss: 6.844754219055176\n",
            "training loss: 6.74705171585083\n",
            "training loss: 6.781914234161377\n",
            "training loss: 7.0517988204956055\n",
            "training loss: 6.751018524169922\n",
            "training loss: 6.884237289428711\n",
            "training loss: 6.793133735656738\n",
            "training loss: 6.919988632202148\n",
            "training loss: 6.7969970703125\n",
            "training loss: 6.903903484344482\n",
            "training loss: 7.0257768630981445\n",
            "training loss: 6.73630428314209\n",
            "training loss: 6.849456787109375\n",
            "training loss: 6.955581188201904\n",
            "training loss: 6.83829402923584\n",
            "training loss: 6.780490875244141\n",
            "training loss: 6.992141246795654\n",
            "training loss: 6.892579078674316\n",
            "training loss: 6.851374626159668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  35%|███▌      | 21/60 [13:39<26:03, 40.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.129133224487305\n",
            "training loss: 7.05056095123291\n",
            "training loss: 6.834190368652344\n",
            "training loss: 6.841165542602539\n",
            "training loss: 6.942766189575195\n",
            "training loss: 6.994068622589111\n",
            "training loss: 6.782136917114258\n",
            "training loss: 6.922613620758057\n",
            "training loss: 6.55466365814209\n",
            "training loss: 6.720989227294922\n",
            "training loss: 6.8983869552612305\n",
            "training loss: 6.895124435424805\n",
            "training loss: 6.602025032043457\n",
            "training loss: 7.140628337860107\n",
            "training loss: 6.949765205383301\n",
            "training loss: 6.891237735748291\n",
            "training loss: 6.773731708526611\n",
            "training loss: 6.862243175506592\n",
            "training loss: 7.251828670501709\n",
            "training loss: 7.062057971954346\n",
            "training loss: 7.0432233810424805\n",
            "training loss: 7.202770233154297\n",
            "training loss: 7.15321159362793\n",
            "training loss: 7.026019096374512\n",
            "training loss: 6.908143997192383\n",
            "training loss: 6.924454689025879\n",
            "training loss: 6.50697135925293\n",
            "training loss: 6.93831205368042\n",
            "training loss: 6.678504467010498\n",
            "training loss: 6.70719051361084\n",
            "training loss: 6.659867286682129\n",
            "training loss: 6.909845352172852\n",
            "training loss: 6.897231101989746\n",
            "training loss: 6.957583427429199\n",
            "training loss: 6.963893890380859\n",
            "training loss: 7.234585762023926\n",
            "training loss: 6.775700092315674\n",
            "training loss: 6.755329132080078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  37%|███▋      | 22/60 [14:18<25:16, 39.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.210700035095215\n",
            "training loss: 7.280634880065918\n",
            "training loss: 7.1201863288879395\n",
            "training loss: 6.921036243438721\n",
            "training loss: 6.899633407592773\n",
            "training loss: 6.9862518310546875\n",
            "training loss: 6.829773902893066\n",
            "training loss: 6.903101921081543\n",
            "training loss: 6.9680914878845215\n",
            "training loss: 6.660061836242676\n",
            "training loss: 6.790430545806885\n",
            "training loss: 6.796070575714111\n",
            "training loss: 6.892922878265381\n",
            "training loss: 6.853414535522461\n",
            "training loss: 7.020436763763428\n",
            "training loss: 6.913593769073486\n",
            "training loss: 6.700383186340332\n",
            "training loss: 6.890918731689453\n",
            "training loss: 7.216863632202148\n",
            "training loss: 7.251250743865967\n",
            "training loss: 7.029544830322266\n",
            "training loss: 7.122547149658203\n",
            "training loss: 6.744854927062988\n",
            "training loss: 6.936036586761475\n",
            "training loss: 6.73862886428833\n",
            "training loss: 6.958298683166504\n",
            "training loss: 6.93310546875\n",
            "training loss: 7.10394287109375\n",
            "training loss: 6.998194694519043\n",
            "training loss: 6.963395595550537\n",
            "training loss: 6.674705505371094\n",
            "training loss: 6.811498165130615\n",
            "training loss: 6.9069366455078125\n",
            "training loss: 6.8187055587768555\n",
            "training loss: 6.693538188934326\n",
            "training loss: 6.8820343017578125\n",
            "training loss: 6.711319446563721\n",
            "training loss: 6.595837593078613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  38%|███▊      | 23/60 [15:00<24:51, 40.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.967005252838135\n",
            "training loss: 6.981806755065918\n",
            "training loss: 7.071987152099609\n",
            "training loss: 7.023414611816406\n",
            "training loss: 7.019271373748779\n",
            "training loss: 7.0901336669921875\n",
            "training loss: 7.2707061767578125\n",
            "training loss: 6.9417572021484375\n",
            "training loss: 7.117517471313477\n",
            "training loss: 7.102762699127197\n",
            "training loss: 7.119544982910156\n",
            "training loss: 6.947575092315674\n",
            "training loss: 7.181549072265625\n",
            "training loss: 6.944566249847412\n",
            "training loss: 7.056298732757568\n",
            "training loss: 7.154702186584473\n",
            "training loss: 7.208966255187988\n",
            "training loss: 7.180850028991699\n",
            "training loss: 7.126945495605469\n",
            "training loss: 6.683711051940918\n",
            "training loss: 7.014088153839111\n",
            "training loss: 6.9841413497924805\n",
            "training loss: 6.7829999923706055\n",
            "training loss: 6.788902282714844\n",
            "training loss: 7.024994373321533\n",
            "training loss: 6.516168594360352\n",
            "training loss: 7.038945198059082\n",
            "training loss: 7.10408353805542\n",
            "training loss: 6.851431846618652\n",
            "training loss: 6.937643051147461\n",
            "training loss: 6.847699165344238\n",
            "training loss: 6.727448463439941\n",
            "training loss: 6.7528157234191895\n",
            "training loss: 6.761521816253662\n",
            "training loss: 6.73660135269165\n",
            "training loss: 7.157357215881348\n",
            "training loss: 7.122265338897705\n",
            "training loss: 6.884180068969727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  40%|████      | 24/60 [15:42<24:34, 40.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.421243667602539\n",
            "training loss: 7.269808769226074\n",
            "training loss: 7.039865493774414\n",
            "training loss: 7.058836936950684\n",
            "training loss: 7.00519323348999\n",
            "training loss: 7.070455074310303\n",
            "training loss: 6.850800037384033\n",
            "training loss: 6.832045078277588\n",
            "training loss: 6.956993103027344\n",
            "training loss: 7.138591766357422\n",
            "training loss: 6.7815093994140625\n",
            "training loss: 6.771083831787109\n",
            "training loss: 6.83294677734375\n",
            "training loss: 6.774871826171875\n",
            "training loss: 6.943699359893799\n",
            "training loss: 6.9907989501953125\n",
            "training loss: 6.752702713012695\n",
            "training loss: 6.59585428237915\n",
            "training loss: 6.6158857345581055\n",
            "training loss: 6.767922401428223\n",
            "training loss: 6.972226142883301\n",
            "training loss: 6.731522560119629\n",
            "training loss: 6.804130554199219\n",
            "training loss: 6.740606784820557\n",
            "training loss: 6.673515319824219\n",
            "training loss: 6.698068141937256\n",
            "training loss: 6.814960479736328\n",
            "training loss: 6.9288554191589355\n",
            "training loss: 6.787388801574707\n",
            "training loss: 6.817103862762451\n",
            "training loss: 6.733172416687012\n",
            "training loss: 6.762621879577637\n",
            "training loss: 6.844867706298828\n",
            "training loss: 6.950913906097412\n",
            "training loss: 6.702458381652832\n",
            "training loss: 6.510937690734863\n",
            "training loss: 6.6945648193359375\n",
            "training loss: 6.820845603942871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  42%|████▏     | 25/60 [16:24<24:02, 41.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.401314735412598\n",
            "training loss: 7.368028163909912\n",
            "training loss: 7.219272613525391\n",
            "training loss: 7.171321868896484\n",
            "training loss: 7.064629554748535\n",
            "training loss: 7.234758377075195\n",
            "training loss: 7.095154285430908\n",
            "training loss: 7.045161724090576\n",
            "training loss: 7.030550956726074\n",
            "training loss: 6.931060314178467\n",
            "training loss: 7.068812370300293\n",
            "training loss: 6.851714134216309\n",
            "training loss: 7.0809831619262695\n",
            "training loss: 6.873610496520996\n",
            "training loss: 7.03376579284668\n",
            "training loss: 7.032923221588135\n",
            "training loss: 7.061609268188477\n",
            "training loss: 7.033758640289307\n",
            "training loss: 6.880650520324707\n",
            "training loss: 7.145517826080322\n",
            "training loss: 6.830728530883789\n",
            "training loss: 6.733518123626709\n",
            "training loss: 6.863198757171631\n",
            "training loss: 6.734868049621582\n",
            "training loss: 6.614126205444336\n",
            "training loss: 6.886929512023926\n",
            "training loss: 6.914676666259766\n",
            "training loss: 6.62677001953125\n",
            "training loss: 6.955503940582275\n",
            "training loss: 6.792917251586914\n",
            "training loss: 6.730862617492676\n",
            "training loss: 6.849893569946289\n",
            "training loss: 6.804025173187256\n",
            "training loss: 6.905571937561035\n",
            "training loss: 7.019976615905762\n",
            "training loss: 6.826420307159424\n",
            "training loss: 6.701595783233643\n",
            "training loss: 6.629143238067627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  43%|████▎     | 26/60 [17:04<23:13, 40.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.962173938751221\n",
            "training loss: 6.852904796600342\n",
            "training loss: 6.738122940063477\n",
            "training loss: 6.8200602531433105\n",
            "training loss: 6.705994129180908\n",
            "training loss: 6.872243404388428\n",
            "training loss: 6.901106834411621\n",
            "training loss: 7.0039191246032715\n",
            "training loss: 7.20576810836792\n",
            "training loss: 7.1443915367126465\n",
            "training loss: 6.869661808013916\n",
            "training loss: 7.017078399658203\n",
            "training loss: 6.6072540283203125\n",
            "training loss: 6.683966636657715\n",
            "training loss: 7.058378219604492\n",
            "training loss: 6.935709476470947\n",
            "training loss: 6.906546592712402\n",
            "training loss: 6.825387954711914\n",
            "training loss: 6.871500015258789\n",
            "training loss: 6.818963050842285\n",
            "training loss: 6.7365875244140625\n",
            "training loss: 6.795596599578857\n",
            "training loss: 6.664106845855713\n",
            "training loss: 7.020573139190674\n",
            "training loss: 6.676201820373535\n",
            "training loss: 6.721006393432617\n",
            "training loss: 6.7430596351623535\n",
            "training loss: 6.622585773468018\n",
            "training loss: 6.872058868408203\n",
            "training loss: 6.669313430786133\n",
            "training loss: 7.025912284851074\n",
            "training loss: 7.193481922149658\n",
            "training loss: 7.0010480880737305\n",
            "training loss: 6.651986122131348\n",
            "training loss: 6.8897905349731445\n",
            "training loss: 6.821523666381836\n",
            "training loss: 6.855202674865723\n",
            "training loss: 6.761392593383789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  45%|████▌     | 27/60 [17:44<22:23, 40.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.139708518981934\n",
            "training loss: 7.152618408203125\n",
            "training loss: 6.830611228942871\n",
            "training loss: 7.105809211730957\n",
            "training loss: 7.311925888061523\n",
            "training loss: 7.136909008026123\n",
            "training loss: 7.120815277099609\n",
            "training loss: 6.988974571228027\n",
            "training loss: 7.233615398406982\n",
            "training loss: 7.381376266479492\n",
            "training loss: 7.219614028930664\n",
            "training loss: 7.024274826049805\n",
            "training loss: 7.146202564239502\n",
            "training loss: 7.015267372131348\n",
            "training loss: 6.911043167114258\n",
            "training loss: 6.836211681365967\n",
            "training loss: 6.881999492645264\n",
            "training loss: 7.0062665939331055\n",
            "training loss: 7.0801849365234375\n",
            "training loss: 7.312714099884033\n",
            "training loss: 6.844305515289307\n",
            "training loss: 7.060397148132324\n",
            "training loss: 6.850588798522949\n",
            "training loss: 6.944245338439941\n",
            "training loss: 7.125059604644775\n",
            "training loss: 6.897775650024414\n",
            "training loss: 6.850660800933838\n",
            "training loss: 6.822606086730957\n",
            "training loss: 6.932969570159912\n",
            "training loss: 6.9275054931640625\n",
            "training loss: 6.836608409881592\n",
            "training loss: 7.049716472625732\n",
            "training loss: 6.932374477386475\n",
            "training loss: 6.775815486907959\n",
            "training loss: 6.800465106964111\n",
            "training loss: 6.7634735107421875\n",
            "training loss: 6.823533535003662\n",
            "training loss: 6.740392684936523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  47%|████▋     | 28/60 [18:27<22:02, 41.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.911458492279053\n",
            "training loss: 7.167852401733398\n",
            "training loss: 7.250931739807129\n",
            "training loss: 7.061855316162109\n",
            "training loss: 7.221195220947266\n",
            "training loss: 7.227445602416992\n",
            "training loss: 7.036398410797119\n",
            "training loss: 7.260634422302246\n",
            "training loss: 6.880131244659424\n",
            "training loss: 6.895473003387451\n",
            "training loss: 7.300324440002441\n",
            "training loss: 7.173616409301758\n",
            "training loss: 7.188650608062744\n",
            "training loss: 7.026001453399658\n",
            "training loss: 6.845729827880859\n",
            "training loss: 6.808071613311768\n",
            "training loss: 6.695998191833496\n",
            "training loss: 6.703861236572266\n",
            "training loss: 6.909549713134766\n",
            "training loss: 6.880414009094238\n",
            "training loss: 6.974421501159668\n",
            "training loss: 6.732666492462158\n",
            "training loss: 7.052647113800049\n",
            "training loss: 6.760253429412842\n",
            "training loss: 6.808526992797852\n",
            "training loss: 7.02366304397583\n",
            "training loss: 6.967124938964844\n",
            "training loss: 7.081411361694336\n",
            "training loss: 6.977113723754883\n",
            "training loss: 6.994259357452393\n",
            "training loss: 6.79569673538208\n",
            "training loss: 6.865442752838135\n",
            "training loss: 6.995935440063477\n",
            "training loss: 6.701013565063477\n",
            "training loss: 6.542749404907227\n",
            "training loss: 6.873149871826172\n",
            "training loss: 6.895007610321045\n",
            "training loss: 6.733356952667236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  48%|████▊     | 29/60 [19:10<21:39, 41.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.133114337921143\n",
            "training loss: 7.050425052642822\n",
            "training loss: 7.099512100219727\n",
            "training loss: 6.983795166015625\n",
            "training loss: 7.020831108093262\n",
            "training loss: 6.8739471435546875\n",
            "training loss: 6.9931840896606445\n",
            "training loss: 6.825597763061523\n",
            "training loss: 7.043747901916504\n",
            "training loss: 6.9589409828186035\n",
            "training loss: 6.811433792114258\n",
            "training loss: 6.997710227966309\n",
            "training loss: 6.972165107727051\n",
            "training loss: 7.03231954574585\n",
            "training loss: 6.9914703369140625\n",
            "training loss: 6.828236103057861\n",
            "training loss: 6.806924819946289\n",
            "training loss: 6.800111293792725\n",
            "training loss: 6.93238639831543\n",
            "training loss: 6.97063684463501\n",
            "training loss: 7.021893501281738\n",
            "training loss: 6.8985490798950195\n",
            "training loss: 6.549151420593262\n",
            "training loss: 6.905938148498535\n",
            "training loss: 6.74891996383667\n",
            "training loss: 6.688366889953613\n",
            "training loss: 6.931638717651367\n",
            "training loss: 6.997582912445068\n",
            "training loss: 6.647592067718506\n",
            "training loss: 6.752797603607178\n",
            "training loss: 6.9483842849731445\n",
            "training loss: 6.672937393188477\n",
            "training loss: 6.880492687225342\n",
            "training loss: 6.701117038726807\n",
            "training loss: 6.973557949066162\n",
            "training loss: 6.81359338760376\n",
            "training loss: 6.792597770690918\n",
            "training loss: 6.821652889251709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  50%|█████     | 30/60 [19:52<20:57, 41.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.8212714195251465\n",
            "training loss: 6.764730453491211\n",
            "training loss: 6.725367546081543\n",
            "training loss: 6.887825012207031\n",
            "training loss: 6.715161323547363\n",
            "training loss: 6.771946907043457\n",
            "training loss: 6.940449237823486\n",
            "training loss: 7.091448783874512\n",
            "training loss: 6.931498050689697\n",
            "training loss: 6.86189079284668\n",
            "training loss: 6.997869491577148\n",
            "training loss: 6.908679962158203\n",
            "training loss: 7.204097270965576\n",
            "training loss: 7.157667636871338\n",
            "training loss: 6.861541748046875\n",
            "training loss: 6.902307987213135\n",
            "training loss: 6.971625328063965\n",
            "training loss: 6.790732383728027\n",
            "training loss: 7.108127593994141\n",
            "training loss: 7.3162841796875\n",
            "training loss: 7.206477165222168\n",
            "training loss: 7.200911998748779\n",
            "training loss: 7.023731708526611\n",
            "training loss: 6.966726303100586\n",
            "training loss: 6.817623615264893\n",
            "training loss: 6.777573585510254\n",
            "training loss: 6.746795654296875\n",
            "training loss: 6.75086784362793\n",
            "training loss: 6.892228126525879\n",
            "training loss: 6.952155113220215\n",
            "training loss: 7.042295455932617\n",
            "training loss: 7.151309013366699\n",
            "training loss: 6.796648025512695\n",
            "training loss: 6.788883686065674\n",
            "training loss: 6.837638854980469\n",
            "training loss: 7.105119705200195\n",
            "training loss: 6.803800106048584\n",
            "training loss: 6.870357036590576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  52%|█████▏    | 31/60 [20:31<19:46, 40.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.292149543762207\n",
            "training loss: 7.204703330993652\n",
            "training loss: 7.244307041168213\n",
            "training loss: 6.884922027587891\n",
            "training loss: 7.088516712188721\n",
            "training loss: 6.885936737060547\n",
            "training loss: 7.211063385009766\n",
            "training loss: 7.146909713745117\n",
            "training loss: 6.953399658203125\n",
            "training loss: 7.0038604736328125\n",
            "training loss: 6.990359783172607\n",
            "training loss: 6.953783988952637\n",
            "training loss: 6.746720314025879\n",
            "training loss: 6.835567474365234\n",
            "training loss: 6.843662738800049\n",
            "training loss: 6.951727867126465\n",
            "training loss: 6.922396659851074\n",
            "training loss: 6.8877482414245605\n",
            "training loss: 7.169456958770752\n",
            "training loss: 7.1708598136901855\n",
            "training loss: 6.883047580718994\n",
            "training loss: 7.036777973175049\n",
            "training loss: 6.928094863891602\n",
            "training loss: 6.9118452072143555\n",
            "training loss: 6.711467742919922\n",
            "training loss: 6.986089706420898\n",
            "training loss: 6.520428657531738\n",
            "training loss: 7.002335071563721\n",
            "training loss: 6.905559539794922\n",
            "training loss: 6.928773880004883\n",
            "training loss: 7.117447376251221\n",
            "training loss: 7.063006401062012\n",
            "training loss: 6.822264671325684\n",
            "training loss: 6.8738226890563965\n",
            "training loss: 6.914836883544922\n",
            "training loss: 6.998863220214844\n",
            "training loss: 6.940561294555664\n",
            "training loss: 7.002712249755859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  53%|█████▎    | 32/60 [21:15<19:29, 41.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.113369464874268\n",
            "training loss: 6.7763471603393555\n",
            "training loss: 7.0381364822387695\n",
            "training loss: 6.910553932189941\n",
            "training loss: 7.022812366485596\n",
            "training loss: 7.175882339477539\n",
            "training loss: 6.834461212158203\n",
            "training loss: 6.797261714935303\n",
            "training loss: 6.90859842300415\n",
            "training loss: 7.188333988189697\n",
            "training loss: 7.256718635559082\n",
            "training loss: 6.899344444274902\n",
            "training loss: 7.080148696899414\n",
            "training loss: 7.217352390289307\n",
            "training loss: 7.308115482330322\n",
            "training loss: 6.983438968658447\n",
            "training loss: 7.06253719329834\n",
            "training loss: 6.7734174728393555\n",
            "training loss: 6.961435317993164\n",
            "training loss: 6.864205837249756\n",
            "training loss: 6.796506881713867\n",
            "training loss: 6.791177749633789\n",
            "training loss: 6.85125207901001\n",
            "training loss: 6.733469009399414\n",
            "training loss: 6.689598560333252\n",
            "training loss: 6.783219814300537\n",
            "training loss: 6.9071044921875\n",
            "training loss: 7.030813217163086\n",
            "training loss: 6.933259010314941\n",
            "training loss: 7.001421928405762\n",
            "training loss: 6.917323589324951\n",
            "training loss: 6.800753593444824\n",
            "training loss: 7.0990142822265625\n",
            "training loss: 6.904048442840576\n",
            "training loss: 6.997826099395752\n",
            "training loss: 6.946144104003906\n",
            "training loss: 6.8330078125\n",
            "training loss: 6.859935760498047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  55%|█████▌    | 33/60 [21:58<18:57, 42.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.101260185241699\n",
            "training loss: 6.896404266357422\n",
            "training loss: 6.8835859298706055\n",
            "training loss: 6.72445821762085\n",
            "training loss: 7.025865077972412\n",
            "training loss: 7.087245464324951\n",
            "training loss: 7.09315299987793\n",
            "training loss: 7.083807945251465\n",
            "training loss: 6.915246486663818\n",
            "training loss: 6.872603416442871\n",
            "training loss: 6.7911272048950195\n",
            "training loss: 6.699531555175781\n",
            "training loss: 6.856633186340332\n",
            "training loss: 6.570242881774902\n",
            "training loss: 6.909488677978516\n",
            "training loss: 6.9728593826293945\n",
            "training loss: 7.119016170501709\n",
            "training loss: 7.08501672744751\n",
            "training loss: 6.957798004150391\n",
            "training loss: 6.731223106384277\n",
            "training loss: 6.782588958740234\n",
            "training loss: 6.832921028137207\n",
            "training loss: 6.731109619140625\n",
            "training loss: 6.874026298522949\n",
            "training loss: 6.715761184692383\n",
            "training loss: 6.77656364440918\n",
            "training loss: 6.98942232131958\n",
            "training loss: 7.0401153564453125\n",
            "training loss: 6.651709079742432\n",
            "training loss: 6.68278694152832\n",
            "training loss: 6.806448936462402\n",
            "training loss: 6.855730056762695\n",
            "training loss: 6.733331203460693\n",
            "training loss: 6.947088718414307\n",
            "training loss: 6.856598854064941\n",
            "training loss: 6.84291934967041\n",
            "training loss: 6.649458408355713\n",
            "training loss: 6.659344673156738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  57%|█████▋    | 34/60 [22:38<18:01, 41.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.043281078338623\n",
            "training loss: 6.699589252471924\n",
            "training loss: 7.102599620819092\n",
            "training loss: 6.9862847328186035\n",
            "training loss: 6.742808818817139\n",
            "training loss: 6.879265785217285\n",
            "training loss: 6.954916477203369\n",
            "training loss: 6.888062477111816\n",
            "training loss: 6.745850563049316\n",
            "training loss: 6.829051971435547\n",
            "training loss: 6.968921184539795\n",
            "training loss: 6.804952621459961\n",
            "training loss: 6.562823295593262\n",
            "training loss: 6.892798900604248\n",
            "training loss: 6.841395378112793\n",
            "training loss: 7.040117263793945\n",
            "training loss: 6.628936767578125\n",
            "training loss: 6.813971996307373\n",
            "training loss: 6.746009826660156\n",
            "training loss: 6.793973445892334\n",
            "training loss: 7.042572021484375\n",
            "training loss: 6.94075870513916\n",
            "training loss: 6.766495704650879\n",
            "training loss: 6.792651653289795\n",
            "training loss: 6.762007713317871\n",
            "training loss: 6.524658679962158\n",
            "training loss: 6.753813743591309\n",
            "training loss: 6.844446182250977\n",
            "training loss: 6.816854000091553\n",
            "training loss: 6.422143936157227\n",
            "training loss: 6.556718826293945\n",
            "training loss: 6.410017013549805\n",
            "training loss: 6.559953689575195\n",
            "training loss: 6.877803325653076\n",
            "training loss: 6.7257866859436035\n",
            "training loss: 6.780361175537109\n",
            "training loss: 6.69345760345459\n",
            "training loss: 6.7250165939331055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  58%|█████▊    | 35/60 [23:16<16:55, 40.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.965790748596191\n",
            "training loss: 7.022829055786133\n",
            "training loss: 6.952366828918457\n",
            "training loss: 6.985260009765625\n",
            "training loss: 6.7866363525390625\n",
            "training loss: 7.131647109985352\n",
            "training loss: 6.936105728149414\n",
            "training loss: 6.978084564208984\n",
            "training loss: 6.669103622436523\n",
            "training loss: 7.107715129852295\n",
            "training loss: 7.074100494384766\n",
            "training loss: 7.104179382324219\n",
            "training loss: 7.129859924316406\n",
            "training loss: 6.953244209289551\n",
            "training loss: 7.062285423278809\n",
            "training loss: 6.9683380126953125\n",
            "training loss: 6.876542568206787\n",
            "training loss: 6.899820804595947\n",
            "training loss: 6.877043724060059\n",
            "training loss: 6.897702693939209\n",
            "training loss: 6.975685119628906\n",
            "training loss: 6.914694786071777\n",
            "training loss: 7.01796817779541\n",
            "training loss: 6.683037757873535\n",
            "training loss: 6.825315475463867\n",
            "training loss: 6.830256462097168\n",
            "training loss: 6.844299793243408\n",
            "training loss: 6.835940361022949\n",
            "training loss: 6.927045822143555\n",
            "training loss: 6.784677505493164\n",
            "training loss: 6.806920051574707\n",
            "training loss: 6.727297782897949\n",
            "training loss: 6.835116863250732\n",
            "training loss: 6.91290283203125\n",
            "training loss: 7.104226112365723\n",
            "training loss: 6.781699180603027\n",
            "training loss: 6.7473602294921875\n",
            "training loss: 6.6346940994262695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  60%|██████    | 36/60 [23:59<16:32, 41.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.117923736572266\n",
            "training loss: 7.226819038391113\n",
            "training loss: 7.218867778778076\n",
            "training loss: 7.036655902862549\n",
            "training loss: 7.262550354003906\n",
            "training loss: 7.120205879211426\n",
            "training loss: 6.791353702545166\n",
            "training loss: 7.062856674194336\n",
            "training loss: 6.952867031097412\n",
            "training loss: 6.769472122192383\n",
            "training loss: 7.111830234527588\n",
            "training loss: 7.044515132904053\n",
            "training loss: 6.816788196563721\n",
            "training loss: 6.66595458984375\n",
            "training loss: 7.000547409057617\n",
            "training loss: 6.767331123352051\n",
            "training loss: 6.838537216186523\n",
            "training loss: 6.638797283172607\n",
            "training loss: 6.346933841705322\n",
            "training loss: 6.933211326599121\n",
            "training loss: 6.737359046936035\n",
            "training loss: 6.800264358520508\n",
            "training loss: 6.834880828857422\n",
            "training loss: 6.935596942901611\n",
            "training loss: 6.766960144042969\n",
            "training loss: 6.847511291503906\n",
            "training loss: 6.892815113067627\n",
            "training loss: 6.501015663146973\n",
            "training loss: 6.5030598640441895\n",
            "training loss: 6.435967445373535\n",
            "training loss: 6.574537754058838\n",
            "training loss: 6.782469272613525\n",
            "training loss: 6.873040676116943\n",
            "training loss: 6.239686965942383\n",
            "training loss: 6.538723945617676\n",
            "training loss: 6.872730255126953\n",
            "training loss: 6.465277194976807\n",
            "training loss: 6.839414596557617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  62%|██████▏   | 37/60 [24:45<16:20, 42.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.919414520263672\n",
            "training loss: 6.9226393699646\n",
            "training loss: 7.248287677764893\n",
            "training loss: 7.062946796417236\n",
            "training loss: 7.092006683349609\n",
            "training loss: 7.181527614593506\n",
            "training loss: 6.890020370483398\n",
            "training loss: 6.922396183013916\n",
            "training loss: 6.989387035369873\n",
            "training loss: 7.037824630737305\n",
            "training loss: 6.807980537414551\n",
            "training loss: 6.584768295288086\n",
            "training loss: 6.788690567016602\n",
            "training loss: 6.8813371658325195\n",
            "training loss: 7.027100563049316\n",
            "training loss: 6.8467302322387695\n",
            "training loss: 6.82641077041626\n",
            "training loss: 6.728393077850342\n",
            "training loss: 6.848246097564697\n",
            "training loss: 6.84118127822876\n",
            "training loss: 6.80881404876709\n",
            "training loss: 6.568391799926758\n",
            "training loss: 6.618978500366211\n",
            "training loss: 6.816072940826416\n",
            "training loss: 6.646206855773926\n",
            "training loss: 6.840579986572266\n",
            "training loss: 6.641261100769043\n",
            "training loss: 6.638314247131348\n",
            "training loss: 6.576393127441406\n",
            "training loss: 6.5380096435546875\n",
            "training loss: 6.712545871734619\n",
            "training loss: 6.826359748840332\n",
            "training loss: 6.70611572265625\n",
            "training loss: 6.355704307556152\n",
            "training loss: 6.762350082397461\n",
            "training loss: 6.715359687805176\n",
            "training loss: 6.9130682945251465\n",
            "training loss: 7.177363395690918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  63%|██████▎   | 38/60 [25:32<16:06, 43.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.934433937072754\n",
            "training loss: 6.898536682128906\n",
            "training loss: 6.808198928833008\n",
            "training loss: 6.9782915115356445\n",
            "training loss: 6.920366287231445\n",
            "training loss: 7.0411481857299805\n",
            "training loss: 7.054568290710449\n",
            "training loss: 6.931557655334473\n",
            "training loss: 7.0639119148254395\n",
            "training loss: 6.828105926513672\n",
            "training loss: 6.945499420166016\n",
            "training loss: 6.870432376861572\n",
            "training loss: 6.753078460693359\n",
            "training loss: 7.070413589477539\n",
            "training loss: 6.933205604553223\n",
            "training loss: 7.278802394866943\n",
            "training loss: 7.062312126159668\n",
            "training loss: 7.073018550872803\n",
            "training loss: 6.744641304016113\n",
            "training loss: 6.729402542114258\n",
            "training loss: 7.060437202453613\n",
            "training loss: 6.740846157073975\n",
            "training loss: 7.042596817016602\n",
            "training loss: 6.803237438201904\n",
            "training loss: 6.749241828918457\n",
            "training loss: 6.986400127410889\n",
            "training loss: 6.893743991851807\n",
            "training loss: 7.148583889007568\n",
            "training loss: 6.7225470542907715\n",
            "training loss: 6.788441181182861\n",
            "training loss: 6.79757833480835\n",
            "training loss: 6.718785285949707\n",
            "training loss: 6.740736961364746\n",
            "training loss: 6.966397285461426\n",
            "training loss: 6.979964256286621\n",
            "training loss: 6.786764144897461\n",
            "training loss: 6.802473068237305\n",
            "training loss: 6.686882019042969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  65%|██████▌   | 39/60 [26:15<15:15, 43.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.178587436676025\n",
            "training loss: 7.1096343994140625\n",
            "training loss: 6.940501689910889\n",
            "training loss: 6.989036560058594\n",
            "training loss: 6.716065406799316\n",
            "training loss: 6.8289690017700195\n",
            "training loss: 6.673750400543213\n",
            "training loss: 6.950797080993652\n",
            "training loss: 6.866969108581543\n",
            "training loss: 6.904532432556152\n",
            "training loss: 6.988480567932129\n",
            "training loss: 7.068222999572754\n",
            "training loss: 6.63906192779541\n",
            "training loss: 6.767806053161621\n",
            "training loss: 7.000345706939697\n",
            "training loss: 6.781737327575684\n",
            "training loss: 6.848203659057617\n",
            "training loss: 6.964639186859131\n",
            "training loss: 6.850214004516602\n",
            "training loss: 7.021191596984863\n",
            "training loss: 7.114097595214844\n",
            "training loss: 6.820188999176025\n",
            "training loss: 6.794812202453613\n",
            "training loss: 6.881522178649902\n",
            "training loss: 6.987009048461914\n",
            "training loss: 7.043966293334961\n",
            "training loss: 7.160066604614258\n",
            "training loss: 7.185762405395508\n",
            "training loss: 7.113447189331055\n",
            "training loss: 6.9388933181762695\n",
            "training loss: 6.960567474365234\n",
            "training loss: 6.7614312171936035\n",
            "training loss: 6.912949562072754\n",
            "training loss: 7.208483695983887\n",
            "training loss: 7.200040817260742\n",
            "training loss: 7.083024978637695\n",
            "training loss: 6.821059226989746\n",
            "training loss: 6.5701398849487305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  67%|██████▋   | 40/60 [27:00<14:43, 44.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.003750324249268\n",
            "training loss: 7.110909461975098\n",
            "training loss: 7.047339916229248\n",
            "training loss: 7.125768661499023\n",
            "training loss: 6.827507972717285\n",
            "training loss: 7.151259422302246\n",
            "training loss: 7.157426834106445\n",
            "training loss: 6.892258644104004\n",
            "training loss: 6.822879791259766\n",
            "training loss: 6.845468521118164\n",
            "training loss: 6.700138092041016\n",
            "training loss: 6.84277868270874\n",
            "training loss: 6.956117630004883\n",
            "training loss: 6.778172969818115\n",
            "training loss: 7.095162391662598\n",
            "training loss: 7.194928169250488\n",
            "training loss: 7.306990623474121\n",
            "training loss: 7.183976173400879\n",
            "training loss: 7.2236199378967285\n",
            "training loss: 7.063648223876953\n",
            "training loss: 7.135997772216797\n",
            "training loss: 7.09336519241333\n",
            "training loss: 7.22463321685791\n",
            "training loss: 7.084333896636963\n",
            "training loss: 6.816492080688477\n",
            "training loss: 7.022472381591797\n",
            "training loss: 7.1186041831970215\n",
            "training loss: 7.005960464477539\n",
            "training loss: 7.02247953414917\n",
            "training loss: 7.076310634613037\n",
            "training loss: 6.9370832443237305\n",
            "training loss: 7.0130767822265625\n",
            "training loss: 7.150998592376709\n",
            "training loss: 6.89988899230957\n",
            "training loss: 6.854341506958008\n",
            "training loss: 6.703137397766113\n",
            "training loss: 6.871359825134277\n",
            "training loss: 6.889277458190918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  68%|██████▊   | 41/60 [27:45<14:01, 44.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.027322769165039\n",
            "training loss: 7.032837867736816\n",
            "training loss: 7.105852127075195\n",
            "training loss: 7.041328430175781\n",
            "training loss: 7.1048383712768555\n",
            "training loss: 7.120072364807129\n",
            "training loss: 6.95474100112915\n",
            "training loss: 6.8345537185668945\n",
            "training loss: 6.982664108276367\n",
            "training loss: 6.6439714431762695\n",
            "training loss: 6.8135809898376465\n",
            "training loss: 6.764884948730469\n",
            "training loss: 6.864709854125977\n",
            "training loss: 6.993946075439453\n",
            "training loss: 6.837306976318359\n",
            "training loss: 6.844601154327393\n",
            "training loss: 6.903204917907715\n",
            "training loss: 6.845005035400391\n",
            "training loss: 7.0056328773498535\n",
            "training loss: 7.016412734985352\n",
            "training loss: 7.021759510040283\n",
            "training loss: 6.862929344177246\n",
            "training loss: 6.844910621643066\n",
            "training loss: 6.757772445678711\n",
            "training loss: 6.994526386260986\n",
            "training loss: 6.746738433837891\n",
            "training loss: 6.472890853881836\n",
            "training loss: 6.8041300773620605\n",
            "training loss: 6.679629325866699\n",
            "training loss: 6.73625373840332\n",
            "training loss: 6.642787456512451\n",
            "training loss: 6.633602142333984\n",
            "training loss: 6.841348648071289\n",
            "training loss: 6.58579158782959\n",
            "training loss: 6.77828311920166\n",
            "training loss: 6.865318298339844\n",
            "training loss: 6.950191497802734\n",
            "training loss: 6.728540897369385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  70%|███████   | 42/60 [28:30<13:19, 44.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.02916145324707\n",
            "training loss: 6.481180191040039\n",
            "training loss: 6.748702526092529\n",
            "training loss: 6.856381416320801\n",
            "training loss: 7.137921333312988\n",
            "training loss: 7.148090362548828\n",
            "training loss: 7.247872829437256\n",
            "training loss: 6.869364261627197\n",
            "training loss: 6.94017219543457\n",
            "training loss: 7.178753852844238\n",
            "training loss: 7.004393100738525\n",
            "training loss: 7.078588962554932\n",
            "training loss: 6.92655611038208\n",
            "training loss: 6.988033294677734\n",
            "training loss: 7.180068016052246\n",
            "training loss: 6.883925437927246\n",
            "training loss: 6.938642978668213\n",
            "training loss: 6.849741458892822\n",
            "training loss: 6.8405914306640625\n",
            "training loss: 6.7532453536987305\n",
            "training loss: 6.995453834533691\n",
            "training loss: 6.891719818115234\n",
            "training loss: 6.787199974060059\n",
            "training loss: 6.879476547241211\n",
            "training loss: 6.764952659606934\n",
            "training loss: 6.808064937591553\n",
            "training loss: 6.85080099105835\n",
            "training loss: 6.74936580657959\n",
            "training loss: 6.831853866577148\n",
            "training loss: 6.899214267730713\n",
            "training loss: 6.696852207183838\n",
            "training loss: 6.718457221984863\n",
            "training loss: 6.973357677459717\n",
            "training loss: 6.850363731384277\n",
            "training loss: 6.756392478942871\n",
            "training loss: 6.8533735275268555\n",
            "training loss: 6.884117126464844\n",
            "training loss: 6.8718438148498535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  72%|███████▏  | 43/60 [29:09<12:08, 42.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.8942952156066895\n",
            "training loss: 6.76713752746582\n",
            "training loss: 6.979563236236572\n",
            "training loss: 7.013392448425293\n",
            "training loss: 7.0631422996521\n",
            "training loss: 7.2421112060546875\n",
            "training loss: 7.17085075378418\n",
            "training loss: 7.17325496673584\n",
            "training loss: 7.073551654815674\n",
            "training loss: 7.1790771484375\n",
            "training loss: 7.097987651824951\n",
            "training loss: 6.783639430999756\n",
            "training loss: 6.998534202575684\n",
            "training loss: 6.818470001220703\n",
            "training loss: 6.987346649169922\n",
            "training loss: 6.753842353820801\n",
            "training loss: 6.930508613586426\n",
            "training loss: 6.8908281326293945\n",
            "training loss: 6.854557037353516\n",
            "training loss: 6.6673502922058105\n",
            "training loss: 6.712836265563965\n",
            "training loss: 6.822785377502441\n",
            "training loss: 6.949986457824707\n",
            "training loss: 6.8056840896606445\n",
            "training loss: 6.884349822998047\n",
            "training loss: 6.889626502990723\n",
            "training loss: 6.685563564300537\n",
            "training loss: 6.969882011413574\n",
            "training loss: 6.73930549621582\n",
            "training loss: 6.842929840087891\n",
            "training loss: 6.7364654541015625\n",
            "training loss: 6.687798500061035\n",
            "training loss: 6.760074138641357\n",
            "training loss: 7.011450290679932\n",
            "training loss: 7.137051582336426\n",
            "training loss: 6.942511558532715\n",
            "training loss: 7.112015247344971\n",
            "training loss: 6.996095657348633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  73%|███████▎  | 44/60 [29:49<11:13, 42.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.005613327026367\n",
            "training loss: 7.017428398132324\n",
            "training loss: 6.9037580490112305\n",
            "training loss: 6.756385803222656\n",
            "training loss: 6.975977897644043\n",
            "training loss: 6.907375812530518\n",
            "training loss: 6.7664031982421875\n",
            "training loss: 6.912998676300049\n",
            "training loss: 6.96013879776001\n",
            "training loss: 6.894576072692871\n",
            "training loss: 7.101441383361816\n",
            "training loss: 7.033761501312256\n",
            "training loss: 6.908899307250977\n",
            "training loss: 6.580211162567139\n",
            "training loss: 6.8067121505737305\n",
            "training loss: 6.945301532745361\n",
            "training loss: 6.932814121246338\n",
            "training loss: 6.841136932373047\n",
            "training loss: 7.039873123168945\n",
            "training loss: 6.5604095458984375\n",
            "training loss: 6.625002861022949\n",
            "training loss: 6.906741142272949\n",
            "training loss: 6.859396934509277\n",
            "training loss: 6.858224868774414\n",
            "training loss: 6.76070499420166\n",
            "training loss: 6.755297660827637\n",
            "training loss: 6.888726234436035\n",
            "training loss: 6.88199520111084\n",
            "training loss: 6.676119804382324\n",
            "training loss: 6.830535411834717\n",
            "training loss: 6.666620254516602\n",
            "training loss: 6.968838691711426\n",
            "training loss: 6.737807750701904\n",
            "training loss: 6.683623313903809\n",
            "training loss: 7.018084526062012\n",
            "training loss: 6.779829025268555\n",
            "training loss: 6.85401725769043\n",
            "training loss: 6.607024669647217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  75%|███████▌  | 45/60 [30:32<10:34, 42.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.848123073577881\n",
            "training loss: 7.048044681549072\n",
            "training loss: 6.941422462463379\n",
            "training loss: 6.86728572845459\n",
            "training loss: 6.923757553100586\n",
            "training loss: 7.053522109985352\n",
            "training loss: 6.963357925415039\n",
            "training loss: 6.677380084991455\n",
            "training loss: 6.936017036437988\n",
            "training loss: 6.815948009490967\n",
            "training loss: 6.682538986206055\n",
            "training loss: 6.813055992126465\n",
            "training loss: 7.013096809387207\n",
            "training loss: 6.641905784606934\n",
            "training loss: 7.078094005584717\n",
            "training loss: 6.928123474121094\n",
            "training loss: 6.779670715332031\n",
            "training loss: 6.989049434661865\n",
            "training loss: 6.846494674682617\n",
            "training loss: 6.916855335235596\n",
            "training loss: 6.773082256317139\n",
            "training loss: 6.827142715454102\n",
            "training loss: 6.903648376464844\n",
            "training loss: 6.761298179626465\n",
            "training loss: 6.76626443862915\n",
            "training loss: 6.7647504806518555\n",
            "training loss: 6.776849746704102\n",
            "training loss: 7.154715538024902\n",
            "training loss: 6.845992088317871\n",
            "training loss: 6.8626580238342285\n",
            "training loss: 6.657448768615723\n",
            "training loss: 6.639438152313232\n",
            "training loss: 6.766697883605957\n",
            "training loss: 6.7684736251831055\n",
            "training loss: 6.37087869644165\n",
            "training loss: 6.480051040649414\n",
            "training loss: 6.751479625701904\n",
            "training loss: 6.566233158111572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  77%|███████▋  | 46/60 [31:11<09:36, 41.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.856990814208984\n",
            "training loss: 6.859879493713379\n",
            "training loss: 7.019880294799805\n",
            "training loss: 6.886839866638184\n",
            "training loss: 7.096941947937012\n",
            "training loss: 7.029726505279541\n",
            "training loss: 6.909963607788086\n",
            "training loss: 6.830902099609375\n",
            "training loss: 6.778964519500732\n",
            "training loss: 6.823537826538086\n",
            "training loss: 7.016666889190674\n",
            "training loss: 7.110006809234619\n",
            "training loss: 7.02040958404541\n",
            "training loss: 6.643542289733887\n",
            "training loss: 6.655840873718262\n",
            "training loss: 6.783176422119141\n",
            "training loss: 6.589098930358887\n",
            "training loss: 6.845576286315918\n",
            "training loss: 6.770864009857178\n",
            "training loss: 6.774096488952637\n",
            "training loss: 7.0183539390563965\n",
            "training loss: 6.911188125610352\n",
            "training loss: 7.014562129974365\n",
            "training loss: 6.936785697937012\n",
            "training loss: 6.838346481323242\n",
            "training loss: 6.823090553283691\n",
            "training loss: 6.892617225646973\n",
            "training loss: 6.8424153327941895\n",
            "training loss: 6.840822219848633\n",
            "training loss: 6.530702590942383\n",
            "training loss: 6.821427822113037\n",
            "training loss: 6.688366889953613\n",
            "training loss: 6.792716979980469\n",
            "training loss: 6.841213226318359\n",
            "training loss: 6.794275760650635\n",
            "training loss: 6.760347843170166\n",
            "training loss: 6.886513710021973\n",
            "training loss: 6.739688873291016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  78%|███████▊  | 47/60 [31:49<08:43, 40.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.034060955047607\n",
            "training loss: 7.005055904388428\n",
            "training loss: 7.251678466796875\n",
            "training loss: 6.920297622680664\n",
            "training loss: 7.050578594207764\n",
            "training loss: 7.075156211853027\n",
            "training loss: 6.980830192565918\n",
            "training loss: 6.797945499420166\n",
            "training loss: 6.914335250854492\n",
            "training loss: 7.130931854248047\n",
            "training loss: 6.970883369445801\n",
            "training loss: 6.737733364105225\n",
            "training loss: 6.785300254821777\n",
            "training loss: 6.949734687805176\n",
            "training loss: 7.167939186096191\n",
            "training loss: 7.200155735015869\n",
            "training loss: 7.08840274810791\n",
            "training loss: 7.0912370681762695\n",
            "training loss: 7.023825168609619\n",
            "training loss: 6.919209957122803\n",
            "training loss: 6.979971885681152\n",
            "training loss: 6.828131675720215\n",
            "training loss: 6.955454349517822\n",
            "training loss: 6.838028430938721\n",
            "training loss: 6.978487491607666\n",
            "training loss: 6.899468421936035\n",
            "training loss: 6.763708114624023\n",
            "training loss: 6.719206809997559\n",
            "training loss: 6.663122653961182\n",
            "training loss: 6.857725143432617\n",
            "training loss: 6.706446170806885\n",
            "training loss: 6.761436462402344\n",
            "training loss: 6.891009330749512\n",
            "training loss: 6.896706581115723\n",
            "training loss: 6.989477157592773\n",
            "training loss: 6.956700325012207\n",
            "training loss: 6.732905387878418\n",
            "training loss: 6.711862564086914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  80%|████████  | 48/60 [32:29<08:03, 40.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.080045700073242\n",
            "training loss: 6.9628376960754395\n",
            "training loss: 7.0937676429748535\n",
            "training loss: 6.944624423980713\n",
            "training loss: 7.030898094177246\n",
            "training loss: 7.113102436065674\n",
            "training loss: 7.046095371246338\n",
            "training loss: 7.0118608474731445\n",
            "training loss: 6.719156742095947\n",
            "training loss: 6.835293769836426\n",
            "training loss: 6.821111679077148\n",
            "training loss: 6.966916561126709\n",
            "training loss: 6.969202041625977\n",
            "training loss: 7.006818771362305\n",
            "training loss: 6.804940223693848\n",
            "training loss: 6.8506317138671875\n",
            "training loss: 6.598779678344727\n",
            "training loss: 6.693556308746338\n",
            "training loss: 6.842154026031494\n",
            "training loss: 6.893239498138428\n",
            "training loss: 6.859592914581299\n",
            "training loss: 6.858983516693115\n",
            "training loss: 6.975126266479492\n",
            "training loss: 6.824840545654297\n",
            "training loss: 6.965322494506836\n",
            "training loss: 6.8891072273254395\n",
            "training loss: 6.921114921569824\n",
            "training loss: 6.852206707000732\n",
            "training loss: 7.022212982177734\n",
            "training loss: 7.011894702911377\n",
            "training loss: 7.006448268890381\n",
            "training loss: 6.933897495269775\n",
            "training loss: 6.790002346038818\n",
            "training loss: 6.818737983703613\n",
            "training loss: 6.842288494110107\n",
            "training loss: 6.763524055480957\n",
            "training loss: 6.918156623840332\n",
            "training loss: 6.737622261047363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  82%|████████▏ | 49/60 [33:12<07:33, 41.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.074853420257568\n",
            "training loss: 6.892539978027344\n",
            "training loss: 6.612090110778809\n",
            "training loss: 7.206552505493164\n",
            "training loss: 7.3601837158203125\n",
            "training loss: 7.025367736816406\n",
            "training loss: 6.986208438873291\n",
            "training loss: 6.812765598297119\n",
            "training loss: 6.960595607757568\n",
            "training loss: 6.983193874359131\n",
            "training loss: 7.035058975219727\n",
            "training loss: 6.98058557510376\n",
            "training loss: 6.911440849304199\n",
            "training loss: 6.74100399017334\n",
            "training loss: 6.908391952514648\n",
            "training loss: 7.12481689453125\n",
            "training loss: 7.041566848754883\n",
            "training loss: 6.990774154663086\n",
            "training loss: 7.016029357910156\n",
            "training loss: 6.87929105758667\n",
            "training loss: 6.858792781829834\n",
            "training loss: 6.766002655029297\n",
            "training loss: 6.870944023132324\n",
            "training loss: 6.868777275085449\n",
            "training loss: 7.048524856567383\n",
            "training loss: 7.2069783210754395\n",
            "training loss: 6.780525207519531\n",
            "training loss: 7.077570915222168\n",
            "training loss: 6.9807538986206055\n",
            "training loss: 6.8885626792907715\n",
            "training loss: 6.984288215637207\n",
            "training loss: 6.9454345703125\n",
            "training loss: 6.738564491271973\n",
            "training loss: 6.9540324211120605\n",
            "training loss: 7.0402398109436035\n",
            "training loss: 6.628969192504883\n",
            "training loss: 6.843790054321289\n",
            "training loss: 6.835248947143555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  83%|████████▎ | 50/60 [33:54<06:51, 41.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.961207389831543\n",
            "training loss: 7.299092769622803\n",
            "training loss: 7.058543682098389\n",
            "training loss: 7.071043968200684\n",
            "training loss: 6.8397064208984375\n",
            "training loss: 6.793144702911377\n",
            "training loss: 7.110195159912109\n",
            "training loss: 6.983532905578613\n",
            "training loss: 6.836915969848633\n",
            "training loss: 6.9064717292785645\n",
            "training loss: 6.906460762023926\n",
            "training loss: 6.53508186340332\n",
            "training loss: 6.790180206298828\n",
            "training loss: 6.689918041229248\n",
            "training loss: 6.577989101409912\n",
            "training loss: 6.96583366394043\n",
            "training loss: 7.140448093414307\n",
            "training loss: 6.852768898010254\n",
            "training loss: 6.974226474761963\n",
            "training loss: 6.843387603759766\n",
            "training loss: 7.004236221313477\n",
            "training loss: 6.889192581176758\n",
            "training loss: 6.598190784454346\n",
            "training loss: 6.965121269226074\n",
            "training loss: 6.922082901000977\n",
            "training loss: 6.762287139892578\n",
            "training loss: 6.832656383514404\n",
            "training loss: 7.068869590759277\n",
            "training loss: 6.887366771697998\n",
            "training loss: 6.687057971954346\n",
            "training loss: 6.619673252105713\n",
            "training loss: 6.518678665161133\n",
            "training loss: 6.573519706726074\n",
            "training loss: 6.914892196655273\n",
            "training loss: 7.025081157684326\n",
            "training loss: 6.673425674438477\n",
            "training loss: 6.582547664642334\n",
            "training loss: 6.809624671936035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  85%|████████▌ | 51/60 [34:36<06:14, 41.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.892455101013184\n",
            "training loss: 6.954013824462891\n",
            "training loss: 6.802385330200195\n",
            "training loss: 7.03770637512207\n",
            "training loss: 6.971781253814697\n",
            "training loss: 6.936123847961426\n",
            "training loss: 6.820364952087402\n",
            "training loss: 6.705624580383301\n",
            "training loss: 6.73643684387207\n",
            "training loss: 6.9023637771606445\n",
            "training loss: 6.862699508666992\n",
            "training loss: 6.78006649017334\n",
            "training loss: 7.091548442840576\n",
            "training loss: 6.995379447937012\n",
            "training loss: 6.716534614562988\n",
            "training loss: 6.841850280761719\n",
            "training loss: 6.824645519256592\n",
            "training loss: 6.591805458068848\n",
            "training loss: 6.786615371704102\n",
            "training loss: 6.809243202209473\n",
            "training loss: 6.760986328125\n",
            "training loss: 6.554662227630615\n",
            "training loss: 6.663980960845947\n",
            "training loss: 6.53082799911499\n",
            "training loss: 6.532759189605713\n",
            "training loss: 6.722834587097168\n",
            "training loss: 6.593376636505127\n",
            "training loss: 6.519508361816406\n",
            "training loss: 6.628721714019775\n",
            "training loss: 6.862020015716553\n",
            "training loss: 6.568166255950928\n",
            "training loss: 6.746765613555908\n",
            "training loss: 6.907495021820068\n",
            "training loss: 6.687892436981201\n",
            "training loss: 6.778938293457031\n",
            "training loss: 6.759900093078613\n",
            "training loss: 6.922903060913086\n",
            "training loss: 6.774873733520508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  87%|████████▋ | 52/60 [35:14<05:24, 40.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.972963333129883\n",
            "training loss: 7.006219387054443\n",
            "training loss: 7.004993438720703\n",
            "training loss: 6.89321756362915\n",
            "training loss: 7.205975532531738\n",
            "training loss: 6.953799724578857\n",
            "training loss: 6.923456192016602\n",
            "training loss: 7.004785537719727\n",
            "training loss: 7.046639442443848\n",
            "training loss: 7.197731971740723\n",
            "training loss: 6.970616817474365\n",
            "training loss: 6.975913047790527\n",
            "training loss: 6.884139060974121\n",
            "training loss: 7.076604843139648\n",
            "training loss: 6.853437423706055\n",
            "training loss: 6.556398391723633\n",
            "training loss: 6.697775363922119\n",
            "training loss: 6.86292839050293\n",
            "training loss: 6.829602241516113\n",
            "training loss: 6.917086601257324\n",
            "training loss: 6.9602251052856445\n",
            "training loss: 7.079653739929199\n",
            "training loss: 6.704606056213379\n",
            "training loss: 6.814319610595703\n",
            "training loss: 6.883748531341553\n",
            "training loss: 6.824796199798584\n",
            "training loss: 6.748466491699219\n",
            "training loss: 6.76089334487915\n",
            "training loss: 6.878705024719238\n",
            "training loss: 6.939857482910156\n",
            "training loss: 7.016848564147949\n",
            "training loss: 7.157442092895508\n",
            "training loss: 7.04112434387207\n",
            "training loss: 6.82607889175415\n",
            "training loss: 6.736961841583252\n",
            "training loss: 6.774969100952148\n",
            "training loss: 6.758896827697754\n",
            "training loss: 7.023096561431885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  88%|████████▊ | 53/60 [35:53<04:39, 39.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.8229241371154785\n",
            "training loss: 6.978436470031738\n",
            "training loss: 6.905290603637695\n",
            "training loss: 7.157358169555664\n",
            "training loss: 6.873775482177734\n",
            "training loss: 7.031538486480713\n",
            "training loss: 6.736562252044678\n",
            "training loss: 6.770174980163574\n",
            "training loss: 6.816176414489746\n",
            "training loss: 6.841639518737793\n",
            "training loss: 6.879429340362549\n",
            "training loss: 6.583896160125732\n",
            "training loss: 6.810758590698242\n",
            "training loss: 7.089756488800049\n",
            "training loss: 6.944772720336914\n",
            "training loss: 6.884036064147949\n",
            "training loss: 6.916372776031494\n",
            "training loss: 6.85581636428833\n",
            "training loss: 6.959402084350586\n",
            "training loss: 6.939637184143066\n",
            "training loss: 6.86070442199707\n",
            "training loss: 6.723086357116699\n",
            "training loss: 6.917492866516113\n",
            "training loss: 7.029820919036865\n",
            "training loss: 6.925222396850586\n",
            "training loss: 6.735731601715088\n",
            "training loss: 6.839869022369385\n",
            "training loss: 6.914552211761475\n",
            "training loss: 6.874425411224365\n",
            "training loss: 7.031776428222656\n",
            "training loss: 6.922146320343018\n",
            "training loss: 6.9344563484191895\n",
            "training loss: 6.962658882141113\n",
            "training loss: 6.943243980407715\n",
            "training loss: 6.961794853210449\n",
            "training loss: 6.708713054656982\n",
            "training loss: 6.814689636230469\n",
            "training loss: 6.776373863220215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  90%|█████████ | 54/60 [36:31<03:56, 39.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.903870105743408\n",
            "training loss: 7.03617525100708\n",
            "training loss: 6.925224781036377\n",
            "training loss: 6.964849472045898\n",
            "training loss: 6.930069923400879\n",
            "training loss: 7.079952239990234\n",
            "training loss: 7.055519104003906\n",
            "training loss: 7.1697587966918945\n",
            "training loss: 6.756884574890137\n",
            "training loss: 7.060019016265869\n",
            "training loss: 7.070013046264648\n",
            "training loss: 7.071118354797363\n",
            "training loss: 6.819187641143799\n",
            "training loss: 6.9886932373046875\n",
            "training loss: 6.926514625549316\n",
            "training loss: 6.8291144371032715\n",
            "training loss: 6.671139240264893\n",
            "training loss: 6.9706220626831055\n",
            "training loss: 6.889263153076172\n",
            "training loss: 6.711435317993164\n",
            "training loss: 6.701684951782227\n",
            "training loss: 6.641923904418945\n",
            "training loss: 6.681867599487305\n",
            "training loss: 6.864557266235352\n",
            "training loss: 6.802175998687744\n",
            "training loss: 6.7433929443359375\n",
            "training loss: 6.712922096252441\n",
            "training loss: 6.976167678833008\n",
            "training loss: 6.881327152252197\n",
            "training loss: 6.787415027618408\n",
            "training loss: 6.640896320343018\n",
            "training loss: 7.244105339050293\n",
            "training loss: 7.192046642303467\n",
            "training loss: 7.160735130310059\n",
            "training loss: 6.780179977416992\n",
            "training loss: 6.907106876373291\n",
            "training loss: 6.611821174621582\n",
            "training loss: 6.728417873382568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  92%|█████████▏| 55/60 [37:09<03:15, 39.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.08101749420166\n",
            "training loss: 6.765387535095215\n",
            "training loss: 6.803796768188477\n",
            "training loss: 6.649214744567871\n",
            "training loss: 6.867998123168945\n",
            "training loss: 6.689599990844727\n",
            "training loss: 6.966554164886475\n",
            "training loss: 6.933890342712402\n",
            "training loss: 6.802604675292969\n",
            "training loss: 6.692333698272705\n",
            "training loss: 6.841772556304932\n",
            "training loss: 6.910487651824951\n",
            "training loss: 6.823941230773926\n",
            "training loss: 6.811901092529297\n",
            "training loss: 6.59879207611084\n",
            "training loss: 6.779997825622559\n",
            "training loss: 6.907293796539307\n",
            "training loss: 6.743054389953613\n",
            "training loss: 6.920454025268555\n",
            "training loss: 6.624956130981445\n",
            "training loss: 6.832566261291504\n",
            "training loss: 6.826194763183594\n",
            "training loss: 6.686408042907715\n",
            "training loss: 6.762887001037598\n",
            "training loss: 6.72812557220459\n",
            "training loss: 6.826191425323486\n",
            "training loss: 6.618575096130371\n",
            "training loss: 6.276834487915039\n",
            "training loss: 6.78187370300293\n",
            "training loss: 6.563266754150391\n",
            "training loss: 6.719230651855469\n",
            "training loss: 6.839003562927246\n",
            "training loss: 6.817522048950195\n",
            "training loss: 6.756740570068359\n",
            "training loss: 6.7721757888793945\n",
            "training loss: 6.824431419372559\n",
            "training loss: 6.750961780548096\n",
            "training loss: 6.934781074523926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  93%|█████████▎| 56/60 [37:47<02:34, 38.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9846601486206055\n",
            "training loss: 7.011218070983887\n",
            "training loss: 7.064876556396484\n",
            "training loss: 6.883882522583008\n",
            "training loss: 7.124920845031738\n",
            "training loss: 6.770108222961426\n",
            "training loss: 6.621429443359375\n",
            "training loss: 6.972975254058838\n",
            "training loss: 6.750853538513184\n",
            "training loss: 6.966207504272461\n",
            "training loss: 6.8374176025390625\n",
            "training loss: 6.98281192779541\n",
            "training loss: 6.714694976806641\n",
            "training loss: 6.869410514831543\n",
            "training loss: 6.746819496154785\n",
            "training loss: 7.040042877197266\n",
            "training loss: 6.925085544586182\n",
            "training loss: 6.552797794342041\n",
            "training loss: 6.778534889221191\n",
            "training loss: 6.732008457183838\n",
            "training loss: 6.9260759353637695\n",
            "training loss: 6.918918132781982\n",
            "training loss: 6.900082588195801\n",
            "training loss: 6.800029754638672\n",
            "training loss: 6.856566429138184\n",
            "training loss: 7.066244125366211\n",
            "training loss: 6.83090877532959\n",
            "training loss: 6.890505790710449\n",
            "training loss: 6.925195693969727\n",
            "training loss: 6.900659561157227\n",
            "training loss: 6.978701114654541\n",
            "training loss: 6.837608337402344\n",
            "training loss: 6.8840436935424805\n",
            "training loss: 6.692757606506348\n",
            "training loss: 6.933830261230469\n",
            "training loss: 6.792752742767334\n",
            "training loss: 6.6129655838012695\n",
            "training loss: 6.678953170776367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  95%|█████████▌| 57/60 [38:24<01:54, 38.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.929502487182617\n",
            "training loss: 6.952098369598389\n",
            "training loss: 7.079798698425293\n",
            "training loss: 6.996832370758057\n",
            "training loss: 6.9196319580078125\n",
            "training loss: 6.789000988006592\n",
            "training loss: 6.937988758087158\n",
            "training loss: 6.749717712402344\n",
            "training loss: 6.935294151306152\n",
            "training loss: 6.799313545227051\n",
            "training loss: 6.938831329345703\n",
            "training loss: 6.669700622558594\n",
            "training loss: 6.761606216430664\n",
            "training loss: 6.572564125061035\n",
            "training loss: 6.637040615081787\n",
            "training loss: 6.791947364807129\n",
            "training loss: 6.868388652801514\n",
            "training loss: 6.597573280334473\n",
            "training loss: 6.688454627990723\n",
            "training loss: 6.733639240264893\n",
            "training loss: 6.73105525970459\n",
            "training loss: 7.139049530029297\n",
            "training loss: 6.779618263244629\n",
            "training loss: 6.918128967285156\n",
            "training loss: 6.941906929016113\n",
            "training loss: 6.91469669342041\n",
            "training loss: 6.94931697845459\n",
            "training loss: 6.80741548538208\n",
            "training loss: 6.799193382263184\n",
            "training loss: 6.917716026306152\n",
            "training loss: 7.150325298309326\n",
            "training loss: 6.979082107543945\n",
            "training loss: 6.792324066162109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "perplexity_tr_decoder = []\n",
        "with open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\n",
        "  perplexity_tr_decoder = pkl.load(pklfile)\n",
        "  pklfile.close()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QcYwi7zKXre0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "89d72de5-e537-4baf-ff4f-1cf5caf6b5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nperplexity_tr_decoder = []\\nwith open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\\n  perplexity_tr_decoder = pkl.load(pklfile)\\n  pklfile.close()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_tr_decoder = [t.to(\"cpu\").item() for t in perplexity_tr_decoder]"
      ],
      "metadata": {
        "id": "FcxFA7rAicEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(perplexity_tr_decoder, label = 'Perplexity transformer decoder')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1rb7IdThijCp",
        "outputId": "adb7e5eb-6ed9-4d18-a850-d370c7554260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "zzz"
      ],
      "metadata": {
        "id": "uTPL4pa61mUs"
      }
    }
  ]
}