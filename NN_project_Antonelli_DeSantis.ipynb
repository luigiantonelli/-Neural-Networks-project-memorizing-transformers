{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/NN-project-memorizing-transformers/blob/main/NN_project_Antonelli_DeSantis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "sH_q6bacGaqq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from pathlib import Path\n",
        "from filelock import FileLock\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a4BTaVB5Pxs",
        "outputId": "5508ff48-1a7d-436f-f229-94d55b735a58"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Memory"
      ],
      "metadata": {
        "id": "4I2ce2jPLzle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QppURbZ0KL0f",
        "outputId": "812fb8ea-de08-4b31-8bc5-185d6a872e51"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.8/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krC3-klsLPVa",
        "outputId": "5a273e8d-d550-45f9-8e38-cce7423b6eb3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import per la knn memory\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import wraps\n",
        "\n",
        "from contextlib import ExitStack, contextmanager\n",
        "\n",
        "from einops import rearrange, pack, unpack\n",
        "\n",
        "# multiprocessing\n",
        "\n",
        "from joblib import Parallel, delayed, cpu_count"
      ],
      "metadata": {
        "id": "KeHkdSn0KBSP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FAISS_INDEX_GPU_ID = int(os.getenv('FAISS_INDEX_GPU_ID', 0))\n",
        "\n",
        "DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY = './.tmp/knn.memories'\n",
        "\n",
        "# helper functions\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "def cast_list(val):\n",
        "    return val if isinstance(val, list) else [val]\n",
        "\n",
        "def all_el_unique(arr):\n",
        "    return len(set(arr)) == len(arr)\n",
        "\n",
        "@contextmanager\n",
        "def multi_context(*cms):\n",
        "    with ExitStack() as stack:\n",
        "        yield [stack.enter_context(cls) for cls in cms]\n",
        "\n",
        "def count_intersect(x, y):\n",
        "    # returns an array that shows how many times an element in x is contained in tensor y\n",
        "    return np.sum(rearrange(x, 'i -> i 1') == rearrange(y, 'j -> 1 j'), axis = -1)\n",
        "\n",
        "def check_shape(tensor, pattern, **kwargs):\n",
        "    return rearrange(tensor, f\"{pattern} -> {pattern}\", **kwargs)\n",
        "\n",
        "# a wrapper around faiss IndexIVFFlat\n",
        "# taking care of expiring old keys automagically\n",
        "\n",
        "class KNN():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_num_entries,\n",
        "        cap_num_entries = False,\n",
        "        M = 15,\n",
        "        keep_stats = False\n",
        "    ):\n",
        "        index = faiss.IndexHNSWFlat(dim, M, faiss.METRIC_INNER_PRODUCT)\n",
        "        self.index = index\n",
        "        self.max_num_entries = max_num_entries\n",
        "        self.cap_num_entries = cap_num_entries\n",
        "        self.is_trained = False\n",
        "        self.keep_stats = keep_stats\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'index'):\n",
        "            del self.index\n",
        "\n",
        "    def reset(self):\n",
        "        self.ids = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.empty((0,), dtype = np.int32)\n",
        "            self.age_num_iterations = np.empty((0,), dtype = np.int32)\n",
        "            self.ages_since_last_hit = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        self.index.reset()\n",
        "        self.is_trained = False\n",
        "\n",
        "    def train(self, x):\n",
        "        self.index.train(x)\n",
        "        self.is_trained = True\n",
        "\n",
        "    def add(self, x, ids):\n",
        "        if not self.is_trained:\n",
        "            self.train(x)\n",
        "\n",
        "        self.ids = np.concatenate((ids, self.ids))\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.concatenate((np.zeros_like(ids), self.hits))\n",
        "            self.age_num_iterations = np.concatenate((np.zeros_like(ids), self.age_num_iterations))\n",
        "            self.ages_since_last_hit = np.concatenate((np.zeros_like(ids), self.ages_since_last_hit))\n",
        "\n",
        "        if self.cap_num_entries and len(self.ids) > self.max_num_entries:\n",
        "            self.reset()\n",
        "\n",
        "        return self.index.add(x)\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        x,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        return_distances = False,\n",
        "        increment_hits = False,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        if not self.is_trained:\n",
        "            return np.full((x.shape[0], topk), -1)\n",
        "\n",
        "        distances, indices = self.index.search(x, k = topk)\n",
        "\n",
        "        if increment_hits and self.keep_stats:\n",
        "            hits = count_intersect(self.ids, rearrange(indices, '... -> (...)'))\n",
        "            self.hits += hits\n",
        "\n",
        "            self.ages_since_last_hit += 1\n",
        "            self.ages_since_last_hit *= (hits == 0)\n",
        "\n",
        "        if increment_age and self.keep_stats:\n",
        "            self.age_num_iterations += 1\n",
        "\n",
        "        if return_distances:\n",
        "            return indices, distances\n",
        "\n",
        "        return indices\n",
        "\n",
        "# KNN memory layer, where one can store key / value memories\n",
        "# can automatically take care of a collection of faiss indices (across batch dimension)\n",
        "\n",
        "class KNNMemory():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_memories = 16000,\n",
        "        num_indices = 1,\n",
        "        memmap_filename = './knn.memory.memmap',\n",
        "        multiprocessing = True\n",
        "    ):\n",
        "        self.dim = dim\n",
        "        self.num_indices = num_indices\n",
        "        self.scoped_indices = list(range(num_indices))\n",
        "\n",
        "        self.max_memories = max_memories\n",
        "        self.shape = (num_indices, max_memories, 2, dim)\n",
        "        self.db_offsets = np.zeros(num_indices, dtype = np.int32)\n",
        "\n",
        "        self.db = np.memmap(memmap_filename, mode = 'w+', dtype = np.float32, shape = self.shape)\n",
        "        self.knns = [KNN(dim = dim, max_num_entries = max_memories, cap_num_entries = True) for _ in range(num_indices)]\n",
        "    \n",
        "        self.n_jobs = cpu_count() if multiprocessing else 1\n",
        "\n",
        "    def set_scoped_indices(self, indices):\n",
        "        indices = list(indices)\n",
        "        assert all_el_unique(indices), f'all scoped batch indices must be unique, received: {indices}'\n",
        "        assert all([0 <= i < self.num_indices for i in indices]), f'each batch index must be between 0 and less than {self.num_indices}: received {indices}'\n",
        "        self.scoped_indices = indices\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(self, indices):\n",
        "        prev_indices = self.scoped_indices\n",
        "        self.set_scoped_indices(indices)\n",
        "        yield self\n",
        "        self.set_scoped_indices(prev_indices)\n",
        "\n",
        "    def clear(self, batch_indices = None):\n",
        "        if not exists(batch_indices):\n",
        "            batch_indices = list(range(self.num_indices))\n",
        "\n",
        "        batch_indices = cast_list(batch_indices)\n",
        "\n",
        "        for index in batch_indices:\n",
        "            knn = self.knns[index]\n",
        "            knn.reset()\n",
        "\n",
        "        self.db_offsets[batch_indices] = 0\n",
        "\n",
        "    def add(self, memories):\n",
        "        check_shape(memories, 'b n kv d', d = self.dim, kv = 2, b = len(self.scoped_indices))\n",
        "\n",
        "        memories = memories.detach().cpu().numpy()\n",
        "        memories = memories[:, -self.max_memories:]\n",
        "        num_memories = memories.shape[1]\n",
        "\n",
        "        knn_insert_ids = np.arange(num_memories)\n",
        "\n",
        "        keys = np.ascontiguousarray(memories[..., 0, :])\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "        db_offsets = [self.db_offsets[i] for i in self.scoped_indices]\n",
        "\n",
        "        # use joblib to insert new key / value memories into faiss index\n",
        "\n",
        "        @delayed\n",
        "        def knn_add(knn, key, db_offset):\n",
        "            knn.add(key, ids = knn_insert_ids + db_offset)\n",
        "            return knn\n",
        "\n",
        "        updated_knns = Parallel(n_jobs = self.n_jobs)(knn_add(*args) for args in zip(knns, keys, db_offsets))\n",
        "        for knn_idx, scoped_idx in enumerate(self.scoped_indices):\n",
        "            self.knns[scoped_idx] = updated_knns[knn_idx]\n",
        "\n",
        "        # add the new memories to the memmap \"database\"\n",
        "\n",
        "        add_indices = (rearrange(np.arange(num_memories), 'j -> 1 j') + rearrange(self.db_offsets[list(self.scoped_indices)], 'i -> i 1')) % self.max_memories\n",
        "        self.db[rearrange(np.array(self.scoped_indices), 'i -> i 1'), add_indices] = memories\n",
        "        self.db.flush()\n",
        "\n",
        "        self.db_offsets += num_memories\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        queries,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        increment_hits = True,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        check_shape(queries, 'b ... d', d = self.dim, b = len(self.scoped_indices))\n",
        "        queries, ps = pack([queries], 'b * d')\n",
        "\n",
        "        device = queries.device\n",
        "        queries = queries.detach().cpu().numpy()\n",
        "\n",
        "        all_masks = []\n",
        "        all_key_values = []\n",
        "\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "\n",
        "        # parallelize faiss search\n",
        "\n",
        "        @delayed\n",
        "        def knn_search(knn, query):\n",
        "            return knn.search(query, topk, nprobe, increment_hits = increment_hits, increment_age = increment_age)\n",
        "\n",
        "        fetched_indices = Parallel(n_jobs = self.n_jobs)(knn_search(*args) for args in zip(knns, queries))\n",
        "\n",
        "        # get all the memory key / values from memmap 'database'\n",
        "        # todo - remove for loop below\n",
        "\n",
        "        for batch_index, indices in zip(self.scoped_indices, fetched_indices):\n",
        "            mask = indices !=  -1\n",
        "            db_indices = np.where(mask, indices, 0)\n",
        "\n",
        "            all_masks.append(torch.from_numpy(mask))\n",
        "\n",
        "            key_values = self.db[batch_index, db_indices % self.max_memories]\n",
        "            all_key_values.append(torch.from_numpy(key_values))\n",
        "\n",
        "        all_masks = torch.stack(all_masks)\n",
        "        all_key_values = torch.stack(all_key_values)\n",
        "        all_key_values = all_key_values.masked_fill(~rearrange(all_masks, '... -> ... 1 1'), 0.)\n",
        "\n",
        "        all_key_values, = unpack(all_key_values, ps, 'b * n kv d')\n",
        "        all_masks, = unpack(all_masks, ps, 'b * n')\n",
        "\n",
        "        return all_key_values.to(device), all_masks.to(device)\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'knns'):\n",
        "            for knn in self.knns:\n",
        "                del knn\n",
        "        del self.db\n",
        "\n",
        "# extends list with some extra methods for collections of KNN memories\n",
        "\n",
        "class KNNMemoryList(list):\n",
        "    def cleanup(self):\n",
        "        for memory in self:\n",
        "            del memory\n",
        "\n",
        "    @classmethod\n",
        "    def create_memories(\n",
        "        self,\n",
        "        *,\n",
        "        batch_size,\n",
        "        num_memory_layers,\n",
        "        memories_directory = DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY\n",
        "    ):\n",
        "        memories_path = Path(memories_directory)\n",
        "        memories_path.mkdir(exist_ok = True, parents = True)\n",
        "\n",
        "        def inner(*args, **kwargs):\n",
        "            return self([KNNMemory(*args, num_indices = batch_size, memmap_filename = str(memories_path / f'knn.memory.layer.{ind + 1}.memmap'), **kwargs) for ind in range(num_memory_layers)])\n",
        "        return inner\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(\n",
        "        self,\n",
        "        indices\n",
        "    ):\n",
        "        knn_batch_indices_contexts = [memory.at_batch_indices(indices) for memory in self]\n",
        "        with multi_context(*knn_batch_indices_contexts):\n",
        "            yield\n",
        "\n",
        "    def clear_memory(\n",
        "        self,\n",
        "        batch_indices = None,\n",
        "        memory_indices = None\n",
        "    ):\n",
        "        memory_indices = default(memory_indices, tuple(range(len(self))))\n",
        "\n",
        "        for memory_index in memory_indices:\n",
        "            memory = self[memory_index]\n",
        "            memory.clear(batch_indices)"
      ],
      "metadata": {
        "id": "E5Wk2XJSLr-9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memorizing transformers"
      ],
      "metadata": {
        "id": "tWJS8R3fL7RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value, sqrt_q, device):\n",
        "    t = torch.matmul(query, key.transpose(-2, -1))/sqrt_q\n",
        "    i, j = t.shape[-2:]\n",
        "    mask = torch.ones((i, j), dtype = torch.bool, device = device).triu(j - i + 1)\n",
        "    return torch.matmul(F.softmax(t.masked_fill_(mask, -1e-9), dim = -1), value)\n",
        "\n",
        "def KNNattention(query, key, value, sqrt_q, mask):\n",
        "    t = torch.einsum('b h i d, b h i j d -> b h i j', query, key)/sqrt_q\n",
        "    return torch.einsum('b h i j, b h i j d -> b h i d', F.softmax(t.masked_fill_(mask, -1e-9), dim = -1), value)"
      ],
      "metadata": {
        "id": "ZK8XwbNMp5vT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, n, d, h, batch_size):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    assert d % h == 0\n",
        "    #assume q = v \n",
        "    self.q = d // h\n",
        "    self.sqrt_q = sqrt(self.q)\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.W_q = nn.Linear(d, d, bias = False) #stack of h matrices of dimension (d, q), one for each head\n",
        "    self.W_k = nn.Linear(d, d, bias = False)\n",
        "    self.W_v = nn.Linear(d, d, bias = False)\n",
        "    self.W_o = nn.Linear(d, d, bias = False)\n",
        "\n",
        "  def forward(self, x, device):\n",
        "    query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    new_memories = torch.stack((key, value), dim = -2).detach()\n",
        "    attention_value = attention(query, key, value, self.sqrt_q, device)\n",
        "    return self.W_o(attention_value.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q)), new_memories"
      ],
      "metadata": {
        "id": "AwoLII4LMvUK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNAttention(nn.Module):\n",
        "   def __init__(self, n, d, h, num_retrieved_memories, batch_size):\n",
        "      super(KNNAttention, self).__init__()\n",
        "      assert d % h == 0\n",
        "      #assume q = v \n",
        "      self.q = d // h\n",
        "      self.sqrt_q = sqrt(self.q)\n",
        "      self.h = h\n",
        "      self.W_q = nn.Linear(d, d, bias = False)\n",
        "      self.W_k = nn.Linear(d, d, bias = False)\n",
        "      self.W_v = nn.Linear(d, d, bias = False)\n",
        "      self.W_o = nn.Linear(d, d, bias = False)\n",
        "      self.b_g = nn.Parameter(torch.randn((h,))) #one for each head\n",
        "      self.num_retrieved_memories = num_retrieved_memories\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "   def forward(self, x, knn_memory, device):\n",
        "      # calculate local attention \n",
        "      query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      local_attention = attention(query, key, value, self.sqrt_q, device)\n",
        "\n",
        "      # calculate knn attention over memory\n",
        "      mem_kv, mem_mask = knn_memory[0].search(query, self.num_retrieved_memories)\n",
        "      mem_key, mem_value = mem_kv.unbind(dim = -2)\n",
        "      knn_attention = KNNattention(query, mem_key, mem_value, self.sqrt_q, ~mem_mask)\n",
        "\n",
        "      # memory to be stored\n",
        "      new_kv_memories = torch.stack((key, value), dim = -2).view(self.batch_size, -1, 2, self.q).detach()\n",
        "\n",
        "      # add to knn memory\n",
        "      if new_kv_memories.numel() > 0:\n",
        "        knn_memory[0].add(new_kv_memories)\n",
        "\n",
        "      # combining local and memory\n",
        "      g = torch.sigmoid(self.b_g)\n",
        "      final_attention = torch.einsum('b h n d, h -> b h n d', knn_attention, g) + \\\n",
        "                        torch.einsum('b h n d, h -> b h n d', local_attention, (1 - g))\n",
        "      \n",
        "      return self.W_o(final_attention.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q)), new_kv_memories"
      ],
      "metadata": {
        "id": "921DW0jjMyWx"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SubLayer(nn.Module):\n",
        "  def __init__(self, d, dropout, hidden_size):\n",
        "    super(SubLayer, self).__init__()\n",
        "    self.norm = nn.LayerNorm(d)\n",
        "    self.mlp = nn.Sequential(nn.Linear(d, hidden_size, bias = True), \n",
        "                             nn.ReLU(),\n",
        "                             nn.Dropout(dropout),\n",
        "                             nn.Linear(hidden_size, d, bias = True))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.mlp(self.norm(x)) #residual connection and normalization"
      ],
      "metadata": {
        "id": "M2Tjkv0gbsmM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    # Compute the positional encodings once in log space.\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
        "                          -(math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    return x + Variable(self.pe[:, :x.size(1)], requires_grad=False)"
      ],
      "metadata": {
        "id": "9U77GkT0cT4u"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MemorizingTransformer(nn.Module):\n",
        "    def __init__(\n",
        "          self,\n",
        "          num_tokens,\n",
        "          d,\n",
        "          heads = 8,\n",
        "          depth = 10,\n",
        "          knn_attn_idx = 2,\n",
        "          attn_dropout = 0.,\n",
        "          hidden_size = 1000,\n",
        "          dropout = 0.3,\n",
        "          max_knn_memories = 1000,\n",
        "          num_retrieved_memories = 8,\n",
        "          knn_memories_directory = DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY,\n",
        "          knn_memory_multiprocessing = False,\n",
        "          batch_size = 16\n",
        "      ):\n",
        "          # asserts\n",
        "          assert d % heads == 0\n",
        "          assert knn_attn_idx < depth\n",
        "\n",
        "          super(MemorizingTransformer, self).__init__()\n",
        "          self.token_emb = nn.Embedding(num_tokens, d)\n",
        "          self.positional_emb = PositionalEncoding(d, max_len = 5000)\n",
        "          self.dim_head = d // heads\n",
        "          self.d = d\n",
        "          self.heads = heads\n",
        "          self.knn_attn_idx = knn_attn_idx\n",
        "          self.depth = depth\n",
        "          self.attn_dropout = attn_dropout\n",
        "          self.hidden_size = hidden_size\n",
        "          self.dropout = dropout\n",
        "          self.max_knn_memories = max_knn_memories\n",
        "          self.num_retrieved_memories = num_retrieved_memories\n",
        "          self.knn_memories_directory = knn_memories_directory\n",
        "          self.knn_memory_multiprocessing =knn_memory_multiprocessing\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "          self.layers = nn.ModuleList([])\n",
        "          for idx in range(depth):\n",
        "              attn = KNNAttention(num_tokens, d, heads, num_retrieved_memories, self.batch_size) \\\n",
        "                  if idx == knn_attn_idx else MultiHeadAttention(num_tokens, d, heads, self.batch_size)\n",
        "\n",
        "              self.layers.append(nn.ModuleList([\n",
        "                  attn,\n",
        "                  SubLayer(d, dropout, hidden_size)\n",
        "              ]))\n",
        "\n",
        "          self.to_out = nn.Sequential(\n",
        "               nn.LayerNorm(d),\n",
        "               nn.Linear(d, num_tokens)\n",
        "          )\n",
        "\n",
        "          # knn memories init\n",
        "\n",
        "          self.knn_mem_kwargs = dict(\n",
        "              dim = self.dim_head,\n",
        "              max_memories = self.max_knn_memories,\n",
        "              multiprocessing = knn_memory_multiprocessing\n",
        "          )\n",
        "          \n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        knn_memory\n",
        "    ):\n",
        "        batch_size, seq_len, *_, device = *x.shape, x.device\n",
        "        x = self.token_emb(x)\n",
        "        x = self.positional_emb(x)\n",
        "\n",
        "        for idx, (attn, sub_l) in enumerate(self.layers):\n",
        "            \n",
        "            #attention\n",
        "\n",
        "            x, mem = attn(x, knn_memory, device) if self.knn_attn_idx == idx else attn(x, device)\n",
        "      \n",
        "            # normalization + feedforward + residual connection\n",
        "\n",
        "            x = sub_l(x)\n",
        "\n",
        "        return self.to_out(x).transpose(1, 2)\n",
        "\n",
        "    \n",
        "    def create_knn_memories(\n",
        "          self,\n",
        "          *,\n",
        "          batch_size\n",
        "      ):  \n",
        "          return KNNMemoryList.create_memories(\n",
        "              batch_size = batch_size,\n",
        "              num_memory_layers = 1,\n",
        "              memories_directory = self.knn_memories_directory\n",
        "          )(**self.knn_mem_kwargs)\n",
        "      \n",
        "    @contextmanager\n",
        "    def knn_memories_context(\n",
        "        self,\n",
        "        **kwargs\n",
        "    ):\n",
        "        knn_dir = Path(self.knn_memories_directory)\n",
        "        knn_dir.mkdir(exist_ok = True, parents = True)\n",
        "        lock = FileLock(str(knn_dir / 'mutex'))\n",
        "\n",
        "        with lock:\n",
        "            knn_memories = self.create_knn_memories(**kwargs)\n",
        "            yield knn_memories\n",
        "            knn_memories.cleanup()\n",
        "\n",
        "    def clear_memory(self, x, token_id):\n",
        "        \"\"\" clears the KNN memories based on if the batch row contains the specified token id \"\"\"\n",
        "        \"\"\" for auto-clearing KNN memories based on start and end of strings \"\"\"\n",
        "\n",
        "        clear_memory = (x == token_id).any(dim = -1)\n",
        "        batch_indices, _ = clear_memory.nonzero(as_tuple = True)\n",
        "        batch_indices_to_clear = batch_indices.tolist()\n",
        "\n",
        "        if len(batch_indices_to_clear) == 0:\n",
        "            return\n",
        "\n",
        "        knn_memories.clear_memory(batch_indices_to_clear)"
      ],
      "metadata": {
        "id": "F5uqCzrVL569"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ihBnTrPhaiDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 16\n",
        "SEQ_LEN = 512\n",
        "SEGMENTS = 5\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS\n",
        "\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 20\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 512\n",
        "CHECKPOINT = 10"
      ],
      "metadata": {
        "id": "ncWOJOkFanTK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MemorizingTransformer(\n",
        "    num_tokens = 256,\n",
        "    d = SEQ_LEN,\n",
        "    heads = HEADS,\n",
        "    batch_size = BATCH_SIZE\n",
        ").cuda()\n",
        "\n",
        "# prepare enwik8 data\n",
        "\n",
        "#Lorenzo\n",
        "with gzip.open('/content/drive/MyDrive/Secondo Anno/Neural Networks/project/enwik8.gz') as file:\n",
        "    X = np.fromstring(file.read(int(95e6)), dtype=np.uint8)\n",
        "    print(X.shape)\n",
        "    # number of samples to take\n",
        "    n_samples = math.ceil(0.6*X.shape[0])\n",
        "    # take the set uniformly at random\n",
        "    data = resample(X, n_samples=n_samples, replace=False)\n",
        "    trX, vaX = train_test_split(data, test_size=math.ceil(0.2*data.shape[0]))\n",
        "    # trX, vaX = np.split(X, [int(90e6)])\n",
        "    print(trX.shape)\n",
        "    print(vaX.shape)\n",
        "    # assert False\n",
        "    data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "    # data = torch.from_numpy(X)\n",
        "\"\"\"\n",
        "\n",
        "#Luigi\n",
        "with gzip.open('/content/drive/MyDrive/Colab Notebooks/enwik8.gz') as file:\n",
        "    X = np.fromstring(file.read(int(95e6)), dtype=np.uint8)\n",
        "    trX, vaX = np.split(X, [int(90e6)])\n",
        "    data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "\"\"\"\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "# # dataset and dataloader\n",
        "# dataset = TextSamplerDataset(data, SEQ_LEN)\n",
        "# # test_dataset = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "\n",
        "# data_size = dataset.__len__()\n",
        "# # data_test_size = test_dataset.__len__()\n",
        "\n",
        "# perc_data = 0.3\n",
        "# valid_size=0.2\n",
        "# indices = list(range(data_size))\n",
        "# np.random.shuffle(indices)\n",
        "# data_size = int(np.floor(data_size * 0.3))\n",
        "# print(data_size)\n",
        "# indices = indices[:data_size]\n",
        "\n",
        "# split = int(np.floor(valid_size * data_size))\n",
        "# train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# # define samplers for obtaining training and validation batches\n",
        "# train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "# valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# train_loader  = DataLoader(dataset, batch_size = BATCH_SIZE, sampler = train_sampler, drop_last = True)\n",
        "\n",
        "# test_loader = DataLoader(dataset, batch_size = BATCH_SIZE, sampler =valid_sampler, drop_last = True)\n",
        "\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE, drop_last = True)\n",
        "test_dataset = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, drop_last = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gVvmKCm3J4A",
        "outputId": "97350cbe-bb9d-4e53-952f-126362efbb1d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-27f4d80b50eb>:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  X = np.fromstring(file.read(int(95e6)), dtype=np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(95000000,)\n",
            "(45600000,)\n",
            "(11400000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_string(a):\n",
        "  seq = \"\"\n",
        "  for word in a:\n",
        "    for letter in word:\n",
        "      seq += chr(letter)\n",
        "    seq += \" \"\n",
        "  return seq"
      ],
      "metadata": {
        "id": "e6Apbm_X-ceS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# training\n",
        "\n",
        "perplexity_list = []\n",
        "for i, data in enumerate(tqdm.tqdm(train_loader, desc = 'training')):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "    with model.knn_memories_context(batch_size = BATCH_SIZE) as knn_memories:\n",
        "        \n",
        "        seq, labels = data[:, :-1], data[:, 1:] #the labels are the same sequences shifted by one\n",
        "\n",
        "        out = model(\n",
        "              seq,\n",
        "              knn_memory = knn_memories\n",
        "        )\n",
        "        #loss_item = torch.exp(loss(out, labels)) #perplexity\n",
        "        loss_item = loss(out, labels)\n",
        "        train_loss += loss_item\n",
        "        loss_item.backward() \n",
        "\n",
        "    print(f'training loss: {train_loss}', flush = True)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if i % EVAL_EVERY == 0:\n",
        "        model.eval()\n",
        "      \n",
        "        test_data = None\n",
        "        for test_data in test_loader:\n",
        "          break\n",
        "\n",
        "        test_loss = 0.\n",
        "\n",
        "        with torch.no_grad(), model.knn_memories_context(batch_size = BATCH_SIZE) as knn_memories: \n",
        "            seq, labels = data[:, :-1], data[:, 1:]\n",
        "            \n",
        "            out = model(\n",
        "              seq,\n",
        "              knn_memory = knn_memories\n",
        "            )\n",
        "\n",
        "            loss_item = loss(out, labels)\n",
        "            test_loss +=  loss_item\n",
        "            \n",
        "\n",
        "        print(f'valid loss: {test_loss}', flush = True)\n",
        "        print(f'perplexity: {torch.exp(test_loss)}', flush = True)\n",
        "        perplexity_list.append(torch.exp(test_loss).cpu())\n",
        "        #Lorenzo\n",
        "        with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity.npy', 'wb') as f:\n",
        "          np.save(f, np.array(perplexity_list))\n",
        "    \n",
        "    if i % CHECKPOINT == 0:\n",
        "      torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "      }, 'model_optimizer2.pt')\n",
        "      #Lorenzo\n",
        "      with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity.npy', 'wb') as f:\n",
        "        np.save(f, np.array(perplexity_list))"
      ],
      "metadata": {
        "id": "d00bJntK2Fyd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "783fffed-1d13-4969-bad3-21640688974e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/5566 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 5.583859920501709\n",
            "valid loss: 4.685384750366211\n",
            "perplexity: 108.3519515991211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 1/5566 [00:03<4:43:07,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 4.761495113372803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 2/5566 [00:04<3:17:26,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 4.342834949493408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 3/5566 [00:05<2:37:04,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 4.1457061767578125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 4/5566 [00:06<2:17:44,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.997325897216797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 5/5566 [00:08<2:21:39,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.9089677333831787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 6/5566 [00:10<2:32:55,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.848611354827881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 7/5566 [00:12<2:35:19,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.8183159828186035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 8/5566 [00:14<3:06:42,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.7277345657348633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 9/5566 [00:16<3:10:09,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.7073957920074463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 10/5566 [00:18<3:00:42,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.6881093978881836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 11/5566 [00:20<2:48:18,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.66084885597229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 12/5566 [00:21<2:31:35,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.6330738067626953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 13/5566 [00:22<2:19:32,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.6036295890808105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 14/5566 [00:23<2:10:23,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.6230766773223877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 15/5566 [00:25<2:04:02,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.6110241413116455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 16/5566 [00:26<1:59:33,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5530009269714355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 17/5566 [00:27<1:56:26,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.57905912399292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 18/5566 [00:28<1:53:55,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5554442405700684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 19/5566 [00:29<1:52:16,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.558539867401123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 20/5566 [00:30<1:51:22,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.572993755340576\n",
            "valid loss: 3.5608463287353516\n",
            "perplexity: 35.19296646118164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 21/5566 [00:33<2:33:57,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.575486898422241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 22/5566 [00:34<2:21:15,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.546755313873291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 23/5566 [00:36<2:11:38,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.582848310470581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 24/5566 [00:37<2:06:41,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5360851287841797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 25/5566 [00:38<2:02:25,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5344812870025635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 26/5566 [00:39<2:00:04,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5317583084106445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 27/5566 [00:40<1:56:46,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.51768159866333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 28/5566 [00:42<1:53:58,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.529911994934082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 29/5566 [00:43<1:52:15,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5371429920196533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 30/5566 [00:44<1:51:06,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.532968521118164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 31/5566 [00:45<1:56:06,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5428149700164795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 32/5566 [00:47<1:54:15,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5460057258605957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 33/5566 [00:48<1:52:41,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5042781829833984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 34/5566 [00:49<1:52:15,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5222489833831787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 35/5566 [00:50<1:51:29,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.543365001678467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 36/5566 [00:51<1:51:15,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.516097068786621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 37/5566 [00:52<1:50:47,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5341320037841797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 38/5566 [00:54<1:50:26,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.54929518699646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 39/5566 [00:55<1:50:02,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.550807476043701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 40/5566 [00:56<1:49:56,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.542736530303955\n",
            "valid loss: 3.538811445236206\n",
            "perplexity: 34.42597961425781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 41/5566 [00:59<2:25:47,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5230836868286133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 42/5566 [01:00<2:22:29,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5214385986328125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 43/5566 [01:01<2:12:54,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5257785320281982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 44/5566 [01:02<2:05:25,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5382394790649414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 45/5566 [01:04<2:00:12,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5578837394714355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 46/5566 [01:05<1:56:48,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5271456241607666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 47/5566 [01:06<1:54:22,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5218896865844727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 48/5566 [01:07<1:52:29,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5510761737823486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 49/5566 [01:08<1:51:48,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.498243808746338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 50/5566 [01:10<1:51:40,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.511568546295166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 51/5566 [01:11<1:56:50,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5203421115875244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 52/5566 [01:12<1:55:07,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.518507957458496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 53/5566 [01:13<1:53:13,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5314698219299316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 54/5566 [01:15<1:52:12,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.4933252334594727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 55/5566 [01:16<1:55:10,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5192105770111084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 56/5566 [01:17<1:55:11,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.519406318664551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 57/5566 [01:18<1:53:56,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5255396366119385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 58/5566 [01:20<1:54:42,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.525297164916992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 59/5566 [01:22<2:14:13,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5337727069854736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 60/5566 [01:24<2:34:33,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.522975444793701\n",
            "valid loss: 3.5206260681152344\n",
            "perplexity: 33.80558395385742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 61/5566 [01:27<3:19:02,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5432262420654297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 62/5566 [01:28<2:53:55,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.543565273284912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 63/5566 [01:29<2:34:16,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5243663787841797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 64/5566 [01:31<2:21:00,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5358896255493164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 65/5566 [01:32<2:22:20,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5102109909057617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 66/5566 [01:34<2:17:56,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.4920716285705566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 67/5566 [01:35<2:08:50,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5212621688842773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 68/5566 [01:36<2:02:13,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.551018476486206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|          | 69/5566 [01:37<1:58:05,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5422005653381348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 70/5566 [01:38<1:55:26,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5328776836395264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 71/5566 [01:40<2:00:53,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.4938557147979736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 72/5566 [01:41<1:57:27,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.527597427368164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 73/5566 [01:42<1:54:26,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5164458751678467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 74/5566 [01:43<1:52:37,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5559284687042236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 75/5566 [01:45<1:50:56,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.516507625579834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 76/5566 [01:46<1:49:57,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5478367805480957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 77/5566 [01:47<1:49:08,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5155773162841797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 78/5566 [01:48<1:49:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.513805866241455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 79/5566 [01:49<1:48:40,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5315678119659424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 80/5566 [01:50<1:48:21,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5278818607330322\n",
            "valid loss: 3.523977041244507\n",
            "perplexity: 33.91905975341797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 81/5566 [01:53<2:23:33,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.520968198776245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 82/5566 [01:54<2:14:16,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.541003942489624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   1%|▏         | 83/5566 [01:55<2:06:20,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5459842681884766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 84/5566 [01:57<2:00:47,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.4964165687561035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 85/5566 [01:58<1:56:53,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.50215744972229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 86/5566 [01:59<1:54:14,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.531989336013794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 87/5566 [02:00<1:52:23,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5176868438720703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 88/5566 [02:01<1:51:10,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5254030227661133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 89/5566 [02:02<1:50:10,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5072922706604004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 90/5566 [02:04<1:49:18,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.505013942718506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 91/5566 [02:05<1:55:03,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.4944331645965576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 92/5566 [02:06<1:53:20,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.538832187652588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 93/5566 [02:07<1:51:36,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5165345668792725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 94/5566 [02:09<1:50:50,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.521580934524536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 95/5566 [02:10<1:50:21,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.533860683441162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 96/5566 [02:11<1:49:46,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.520343065261841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 97/5566 [02:12<1:49:51,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 3.5520544052124023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training:   2%|▏         | 98/5566 [02:14<2:05:10,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-d5c37847425a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#the labels are the same sequences shifted by one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         out = model(\n\u001b[0m\u001b[1;32m     18\u001b[0m               \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mknn_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_memories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-469f4ff54119>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, knn_memory)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m#attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn_attn_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# normalization + feedforward + residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-8103cbc733b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, knn_memory, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;31m# add to knn memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnew_kv_memories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mknn_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_kv_memories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;31m# combining local and memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-c1d99043efa8>\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, memories)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mupdated_knns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_offsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mknn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoped_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoped_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoped_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdated_knns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-c1d99043efa8>\u001b[0m in \u001b[0;36mknn_add\u001b[0;34m(knn, key, db_offset)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mknn_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_insert_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-c1d99043efa8>\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, x, ids)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     def search(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/faiss/__init__.py\u001b[0m in \u001b[0;36mreplacement_add\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplacement_add_with_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/faiss/swigfaiss.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, n, x)\u001b[0m\n\u001b[1;32m   5920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5922\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexHNSW_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5924\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(\n",
        "          self,\n",
        "          num_tokens,\n",
        "          d,\n",
        "          heads = 8,\n",
        "          depth = 4,\n",
        "          hidden_size = 1000,\n",
        "          dropout = 0.3,\n",
        "          batch_size = 16\n",
        "      ):\n",
        "          # asserts\n",
        "          assert d % heads == 0\n",
        "\n",
        "          super(TransformerDecoder, self).__init__()\n",
        "          self.token_emb = nn.Embedding(num_tokens, d)\n",
        "          self.positional_emb = PositionalEncoding(d, max_len = 5000)\n",
        "          self.dim_head = d // heads\n",
        "          self.d = d\n",
        "          self.heads = heads\n",
        "          self.depth = depth\n",
        "          self.hidden_size = hidden_size\n",
        "          self.dropout = dropout\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "          self.layers = nn.ModuleList([])\n",
        "          for idx in range(depth):\n",
        "              attn = MultiHeadAttention(num_tokens, d, heads, self.batch_size)\n",
        "\n",
        "              self.layers.append(nn.ModuleList([\n",
        "                  attn,\n",
        "                  SubLayer(d, dropout, hidden_size)\n",
        "              ]))\n",
        "\n",
        "          self.to_out = nn.Sequential(\n",
        "               nn.LayerNorm(d),\n",
        "               nn.Linear(d, num_tokens)\n",
        "          )\n",
        "          \n",
        "    def forward(\n",
        "        self,\n",
        "        x\n",
        "    ):\n",
        "        batch_size, seq_len, *_, device = *x.shape, x.device\n",
        "        x = self.token_emb(x)\n",
        "        x = self.positional_emb(x)\n",
        "\n",
        "        for idx, (attn, sub_l) in enumerate(self.layers):\n",
        "            \n",
        "            #attention\n",
        "            x, mem = attn(x, device)\n",
        "      \n",
        "            # normalization + feedforward + residual connection\n",
        "            x = sub_l(x)\n",
        "\n",
        "        return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "lBz91btCHjXt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}