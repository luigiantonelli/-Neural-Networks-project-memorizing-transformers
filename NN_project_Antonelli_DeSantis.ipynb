{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/NN-project-memorizing-transformers/blob/main/NN_project_Antonelli_DeSantis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we are presenting our implementation of the Memorizing transformer architecture from the paper \"Memorizing Transformers\" by Yuhuai Wu, Markus N. Rabe, DeLesley Hutchins and Christian Szegedy (https://arxiv.org/abs/2203.08913).\n",
        "\n",
        "Memorizing transformers are decoder-only transformers which have the ability to store in a non-differentiable memory the internal representations of past inputs, allowing to combine local attention with a $k$-nearest neighbors search into the memory. In particular, the architecture of these models uses standard transfomer blocks and a special transformer block that uses this modified version of the attention taking also into consideration past information stored in the memory during previous training steps. For simplicity, we will refer to this block as \"memory block\" in the remainder of this notebook.\n",
        "\n",
        "As it is explained in the paper, the memory block is usually put almost at the end of the architecture and the use of more than one of these blocks don't result in better performances. We followed this approach and conduct our experiments by stacking multiple transformer blocks, followed by a memory block and by one last standard transformer block.\n",
        "\n",
        "The task that we are training our models on is language modeling. So the models are trained on text sequences and are evaluated on their ability to predict "
      ],
      "metadata": {
        "id": "ZZGF-YhbMYid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports"
      ],
      "metadata": {
        "id": "-4GElPh7HbB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section there is everything that is needed to run the cells of the notebook."
      ],
      "metadata": {
        "id": "lVJsp0dwMVb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW8KnU4lPkgI",
        "outputId": "feef273f-a85a-41d2-b0a4-334501e3442e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_transformers import BertTokenizer\n",
        "from pytorch_transformers import BertModel"
      ],
      "metadata": {
        "id": "G5xdOnnKPbxi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata --quiet\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install torchtext --quiet\n",
        "!pip install -U spacy --quiet\n",
        "!python -m spacy download en_core_web_sm --quiet"
      ],
      "metadata": {
        "id": "oZJbIamFP23c",
        "outputId": "4b18a9c8-219f-4691-de40-fc84c9aff477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from pathlib import Path\n",
        "from filelock import FileLock\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pickle as pkl\n",
        "import torchtext\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import spacy\n",
        "from typing import Iterable, List\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchmetrics.text.perplexity import Perplexity\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "Kd714QnlGIP-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a4BTaVB5Pxs",
        "outputId": "79d618d6-60c2-4c42-eb44-bf05bd9628aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "zAXedSwA5nyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, test_iter = WikiText2(split = ('train', 'test'))"
      ],
      "metadata": {
        "id": "jag9JLsDbyOB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from itertools import chain\n",
        "data_iter = chain(train_iter, test_iter)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J4Lo0Rsz7fT-",
        "outputId": "ac97658b-d9ae-47aa-e5aa-419c58d041bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom itertools import chain\\ndata_iter = chain(train_iter, test_iter)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "token_transform = get_tokenizer('spacy', language = 'en_core_web_sm')\n",
        "\n",
        "def yield_tokens(data) -> List[str]:\n",
        "    for line in data:\n",
        "        yield token_transform(line)\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "vocabulary_ = build_vocab_from_iterator(yield_tokens(data_iter), min_freq = 1, specials = special_symbols, special_first = True)\n",
        "vocabulary_.set_default_index(UNK_IDX)\n",
        "vocabulary_.__len__()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uvcwcyno7i6V",
        "outputId": "6e243d91-b59d-436c-8e38-19fcf34b5b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntoken_transform = get_tokenizer('spacy', language = 'en_core_web_sm')\\n\\ndef yield_tokens(data) -> List[str]:\\n    for line in data:\\n        yield token_transform(line)\\n\\nUNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\\n\\nvocabulary_ = build_vocab_from_iterator(yield_tokens(data_iter), min_freq = 1, specials = special_symbols, special_first = True)\\nvocabulary_.set_default_index(UNK_IDX)\\nvocabulary_.__len__()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def preprocessing_(dataset):\n",
        "  new_ds = torch.tensor([], dtype = torch.int32)\n",
        "  for line in dataset:\n",
        "    tokenized_line = torch.tensor([vocabulary_[token] for token in token_transform(line)])\n",
        "    new_ds = torch.cat((new_ds, tokenized_line))\n",
        "  return new_ds\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0JbiwRcz8G7q",
        "outputId": "6021159d-c8d4-4994-ed7b-b5c00a357da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef preprocessing_(dataset):\\n  new_ds = torch.tensor([], dtype = torch.int32)\\n  for line in dataset:\\n    tokenized_line = torch.tensor([vocabulary_[token] for token in token_transform(line)])\\n    new_ds = torch.cat((new_ds, tokenized_line))\\n  return new_ds\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_ds = preprocessing_(train_iter)\n",
        "test_ds = preprocessing_(test_iter)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "R29fLy2G8fIF",
        "outputId": "6d9fb7aa-8bae-4a7a-f9bb-e175c6a42b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_ds = preprocessing_(train_iter)\\ntest_ds = preprocessing_(test_iter)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zlNANpHQiOt",
        "outputId": "f78eb23f-7952-4a9d-de31-351419070dc2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 347567.36B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(dataset):\n",
        "  new_ds = []\n",
        "  for line in dataset:\n",
        "    tokenized_line = tokenizer.tokenize(line)\n",
        "    new_ds.append(tokenized_line)\n",
        "  return new_ds"
      ],
      "metadata": {
        "id": "RnfQlE72RQCR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = preprocessing(train_iter)\n",
        "test_ds = preprocessing(test_iter)"
      ],
      "metadata": {
        "id": "t4ZDCYlDRei8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tokens_to_idxs(dataset):\n",
        "  new_ds = torch.tensor([], dtype = torch.int32)\n",
        "  for line in dataset:\n",
        "    tokenized_line = torch.tensor(tokenizer.convert_tokens_to_ids(line))    \n",
        "    new_ds = torch.cat((new_ds, tokenized_line))\n",
        "  return new_ds"
      ],
      "metadata": {
        "id": "_wQHPc5URusJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = convert_tokens_to_idxs(train_ds)\n",
        "test_ds = convert_tokens_to_idxs(test_ds)"
      ],
      "metadata": {
        "id": "VjlekiRPSahL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCEOkwkgTQiS",
        "outputId": "e0dcd350-b390-4e71-91db-6d13f2063ca9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2405592])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = 30522"
      ],
      "metadata": {
        "id": "juDl2xbjdzEF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "print(len(train_loader))\n",
        "train_ds = torch.zeros((len(train_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(train_loader):\n",
        "  train_ds[i] = document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zCX45xyL955",
        "outputId": "1cdff555-ff6c-45e1-8b55-ccc15d6d31b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "\n",
        "test_ds = torch.zeros((len(test_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(test_loader):\n",
        "  test_ds[i] = document"
      ],
      "metadata": {
        "id": "KlSGhT9-dCDt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGcfKRdsP98_",
        "outputId": "38c9e92c-296d-4611-c67a-b3d002f841d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([240, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.shape"
      ],
      "metadata": {
        "id": "B0wCMRhZdatc",
        "outputId": "0e9e7ef3-b891-4fdb-c32a-120efda337cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Memory"
      ],
      "metadata": {
        "id": "4I2ce2jPLzle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QppURbZ0KL0f",
        "outputId": "dafd4ae9-6acc-4f3b-88bd-fd3688fd7bfd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krC3-klsLPVa",
        "outputId": "0f2d2c0b-824f-4c11-df11-135913933419"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import per la knn memory\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import wraps\n",
        "\n",
        "from contextlib import ExitStack, contextmanager\n",
        "\n",
        "from einops import rearrange, pack, unpack\n",
        "\n",
        "# multiprocessing\n",
        "\n",
        "from joblib import Parallel, delayed, cpu_count"
      ],
      "metadata": {
        "id": "KeHkdSn0KBSP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FAISS_INDEX_GPU_ID = int(os.getenv('FAISS_INDEX_GPU_ID', 0))\n",
        "\n",
        "DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY = './.tmp/knn.memories'\n",
        "\n",
        "# helper functions\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "def cast_list(val):\n",
        "    return val if isinstance(val, list) else [val]\n",
        "\n",
        "def all_el_unique(arr):\n",
        "    return len(set(arr)) == len(arr)\n",
        "\n",
        "@contextmanager\n",
        "def multi_context(*cms):\n",
        "    with ExitStack() as stack:\n",
        "        yield [stack.enter_context(cls) for cls in cms]\n",
        "\n",
        "def count_intersect(x, y):\n",
        "    # returns an array that shows how many times an element in x is contained in tensor y\n",
        "    return np.sum(rearrange(x, 'i -> i 1') == rearrange(y, 'j -> 1 j'), axis = -1)\n",
        "\n",
        "def check_shape(tensor, pattern, **kwargs):\n",
        "    return rearrange(tensor, f\"{pattern} -> {pattern}\", **kwargs)\n",
        "\n",
        "# a wrapper around faiss IndexIVFFlat\n",
        "# taking care of expiring old keys automagically\n",
        "\n",
        "class KNN():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_num_entries,\n",
        "        cap_num_entries = False,\n",
        "        M = 15,\n",
        "        keep_stats = False\n",
        "    ):\n",
        "        index = faiss.IndexHNSWFlat(dim, M, faiss.METRIC_INNER_PRODUCT)\n",
        "        self.index = index\n",
        "        self.max_num_entries = max_num_entries\n",
        "        self.cap_num_entries = cap_num_entries\n",
        "        self.is_trained = False\n",
        "        self.keep_stats = keep_stats\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'index'):\n",
        "            del self.index\n",
        "\n",
        "    def reset(self):\n",
        "        self.ids = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.empty((0,), dtype = np.int32)\n",
        "            self.age_num_iterations = np.empty((0,), dtype = np.int32)\n",
        "            self.ages_since_last_hit = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        self.index.reset()\n",
        "        self.is_trained = False\n",
        "\n",
        "    def train(self, x):\n",
        "        self.index.train(x)\n",
        "        self.is_trained = True\n",
        "\n",
        "    def add(self, x, ids):\n",
        "        if not self.is_trained:\n",
        "            self.train(x)\n",
        "\n",
        "        self.ids = np.concatenate((ids, self.ids))\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.concatenate((np.zeros_like(ids), self.hits))\n",
        "            self.age_num_iterations = np.concatenate((np.zeros_like(ids), self.age_num_iterations))\n",
        "            self.ages_since_last_hit = np.concatenate((np.zeros_like(ids), self.ages_since_last_hit))\n",
        "\n",
        "        if self.cap_num_entries and len(self.ids) > self.max_num_entries:\n",
        "            self.reset()\n",
        "\n",
        "        return self.index.add(x)\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        x,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        return_distances = False,\n",
        "        increment_hits = False,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        if not self.is_trained:\n",
        "            return np.full((x.shape[0], topk), -1)\n",
        "\n",
        "        distances, indices = self.index.search(x, k = topk)\n",
        "\n",
        "        if increment_hits and self.keep_stats:\n",
        "            hits = count_intersect(self.ids, rearrange(indices, '... -> (...)'))\n",
        "            self.hits += hits\n",
        "\n",
        "            self.ages_since_last_hit += 1\n",
        "            self.ages_since_last_hit *= (hits == 0)\n",
        "\n",
        "        if increment_age and self.keep_stats:\n",
        "            self.age_num_iterations += 1\n",
        "\n",
        "        if return_distances:\n",
        "            return indices, distances\n",
        "\n",
        "        return indices\n",
        "\n",
        "# KNN memory layer, where one can store key / value memories\n",
        "# can automatically take care of a collection of faiss indices (across batch dimension)\n",
        "\n",
        "class KNNMemory():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_memories = 16000,\n",
        "        num_indices = 1,\n",
        "        memmap_filename = './knn.memory.memmap',\n",
        "        multiprocessing = True\n",
        "    ):\n",
        "        self.dim = dim\n",
        "        self.num_indices = num_indices\n",
        "        self.scoped_indices = list(range(num_indices))\n",
        "\n",
        "        self.max_memories = max_memories\n",
        "        self.shape = (num_indices, max_memories, 2, dim)\n",
        "        self.db_offsets = np.zeros(num_indices, dtype = np.int32)\n",
        "\n",
        "        self.db = np.memmap(memmap_filename, mode = 'w+', dtype = np.float32, shape = self.shape)\n",
        "        self.knns = [KNN(dim = dim, max_num_entries = max_memories, cap_num_entries = True) for _ in range(num_indices)]\n",
        "    \n",
        "        self.n_jobs = cpu_count() if multiprocessing else 1\n",
        "\n",
        "    def set_scoped_indices(self, indices):\n",
        "        indices = list(indices)\n",
        "        assert all_el_unique(indices), f'all scoped batch indices must be unique, received: {indices}'\n",
        "        assert all([0 <= i < self.num_indices for i in indices]), f'each batch index must be between 0 and less than {self.num_indices}: received {indices}'\n",
        "        self.scoped_indices = indices\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(self, indices):\n",
        "        prev_indices = self.scoped_indices\n",
        "        self.set_scoped_indices(indices)\n",
        "        yield self\n",
        "        self.set_scoped_indices(prev_indices)\n",
        "\n",
        "    def clear(self, batch_indices = None):\n",
        "        if not exists(batch_indices):\n",
        "            batch_indices = list(range(self.num_indices))\n",
        "\n",
        "        batch_indices = cast_list(batch_indices)\n",
        "\n",
        "        for index in batch_indices:\n",
        "            knn = self.knns[index]\n",
        "            knn.reset()\n",
        "\n",
        "        self.db_offsets[batch_indices] = 0\n",
        "\n",
        "    def add(self, memories):\n",
        "        check_shape(memories, 'b n kv d', d = self.dim, kv = 2, b = len(self.scoped_indices))\n",
        "\n",
        "        memories = memories.detach().cpu().numpy()\n",
        "        memories = memories[:, -self.max_memories:]\n",
        "        num_memories = memories.shape[1]\n",
        "\n",
        "        knn_insert_ids = np.arange(num_memories)\n",
        "\n",
        "        keys = np.ascontiguousarray(memories[..., 0, :])\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "        db_offsets = [self.db_offsets[i] for i in self.scoped_indices]\n",
        "\n",
        "        # use joblib to insert new key / value memories into faiss index\n",
        "\n",
        "        @delayed\n",
        "        def knn_add(knn, key, db_offset):\n",
        "            knn.add(key, ids = knn_insert_ids + db_offset)\n",
        "            return knn\n",
        "\n",
        "        updated_knns = Parallel(n_jobs = self.n_jobs)(knn_add(*args) for args in zip(knns, keys, db_offsets))\n",
        "        for knn_idx, scoped_idx in enumerate(self.scoped_indices):\n",
        "            self.knns[scoped_idx] = updated_knns[knn_idx]\n",
        "\n",
        "        # add the new memories to the memmap \"database\"\n",
        "\n",
        "        add_indices = (rearrange(np.arange(num_memories), 'j -> 1 j') + rearrange(self.db_offsets[list(self.scoped_indices)], 'i -> i 1')) % self.max_memories\n",
        "        self.db[rearrange(np.array(self.scoped_indices), 'i -> i 1'), add_indices] = memories\n",
        "        self.db.flush()\n",
        "\n",
        "        self.db_offsets += num_memories\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        queries,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        increment_hits = True,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        check_shape(queries, 'b ... d', d = self.dim, b = len(self.scoped_indices))\n",
        "        queries, ps = pack([queries], 'b * d')\n",
        "\n",
        "        device = queries.device\n",
        "        queries = queries.detach().cpu().numpy()\n",
        "\n",
        "        all_masks = []\n",
        "        all_key_values = []\n",
        "\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "\n",
        "        # parallelize faiss search\n",
        "\n",
        "        @delayed\n",
        "        def knn_search(knn, query):\n",
        "            return knn.search(query, topk, nprobe, increment_hits = increment_hits, increment_age = increment_age)\n",
        "\n",
        "        fetched_indices = Parallel(n_jobs = self.n_jobs)(knn_search(*args) for args in zip(knns, queries))\n",
        "\n",
        "        # get all the memory key / values from memmap 'database'\n",
        "        # todo - remove for loop below\n",
        "\n",
        "        for batch_index, indices in zip(self.scoped_indices, fetched_indices):\n",
        "            mask = indices !=  -1\n",
        "            db_indices = np.where(mask, indices, 0)\n",
        "\n",
        "            all_masks.append(torch.from_numpy(mask))\n",
        "\n",
        "            key_values = self.db[batch_index, db_indices % self.max_memories]\n",
        "            all_key_values.append(torch.from_numpy(key_values))\n",
        "\n",
        "        all_masks = torch.stack(all_masks)\n",
        "        all_key_values = torch.stack(all_key_values)\n",
        "        all_key_values = all_key_values.masked_fill(~rearrange(all_masks, '... -> ... 1 1'), 0.)\n",
        "\n",
        "        all_key_values, = unpack(all_key_values, ps, 'b * n kv d')\n",
        "        all_masks, = unpack(all_masks, ps, 'b * n')\n",
        "\n",
        "        return all_key_values.to(device), all_masks.to(device)\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'knns'):\n",
        "            for knn in self.knns:\n",
        "                del knn\n",
        "        del self.db\n",
        "\n",
        "# extends list with some extra methods for collections of KNN memories\n",
        "\n",
        "class KNNMemoryList(list):\n",
        "    def cleanup(self):\n",
        "        for memory in self:\n",
        "            del memory\n",
        "\n",
        "    @classmethod\n",
        "    def create_memories(\n",
        "        self,\n",
        "        *,\n",
        "        batch_size,\n",
        "        num_memory_layers,\n",
        "        memories_directory = DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY\n",
        "    ):\n",
        "        memories_path = Path(memories_directory)\n",
        "        memories_path.mkdir(exist_ok = True, parents = True)\n",
        "\n",
        "        def inner(*args, **kwargs):\n",
        "            return self([KNNMemory(*args, num_indices = batch_size, memmap_filename = str(memories_path / f'knn.memory.layer.{ind + 1}.memmap'), **kwargs) for ind in range(num_memory_layers)])\n",
        "        return inner\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(\n",
        "        self,\n",
        "        indices\n",
        "    ):\n",
        "        knn_batch_indices_contexts = [memory.at_batch_indices(indices) for memory in self]\n",
        "        with multi_context(*knn_batch_indices_contexts):\n",
        "            yield\n",
        "\n",
        "    def clear_memory(\n",
        "        self,\n",
        "        batch_indices = None,\n",
        "        memory_indices = None\n",
        "    ):\n",
        "        memory_indices = default(memory_indices, tuple(range(len(self))))\n",
        "\n",
        "        for memory_index in memory_indices:\n",
        "            memory = self[memory_index]\n",
        "            memory.clear(batch_indices)"
      ],
      "metadata": {
        "id": "E5Wk2XJSLr-9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memorizing transformers"
      ],
      "metadata": {
        "id": "tWJS8R3fL7RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value, sqrt_q, device, mask = None):\n",
        "    t = torch.matmul(query, key.transpose(-2, -1))/sqrt_q\n",
        "    if mask is not None:\n",
        "      t = t.masked_fill_(mask == 0, -1e-9)\n",
        "    return torch.matmul(F.softmax(t, dim = -1), value)\n",
        "\n",
        "def KNNattention(query, key, value, sqrt_q, mask):\n",
        "    t = torch.einsum('b h i q, b h i j q -> b h i j', query, key)/sqrt_q\n",
        "    return torch.einsum('b h i j, b h i j q -> b h i q', F.softmax(t.masked_fill_(mask, -1e-9), dim = -1), value)"
      ],
      "metadata": {
        "id": "ZK8XwbNMp5vT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d, h, batch_size):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    assert d % h == 0\n",
        "    #assume q = v \n",
        "    self.q = d // h #single head dimension\n",
        "    self.sqrt_q = sqrt(self.q)\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.W_q = nn.Linear(d, d, bias = False) #stack of h matrices of dimension (d, q), one for each head\n",
        "    self.W_k = nn.Linear(d, d, bias = False)\n",
        "    self.W_v = nn.Linear(d, d, bias = False)\n",
        "    self.W_o = nn.Linear(d, d, bias = False)\n",
        "\n",
        "  def forward(self, x, mask = None):\n",
        "    query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    #new_memories = torch.stack((key, value), dim = -2).detach()\n",
        "    attention_value = attention(query, key, value, self.sqrt_q, mask)\n",
        "    return self.W_o(attention_value.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q))"
      ],
      "metadata": {
        "id": "AwoLII4LMvUK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNAttention(nn.Module):\n",
        "   def __init__(self, d, h, batch_size, num_retrieved_memories):\n",
        "      super(KNNAttention, self).__init__()\n",
        "      assert d % h == 0\n",
        "      #assume q = v \n",
        "      self.q = d // h\n",
        "      self.sqrt_q = sqrt(self.q)\n",
        "      self.h = h\n",
        "      self.W_q = nn.Linear(d, d, bias = False)\n",
        "      self.W_k = nn.Linear(d, d, bias = False)\n",
        "      self.W_v = nn.Linear(d, d, bias = False)\n",
        "      self.W_o = nn.Linear(d, d, bias = False)\n",
        "      self.b_g = nn.Parameter(torch.randn((h,))) #one for each head\n",
        "      self.num_retrieved_memories = num_retrieved_memories\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "   def forward(self, x, mask, knn_memory):\n",
        "      # calculate local attention \n",
        "      query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      local_attention = attention(query, key, value, self.sqrt_q, mask)\n",
        "\n",
        "      # calculate knn attention over memory\n",
        "      query = F.normalize(query, dim = -1)\n",
        "      key = F.normalize(key, dim = -1)\n",
        "      mem_kv, mem_mask = knn_memory.search(query, self.num_retrieved_memories)\n",
        "      mem_key, mem_value = mem_kv.unbind(dim = -2)\n",
        "      knn_attention = KNNattention(query, mem_key, mem_value, self.sqrt_q, ~mem_mask)\n",
        "\n",
        "      # memory to be stored\n",
        "      new_kv_memories = torch.stack((key, value), dim = -2).view(self.batch_size, -1, 2, self.q).detach()\n",
        "\n",
        "      # add to knn memory\n",
        "      if new_kv_memories.numel() > 0:\n",
        "        knn_memory.add(new_kv_memories)\n",
        "\n",
        "      # combining local and memory\n",
        "      g = torch.sigmoid(self.b_g)\n",
        "      final_attention = torch.einsum('b h n q, h -> b h n q', knn_attention, g) + \\\n",
        "                        torch.einsum('b h n q, h -> b h n q', local_attention, (1 - g))\n",
        "      \n",
        "      return self.W_o(final_attention.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q))"
      ],
      "metadata": {
        "id": "921DW0jjMyWx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    # Compute the positional encodings once in log space.\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
        "                          -(math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    return x + Variable(self.pe[:, :x.size(1)], requires_grad=False)"
      ],
      "metadata": {
        "id": "9U77GkT0cT4u"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, d, h, batch_size, hidden_size, dropout, is_mem = False, num_retrieved_memories = 32):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.d = d\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = MultiHeadAttention(d, h, batch_size) if not is_mem else KNNAttention(d, h, batch_size, num_retrieved_memories)\n",
        "    self.norm1 = nn.LayerNorm(d)\n",
        "    self.dropout1 = nn.Dropout(dropout)\n",
        "    self.norm2 = nn.LayerNorm(d)\n",
        "    self.dropout2 = nn.Dropout(dropout)\n",
        "    self.ff = nn.Sequential(nn.Linear(d, hidden_size, bias = True), \n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(dropout),\n",
        "                            nn.Linear(hidden_size, d, bias = True))\n",
        "  def forward(self, x, mask, knn_memory = None):\n",
        "    if knn_memory is None:\n",
        "      x = self.attention(x, mask)\n",
        "    else:\n",
        "      x = self.attention(x, mask, knn_memory)\n",
        "    x = self.dropout1(x + self.norm1(x))\n",
        "    x = x + self.ff(x)\n",
        "    x = self.dropout2(self.norm2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "prYm-KEpwLQq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module): #block of the classic transformer decoder (not used)\n",
        "  def __init__(self, d, h, batch_size, hidden_size, dropout):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    self.attention = MultiHeadAttention(d, h, batch_size)\n",
        "    self.norm = nn.LayerNorm(d)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.transformer_block = TransformerBlock(d, h, batch_size, hidden_size, dropout)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = self.attention(x, mask)\n",
        "    x = self.dropout(self.norm(x))\n",
        "    return self.transformer_block(x)"
      ],
      "metadata": {
        "id": "P4fkZ_djysyF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MemorizingTransformer(nn.Module):\n",
        "    def __init__(\n",
        "          self,\n",
        "          num_tokens,\n",
        "          d,\n",
        "          heads = 8,\n",
        "          depth = 4,\n",
        "          knn_attn_idx = 2,\n",
        "          attn_dropout = 0.,\n",
        "          hidden_size = 1000,\n",
        "          dropout = 0.3,\n",
        "          max_knn_memories = 1000,\n",
        "          num_retrieved_memories = 32,\n",
        "          batch_size = 16,\n",
        "          use_bert = True\n",
        "      ):\n",
        "          # asserts\n",
        "          self.d = d if not use_bert else 768\n",
        "          assert self.d % heads == 0\n",
        "          assert knn_attn_idx < depth\n",
        "\n",
        "          super(MemorizingTransformer, self).__init__()\n",
        "          #self.token_emb = nn.Embedding(num_tokens, self.d) #without BERT\n",
        "          self.token_emb = BertModel.from_pretrained('bert-base-uncased')\n",
        "          self.positional_enc = PositionalEncoding(self.d, max_len = 5000)\n",
        "          self.dim_head = self.d // heads\n",
        "          \n",
        "          self.heads = heads\n",
        "          self.knn_attn_idx = knn_attn_idx\n",
        "          self.depth = depth\n",
        "          self.attn_dropout = attn_dropout\n",
        "          self.hidden_size = hidden_size\n",
        "          self.dropout = dropout\n",
        "          self.max_knn_memories = max_knn_memories\n",
        "          self.num_retrieved_memories = num_retrieved_memories\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "          self.layers = nn.ModuleList([])\n",
        "          for idx in range(depth):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(self.d, heads, batch_size, hidden_size, dropout, is_mem = idx == self.knn_attn_idx)\n",
        "            )\n",
        "\n",
        "          self.to_out = nn.Linear(self.d, num_tokens)\n",
        "    \n",
        "    def create_mask(self, x):\n",
        "      batch_size, seq_len = x.shape\n",
        "      mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "          batch_size, 1, seq_len, seq_len)\n",
        "      return mask    \n",
        "          \n",
        "    def forward(self, x, knn_memory):\n",
        "      mask = self.create_mask(x)\n",
        "      #x = self.token_emb(x) #without BERT\n",
        "      x = self.token_emb(x)[0] #with BERT\n",
        "      x = self.positional_enc(x)\n",
        "\n",
        "      for idx in range(self.depth):\n",
        "          x= self.layers[idx](x, mask, knn_memory = knn_memory if idx == self.knn_attn_idx else None)\n",
        "\n",
        "      return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "F5uqCzrVL569"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ihBnTrPhaiDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "SEQ_LEN = 256\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS \n",
        "DIM_HEAD_BERT = 768 // HEADS #it's 96 with bert (768/8)\n",
        "\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 1\n",
        "CHECKPOINT = 1"
      ],
      "metadata": {
        "id": "ncWOJOkFanTK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "memory = None\n",
        "data = None\n",
        "train_loader_ = None\n",
        "test_loader_ = None"
      ],
      "metadata": {
        "id": "kWjcjNDgEiuS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MemorizingTransformer(\n",
        "    num_tokens = vocabulary,\n",
        "    d = SEQ_LEN,\n",
        "    heads = HEADS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    depth = 4,\n",
        "    knn_attn_idx = 2,\n",
        "    num_retrieved_memories = 32,\n",
        "    use_bert = True #False if you want to try without BERT\n",
        ").to(device)\n",
        "\n",
        "memory = KNNMemory(\n",
        "    dim = DIM_HEAD_BERT,       #substitute with DIM_HEAD if you want to try without BERT\n",
        "    max_memories = 1000,       #maximum number of memories (old ones will be discarded after reaching maximum capacity)\n",
        "    num_indices = BATCH_SIZE   #each batch keeps track of its own memories, expiring when it sees a new document\n",
        ")\n",
        "\n",
        "train_loader_ = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)\n",
        "test_loader_ = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)"
      ],
      "metadata": {
        "id": "1gVvmKCm3J4A",
        "outputId": "5f3ff21e-9d23-48da-9ac1-a4fbd8ce44a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 433/433 [00:00<00:00, 238839.25B/s]\n",
            "100%|██████████| 440473133/440473133 [00:35<00:00, 12579378.68B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epochs = 5\n",
        "# training\n",
        "\n",
        "perplexity_list = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, data in enumerate(tqdm.tqdm(train_loader_, desc = 'training')):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "\n",
        "    num_seq = 10000 // (SEQ_LEN + 1)\n",
        "    data = data.long().to(device)\n",
        "    for j in range(num_seq):\n",
        "      mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "      seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "      out = model(\n",
        "        seq,\n",
        "        knn_memory = memory\n",
        "      )\n",
        "      loss_item = loss(out, labels)\n",
        "      print(f'training loss: {loss_item}', flush = True)\n",
        "      loss_item.backward() \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "  data = None\n",
        "\n",
        "  if e % EVAL_EVERY == 0:\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      metric = Perplexity().to(device)\n",
        "      for i, data in enumerate(tqdm.tqdm(test_loader_, desc = 'evaluation')):\n",
        "        num_seq = 10000 // (SEQ_LEN + 1)\n",
        "        data = data.long().to(device)\n",
        "\n",
        "        for j in range(num_seq):\n",
        "          mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "          seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "          out = model(\n",
        "            seq,\n",
        "            knn_memory = memory\n",
        "          )\n",
        "          test_loss = loss(out, labels)\n",
        "          metric(out.transpose(1, 2), labels)\n",
        "          #print(f'test loss: {test_loss}', flush = True)\n",
        "\n",
        "      perplexity = metric.compute()\n",
        "      perplexity_list.append(perplexity.to(\"cpu\").item())\n",
        "      print(f'perplexity: {perplexity}', flush = True)\n",
        "\n",
        "  data = None\n",
        "  if e % CHECKPOINT == 0:\n",
        "    torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, 'model_optimizer.pt')\n",
        "    \"\"\"\n",
        "    #Lorenzo\n",
        "    with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity_moreNN.npy', 'wb') as f:\n",
        "      np.save(f, np.array(perplexity_list))\n",
        "    \"\"\"\n",
        "    #Luigi\n",
        "    with open(f'drive/MyDrive/Colab Notebooks/perplexity_memorizing_tr.pkl', 'wb') as pklfile:\n",
        "      pkl.dump(perplexity_list, pklfile)\n"
      ],
      "metadata": {
        "id": "9sF-vlC6koIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#Luigi\n",
        "perplexity_list = []\n",
        "with open(f'drive/MyDrive/Colab Notebooks/perplexity_memorizing_tr.pkl', 'rb') as pklfile:\n",
        "  perplexity_list = pkl.load(pklfile)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "16-Mkrn0WGN4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(perplexity_list, label = \"Memorizing Transformer Perplexity Plot\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n1DiMQgKWJnx",
        "outputId": "8fa95ffb-518b-4bec-df82-ea47585ed1e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer decoder training"
      ],
      "metadata": {
        "id": "ayPdgmodFg4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module): #decoder-only architecture of the transformer\n",
        "  def __init__(\n",
        "        self,\n",
        "        num_tokens,\n",
        "        d,\n",
        "        heads = 8,\n",
        "        depth = 4,\n",
        "        hidden_size = 1000,\n",
        "        dropout = 0.3,\n",
        "        batch_size = 16,\n",
        "        use_bert = True\n",
        "    ):\n",
        "      # asserts\n",
        "      self.d = d if not use_bert else 768\n",
        "      assert self.d % heads == 0\n",
        " \n",
        "      super(TransformerDecoder, self).__init__()\n",
        "      self.token_emb = nn.Embedding(num_tokens, self.d)\n",
        "      self.positional_enc = PositionalEncoding(self.d, max_len = 5000)\n",
        "      self.dim_head = self.d // heads\n",
        "      self.heads = heads\n",
        "      self.depth = depth\n",
        "      self.hidden_size = hidden_size\n",
        "      self.dropout = dropout\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      self.layers = nn.ModuleList([])\n",
        "      for idx in range(depth):\n",
        "          self.layers.append(\n",
        "              TransformerBlock(d, heads, batch_size, hidden_size, dropout)\n",
        "          )\n",
        "\n",
        "      self.to_out = nn.Linear(d, num_tokens)\n",
        "    \n",
        "  def create_mask(self, x):\n",
        "    batch_size, seq_len = x.shape\n",
        "    mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "        batch_size, 1, seq_len, seq_len\n",
        "    )\n",
        "    return mask \n",
        "          \n",
        "  def forward(self, x):\n",
        "    mask = self.create_mask(x)\n",
        "\n",
        "    x = self.token_emb(x)\n",
        "    x = self.positional_enc(x)\n",
        "\n",
        "    for idx in range(self.depth):\n",
        "        x= self.layers[idx](x, mask)\n",
        "\n",
        "    return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "lBz91btCHjXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "SEQ_LEN = 256\n",
        "SEGMENTS = 5\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS\n",
        "DIM_HEAD_BERT = 768 // HEADS\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 20\n",
        "CHECKPOINT = 5"
      ],
      "metadata": {
        "id": "sF-Xk7gtKMA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tr_decoder = TransformerDecoder(\n",
        "    num_tokens = vocabulary,\n",
        "    d = SEQ_LEN,\n",
        "    depth = 4,\n",
        "    heads = HEADS,\n",
        "    hidden_size = 5000,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    use_bert = True\n",
        ").to(device)\n",
        "\n",
        "train_loader_ = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)\n",
        "test_loader_ = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)"
      ],
      "metadata": {
        "id": "GOz3oBuiGkYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "optimizer = torch.optim.Adam(tr_decoder.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epochs = 5\n",
        "# training\n",
        "\n",
        "perplexity_tr_decoder = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, data in enumerate(tqdm.tqdm(train_loader_, desc = 'training')):\n",
        "    tr_decoder.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "\n",
        "    num_seq = 10000 // (SEQ_LEN + 1)\n",
        "    data = data.long().to(device)\n",
        "    for j in range(num_seq):\n",
        "      mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "      seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "\n",
        "      out = tr_decoder(seq)\n",
        "\n",
        "      loss_item = loss(out, labels)\n",
        "      print(f'training loss: {loss_item}', flush = True)\n",
        "      loss_item.backward() \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "  data = None\n",
        "    \n",
        "\n",
        "  if e % EVAL_EVERY == 0:\n",
        "    tr_decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      metric = Perplexity().to(device)\n",
        "      for i, data in enumerate(tqdm.tqdm(test_loader_, desc = 'evaluation')):\n",
        "        num_seq = 10000 // (SEQ_LEN + 1)\n",
        "        data = data.long().to(device)\n",
        "\n",
        "        for j in range(num_seq):\n",
        "          mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "          seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "\n",
        "          out = tr_decoder(seq)\n",
        "\n",
        "          test_loss = loss(out, labels)\n",
        "          metric(out.transpose(1, 2), labels)\n",
        "          print(f'test loss: {test_loss}', flush = True)\n",
        "\n",
        "      perplexity = metric.compute()\n",
        "      perplexity_tr_decoder.append(perplexity.to(\"cpu\").item())\n",
        "      print(f'perplexity: {perplexity}', flush = True)\n",
        "\n",
        "  data = None\n",
        "  if e % CHECKPOINT == 0:\n",
        "    torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, 'model_optimizer.pt')\n",
        "    \"\"\"\n",
        "    #Lorenzo\n",
        "    with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity_moreNN.npy', 'wb') as f:\n",
        "      np.save(f, np.array(perplexity_list))\n",
        "    \"\"\"\n",
        "    with open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\n",
        "      pkl.dump(perplexity_tr_decoder, pklfile)\n",
        "\n",
        "plt.plot(perplexity_tr_decoder, label = \"Transformer Decoder Perplexity Plot\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tqKuP2z1BeFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "perplexity_tr_decoder = []\n",
        "with open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\n",
        "  perplexity_tr_decoder = pkl.load(pklfile)\n",
        "  pklfile.close()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QcYwi7zKXre0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "89d72de5-e537-4baf-ff4f-1cf5caf6b5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nperplexity_tr_decoder = []\\nwith open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\\n  perplexity_tr_decoder = pkl.load(pklfile)\\n  pklfile.close()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(perplexity_tr_decoder, label = 'Perplexity transformer decoder')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1rb7IdThijCp",
        "outputId": "adb7e5eb-6ed9-4d18-a850-d370c7554260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "zzz"
      ],
      "metadata": {
        "id": "uTPL4pa61mUs"
      }
    }
  ]
}