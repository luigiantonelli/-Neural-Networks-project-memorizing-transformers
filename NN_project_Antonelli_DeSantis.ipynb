{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/NN-project-memorizing-transformers/blob/main/NN_project_Antonelli_DeSantis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports"
      ],
      "metadata": {
        "id": "-4GElPh7HbB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW8KnU4lPkgI",
        "outputId": "ba0e455a-9ca2-47e9-9b69-d73e1f6978fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_transformers import BertTokenizer\n",
        "from pytorch_transformers import BertModel"
      ],
      "metadata": {
        "id": "G5xdOnnKPbxi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata --quiet\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install torchtext --quiet\n",
        "!pip install -U spacy --quiet\n",
        "!python -m spacy download en_core_web_sm --quiet"
      ],
      "metadata": {
        "id": "oZJbIamFP23c",
        "outputId": "e0cae71c-772d-4666-b9be-a0315fa7f8b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from pathlib import Path\n",
        "from filelock import FileLock\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pickle as pkl\n",
        "import torchtext\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import spacy\n",
        "from typing import Iterable, List\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchmetrics.text.perplexity import Perplexity\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "Kd714QnlGIP-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a4BTaVB5Pxs",
        "outputId": "33e63d87-1681-4a6e-a249-07d8dbf53b98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "zAXedSwA5nyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 16\n",
        "SEQ_LEN = 512\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS\n",
        "\n",
        "LEARNING_RATE = 1e-3 #2e-4 prima era così\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 20\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 512\n",
        "CHECKPOINT = 10\n",
        "\n"
      ],
      "metadata": {
        "id": "nIq8h5NB87h4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, test_iter = WikiText2(split = ('train', 'test'))"
      ],
      "metadata": {
        "id": "jag9JLsDbyOB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from itertools import chain\n",
        "data_iter = chain(train_iter, test_iter)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J4Lo0Rsz7fT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "token_transform = get_tokenizer('spacy', language = 'en_core_web_sm')\n",
        "\n",
        "def yield_tokens(data) -> List[str]:\n",
        "    for line in data:\n",
        "        yield token_transform(line)\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "vocabulary_ = build_vocab_from_iterator(yield_tokens(data_iter), min_freq = 1, specials = special_symbols, special_first = True)\n",
        "vocabulary_.set_default_index(UNK_IDX)\n",
        "vocabulary_.__len__()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uvcwcyno7i6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def preprocessing_(dataset):\n",
        "  new_ds = torch.tensor([], dtype = torch.int32)\n",
        "  for line in dataset:\n",
        "    tokenized_line = torch.tensor([vocabulary_[token] for token in token_transform(line)])\n",
        "    new_ds = torch.cat((new_ds, tokenized_line))\n",
        "  return new_ds\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0JbiwRcz8G7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_ds = preprocessing_(train_iter)\n",
        "test_ds = preprocessing_(test_iter)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "R29fLy2G8fIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zlNANpHQiOt",
        "outputId": "b3f5038c-b5c3-4ac8-d63c-072912092ced"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 261967.05B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(dataset):\n",
        "  new_ds = []\n",
        "  for line in dataset:\n",
        "    tokenized_line = tokenizer.tokenize(line)\n",
        "    new_ds.append(tokenized_line)\n",
        "  return new_ds"
      ],
      "metadata": {
        "id": "RnfQlE72RQCR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = preprocessing(train_iter)\n",
        "test_ds = preprocessing(test_iter)"
      ],
      "metadata": {
        "id": "t4ZDCYlDRei8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tokens_to_idxs(dataset):\n",
        "  new_ds = torch.tensor([], dtype = torch.int32)\n",
        "  for line in dataset:\n",
        "    tokenized_line = torch.tensor(tokenizer.convert_tokens_to_ids(line))    \n",
        "    new_ds = torch.cat((new_ds, tokenized_line))\n",
        "  return new_ds"
      ],
      "metadata": {
        "id": "_wQHPc5URusJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = convert_tokens_to_idxs(train_ds)\n",
        "test_ds = convert_tokens_to_idxs(test_ds)"
      ],
      "metadata": {
        "id": "VjlekiRPSahL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCEOkwkgTQiS",
        "outputId": "90f23659-6d98-4a0d-f0f8-a9c859b63743"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2405592])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = 30522"
      ],
      "metadata": {
        "id": "juDl2xbjdzEF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "print(len(train_loader))\n",
        "train_ds = torch.zeros((len(train_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(train_loader):\n",
        "  train_ds[i] = document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zCX45xyL955",
        "outputId": "aadb0b9a-2a59-43a2-e6fa-8849c1139931"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "\n",
        "test_ds = torch.zeros((len(test_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(test_loader):\n",
        "  test_ds[i] = document"
      ],
      "metadata": {
        "id": "KlSGhT9-dCDt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGcfKRdsP98_",
        "outputId": "54ef355d-f0d7-4c26-b357-a176322072ab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([240, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.shape"
      ],
      "metadata": {
        "id": "B0wCMRhZdatc",
        "outputId": "844fd482-b89c-460b-8092-6ca48f236687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Memory"
      ],
      "metadata": {
        "id": "4I2ce2jPLzle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QppURbZ0KL0f",
        "outputId": "8eefd167-8219-4ba2-eeca-04be258b9d8b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krC3-klsLPVa",
        "outputId": "1f2464f6-bf00-44e8-e06f-847f954bb422"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import per la knn memory\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import wraps\n",
        "\n",
        "from contextlib import ExitStack, contextmanager\n",
        "\n",
        "from einops import rearrange, pack, unpack\n",
        "\n",
        "# multiprocessing\n",
        "\n",
        "from joblib import Parallel, delayed, cpu_count"
      ],
      "metadata": {
        "id": "KeHkdSn0KBSP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FAISS_INDEX_GPU_ID = int(os.getenv('FAISS_INDEX_GPU_ID', 0))\n",
        "\n",
        "DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY = './.tmp/knn.memories'\n",
        "\n",
        "# helper functions\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "def cast_list(val):\n",
        "    return val if isinstance(val, list) else [val]\n",
        "\n",
        "def all_el_unique(arr):\n",
        "    return len(set(arr)) == len(arr)\n",
        "\n",
        "@contextmanager\n",
        "def multi_context(*cms):\n",
        "    with ExitStack() as stack:\n",
        "        yield [stack.enter_context(cls) for cls in cms]\n",
        "\n",
        "def count_intersect(x, y):\n",
        "    # returns an array that shows how many times an element in x is contained in tensor y\n",
        "    return np.sum(rearrange(x, 'i -> i 1') == rearrange(y, 'j -> 1 j'), axis = -1)\n",
        "\n",
        "def check_shape(tensor, pattern, **kwargs):\n",
        "    return rearrange(tensor, f\"{pattern} -> {pattern}\", **kwargs)\n",
        "\n",
        "# a wrapper around faiss IndexIVFFlat\n",
        "# taking care of expiring old keys automagically\n",
        "\n",
        "class KNN():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_num_entries,\n",
        "        cap_num_entries = False,\n",
        "        M = 15,\n",
        "        keep_stats = False\n",
        "    ):\n",
        "        index = faiss.IndexHNSWFlat(dim, M, faiss.METRIC_INNER_PRODUCT)\n",
        "        self.index = index\n",
        "        self.max_num_entries = max_num_entries\n",
        "        self.cap_num_entries = cap_num_entries\n",
        "        self.is_trained = False\n",
        "        self.keep_stats = keep_stats\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'index'):\n",
        "            del self.index\n",
        "\n",
        "    def reset(self):\n",
        "        self.ids = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.empty((0,), dtype = np.int32)\n",
        "            self.age_num_iterations = np.empty((0,), dtype = np.int32)\n",
        "            self.ages_since_last_hit = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        self.index.reset()\n",
        "        self.is_trained = False\n",
        "\n",
        "    def train(self, x):\n",
        "        self.index.train(x)\n",
        "        self.is_trained = True\n",
        "\n",
        "    def add(self, x, ids):\n",
        "        if not self.is_trained:\n",
        "            self.train(x)\n",
        "\n",
        "        self.ids = np.concatenate((ids, self.ids))\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.concatenate((np.zeros_like(ids), self.hits))\n",
        "            self.age_num_iterations = np.concatenate((np.zeros_like(ids), self.age_num_iterations))\n",
        "            self.ages_since_last_hit = np.concatenate((np.zeros_like(ids), self.ages_since_last_hit))\n",
        "\n",
        "        if self.cap_num_entries and len(self.ids) > self.max_num_entries:\n",
        "            self.reset()\n",
        "\n",
        "        return self.index.add(x)\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        x,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        return_distances = False,\n",
        "        increment_hits = False,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        if not self.is_trained:\n",
        "            return np.full((x.shape[0], topk), -1)\n",
        "\n",
        "        distances, indices = self.index.search(x, k = topk)\n",
        "\n",
        "        if increment_hits and self.keep_stats:\n",
        "            hits = count_intersect(self.ids, rearrange(indices, '... -> (...)'))\n",
        "            self.hits += hits\n",
        "\n",
        "            self.ages_since_last_hit += 1\n",
        "            self.ages_since_last_hit *= (hits == 0)\n",
        "\n",
        "        if increment_age and self.keep_stats:\n",
        "            self.age_num_iterations += 1\n",
        "\n",
        "        if return_distances:\n",
        "            return indices, distances\n",
        "\n",
        "        return indices\n",
        "\n",
        "# KNN memory layer, where one can store key / value memories\n",
        "# can automatically take care of a collection of faiss indices (across batch dimension)\n",
        "\n",
        "class KNNMemory():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_memories = 16000,\n",
        "        num_indices = 1,\n",
        "        memmap_filename = './knn.memory.memmap',\n",
        "        multiprocessing = True\n",
        "    ):\n",
        "        self.dim = dim\n",
        "        self.num_indices = num_indices\n",
        "        self.scoped_indices = list(range(num_indices))\n",
        "\n",
        "        self.max_memories = max_memories\n",
        "        self.shape = (num_indices, max_memories, 2, dim)\n",
        "        self.db_offsets = np.zeros(num_indices, dtype = np.int32)\n",
        "\n",
        "        self.db = np.memmap(memmap_filename, mode = 'w+', dtype = np.float32, shape = self.shape)\n",
        "        self.knns = [KNN(dim = dim, max_num_entries = max_memories, cap_num_entries = True) for _ in range(num_indices)]\n",
        "    \n",
        "        self.n_jobs = cpu_count() if multiprocessing else 1\n",
        "\n",
        "    def set_scoped_indices(self, indices):\n",
        "        indices = list(indices)\n",
        "        assert all_el_unique(indices), f'all scoped batch indices must be unique, received: {indices}'\n",
        "        assert all([0 <= i < self.num_indices for i in indices]), f'each batch index must be between 0 and less than {self.num_indices}: received {indices}'\n",
        "        self.scoped_indices = indices\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(self, indices):\n",
        "        prev_indices = self.scoped_indices\n",
        "        self.set_scoped_indices(indices)\n",
        "        yield self\n",
        "        self.set_scoped_indices(prev_indices)\n",
        "\n",
        "    def clear(self, batch_indices = None):\n",
        "        if not exists(batch_indices):\n",
        "            batch_indices = list(range(self.num_indices))\n",
        "\n",
        "        batch_indices = cast_list(batch_indices)\n",
        "\n",
        "        for index in batch_indices:\n",
        "            knn = self.knns[index]\n",
        "            knn.reset()\n",
        "\n",
        "        self.db_offsets[batch_indices] = 0\n",
        "\n",
        "    def add(self, memories):\n",
        "        check_shape(memories, 'b n kv d', d = self.dim, kv = 2, b = len(self.scoped_indices))\n",
        "\n",
        "        memories = memories.detach().cpu().numpy()\n",
        "        memories = memories[:, -self.max_memories:]\n",
        "        num_memories = memories.shape[1]\n",
        "\n",
        "        knn_insert_ids = np.arange(num_memories)\n",
        "\n",
        "        keys = np.ascontiguousarray(memories[..., 0, :])\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "        db_offsets = [self.db_offsets[i] for i in self.scoped_indices]\n",
        "\n",
        "        # use joblib to insert new key / value memories into faiss index\n",
        "\n",
        "        @delayed\n",
        "        def knn_add(knn, key, db_offset):\n",
        "            knn.add(key, ids = knn_insert_ids + db_offset)\n",
        "            return knn\n",
        "\n",
        "        updated_knns = Parallel(n_jobs = self.n_jobs)(knn_add(*args) for args in zip(knns, keys, db_offsets))\n",
        "        for knn_idx, scoped_idx in enumerate(self.scoped_indices):\n",
        "            self.knns[scoped_idx] = updated_knns[knn_idx]\n",
        "\n",
        "        # add the new memories to the memmap \"database\"\n",
        "\n",
        "        add_indices = (rearrange(np.arange(num_memories), 'j -> 1 j') + rearrange(self.db_offsets[list(self.scoped_indices)], 'i -> i 1')) % self.max_memories\n",
        "        self.db[rearrange(np.array(self.scoped_indices), 'i -> i 1'), add_indices] = memories\n",
        "        self.db.flush()\n",
        "\n",
        "        self.db_offsets += num_memories\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        queries,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        increment_hits = True,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        check_shape(queries, 'b ... d', d = self.dim, b = len(self.scoped_indices))\n",
        "        queries, ps = pack([queries], 'b * d')\n",
        "\n",
        "        device = queries.device\n",
        "        queries = queries.detach().cpu().numpy()\n",
        "\n",
        "        all_masks = []\n",
        "        all_key_values = []\n",
        "\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "\n",
        "        # parallelize faiss search\n",
        "\n",
        "        @delayed\n",
        "        def knn_search(knn, query):\n",
        "            return knn.search(query, topk, nprobe, increment_hits = increment_hits, increment_age = increment_age)\n",
        "\n",
        "        fetched_indices = Parallel(n_jobs = self.n_jobs)(knn_search(*args) for args in zip(knns, queries))\n",
        "\n",
        "        # get all the memory key / values from memmap 'database'\n",
        "        # todo - remove for loop below\n",
        "\n",
        "        for batch_index, indices in zip(self.scoped_indices, fetched_indices):\n",
        "            mask = indices !=  -1\n",
        "            db_indices = np.where(mask, indices, 0)\n",
        "\n",
        "            all_masks.append(torch.from_numpy(mask))\n",
        "\n",
        "            key_values = self.db[batch_index, db_indices % self.max_memories]\n",
        "            all_key_values.append(torch.from_numpy(key_values))\n",
        "\n",
        "        all_masks = torch.stack(all_masks)\n",
        "        all_key_values = torch.stack(all_key_values)\n",
        "        all_key_values = all_key_values.masked_fill(~rearrange(all_masks, '... -> ... 1 1'), 0.)\n",
        "\n",
        "        all_key_values, = unpack(all_key_values, ps, 'b * n kv d')\n",
        "        all_masks, = unpack(all_masks, ps, 'b * n')\n",
        "\n",
        "        return all_key_values.to(device), all_masks.to(device)\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'knns'):\n",
        "            for knn in self.knns:\n",
        "                del knn\n",
        "        del self.db\n",
        "\n",
        "# extends list with some extra methods for collections of KNN memories\n",
        "\n",
        "class KNNMemoryList(list):\n",
        "    def cleanup(self):\n",
        "        for memory in self:\n",
        "            del memory\n",
        "\n",
        "    @classmethod\n",
        "    def create_memories(\n",
        "        self,\n",
        "        *,\n",
        "        batch_size,\n",
        "        num_memory_layers,\n",
        "        memories_directory = DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY\n",
        "    ):\n",
        "        memories_path = Path(memories_directory)\n",
        "        memories_path.mkdir(exist_ok = True, parents = True)\n",
        "\n",
        "        def inner(*args, **kwargs):\n",
        "            return self([KNNMemory(*args, num_indices = batch_size, memmap_filename = str(memories_path / f'knn.memory.layer.{ind + 1}.memmap'), **kwargs) for ind in range(num_memory_layers)])\n",
        "        return inner\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(\n",
        "        self,\n",
        "        indices\n",
        "    ):\n",
        "        knn_batch_indices_contexts = [memory.at_batch_indices(indices) for memory in self]\n",
        "        with multi_context(*knn_batch_indices_contexts):\n",
        "            yield\n",
        "\n",
        "    def clear_memory(\n",
        "        self,\n",
        "        batch_indices = None,\n",
        "        memory_indices = None\n",
        "    ):\n",
        "        memory_indices = default(memory_indices, tuple(range(len(self))))\n",
        "\n",
        "        for memory_index in memory_indices:\n",
        "            memory = self[memory_index]\n",
        "            memory.clear(batch_indices)"
      ],
      "metadata": {
        "id": "E5Wk2XJSLr-9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memorizing transformers"
      ],
      "metadata": {
        "id": "tWJS8R3fL7RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value, sqrt_q, device, mask = None):\n",
        "    t = torch.matmul(query, key.transpose(-2, -1))/sqrt_q\n",
        "    if mask is not None:\n",
        "      t = t.masked_fill_(mask == 0, -1e-9)\n",
        "    return torch.matmul(F.softmax(t, dim = -1), value)\n",
        "\n",
        "def KNNattention(query, key, value, sqrt_q, mask):\n",
        "    t = torch.einsum('b h i q, b h i j q -> b h i j', query, key)/sqrt_q\n",
        "    return torch.einsum('b h i j, b h i j q -> b h i q', F.softmax(t.masked_fill_(mask, -1e-9), dim = -1), value)"
      ],
      "metadata": {
        "id": "ZK8XwbNMp5vT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d, h, batch_size):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    assert d % h == 0\n",
        "    #assume q = v \n",
        "    self.q = d // h #single head dimension\n",
        "    self.sqrt_q = sqrt(self.q)\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.W_q = nn.Linear(d, d, bias = False) #stack of h matrices of dimension (d, q), one for each head\n",
        "    self.W_k = nn.Linear(d, d, bias = False)\n",
        "    self.W_v = nn.Linear(d, d, bias = False)\n",
        "    self.W_o = nn.Linear(d, d, bias = False)\n",
        "\n",
        "  def forward(self, x, mask = None):\n",
        "    query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    #new_memories = torch.stack((key, value), dim = -2).detach()\n",
        "    attention_value = attention(query, key, value, self.sqrt_q, mask)\n",
        "    return self.W_o(attention_value.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q))"
      ],
      "metadata": {
        "id": "AwoLII4LMvUK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNAttention(nn.Module):\n",
        "   def __init__(self, d, h, batch_size, num_retrieved_memories):\n",
        "      super(KNNAttention, self).__init__()\n",
        "      assert d % h == 0\n",
        "      #assume q = v \n",
        "      self.q = d // h\n",
        "      self.sqrt_q = sqrt(self.q)\n",
        "      self.h = h\n",
        "      self.W_q = nn.Linear(d, d, bias = False)\n",
        "      self.W_k = nn.Linear(d, d, bias = False)\n",
        "      self.W_v = nn.Linear(d, d, bias = False)\n",
        "      self.W_o = nn.Linear(d, d, bias = False)\n",
        "      self.b_g = nn.Parameter(torch.randn((h,))) #one for each head\n",
        "      self.num_retrieved_memories = num_retrieved_memories\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "   def forward(self, x, mask, knn_memory):\n",
        "      # calculate local attention \n",
        "      query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      local_attention = attention(query, key, value, self.sqrt_q, mask)\n",
        "\n",
        "      # calculate knn attention over memory\n",
        "      query = F.normalize(query, dim = -1)\n",
        "      key = F.normalize(key, dim = -1)\n",
        "      mem_kv, mem_mask = knn_memory.search(query, self.num_retrieved_memories)\n",
        "      mem_key, mem_value = mem_kv.unbind(dim = -2)\n",
        "      knn_attention = KNNattention(query, mem_key, mem_value, self.sqrt_q, ~mem_mask)\n",
        "\n",
        "      # memory to be stored\n",
        "      new_kv_memories = torch.stack((key, value), dim = -2).view(self.batch_size, -1, 2, self.q).detach()\n",
        "\n",
        "      # add to knn memory\n",
        "      if new_kv_memories.numel() > 0:\n",
        "        knn_memory.add(new_kv_memories)\n",
        "\n",
        "      # combining local and memory\n",
        "      g = torch.sigmoid(self.b_g)\n",
        "      final_attention = torch.einsum('b h n q, h -> b h n q', knn_attention, g) + \\\n",
        "                        torch.einsum('b h n q, h -> b h n q', local_attention, (1 - g))\n",
        "      \n",
        "      return self.W_o(final_attention.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q))"
      ],
      "metadata": {
        "id": "921DW0jjMyWx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    # Compute the positional encodings once in log space.\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
        "                          -(math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    return x + Variable(self.pe[:, :x.size(1)], requires_grad=False)"
      ],
      "metadata": {
        "id": "9U77GkT0cT4u"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, d, h, batch_size, hidden_size, dropout, is_mem = False, num_retrieved_memories = 32):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.d = d\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = MultiHeadAttention(d, h, batch_size) if not is_mem else KNNAttention(d, h, batch_size, num_retrieved_memories)\n",
        "    self.norm1 = nn.LayerNorm(d)\n",
        "    self.dropout1 = nn.Dropout(dropout)\n",
        "    self.norm2 = nn.LayerNorm(d)\n",
        "    self.dropout2 = nn.Dropout(dropout)\n",
        "    self.ff = nn.Sequential(nn.Linear(d, hidden_size, bias = True), \n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(dropout),\n",
        "                            nn.Linear(hidden_size, d, bias = True))\n",
        "  def forward(self, x, mask, knn_memory = None):\n",
        "    if knn_memory is None:\n",
        "      x = self.attention(x, mask)\n",
        "    else:\n",
        "      x = self.attention(x, mask, knn_memory)\n",
        "    x = self.dropout1(x + self.norm1(x))\n",
        "    x = x + self.ff(x)\n",
        "    x = self.dropout2(self.norm2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "prYm-KEpwLQq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module): #block of the classic transformer decoder (not used)\n",
        "  def __init__(self, d, h, batch_size, hidden_size, dropout):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    self.attention = MultiHeadAttention(d, h, batch_size)\n",
        "    self.norm = nn.LayerNorm(d)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.transformer_block = TransformerBlock(d, h, batch_size, hidden_size, dropout)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = self.attention(x, mask)\n",
        "    x = self.dropout(self.norm(x))\n",
        "    return self.transformer_block(x)"
      ],
      "metadata": {
        "id": "P4fkZ_djysyF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MemorizingTransformer(nn.Module):\n",
        "    def __init__(\n",
        "          self,\n",
        "          num_tokens,\n",
        "          d,\n",
        "          heads = 8,\n",
        "          depth = 4,\n",
        "          knn_attn_idx = 2,\n",
        "          attn_dropout = 0.,\n",
        "          hidden_size = 1000,\n",
        "          dropout = 0.3,\n",
        "          max_knn_memories = 1000,\n",
        "          num_retrieved_memories = 32,\n",
        "          batch_size = 16,\n",
        "          use_bert = True\n",
        "      ):\n",
        "          # asserts\n",
        "          self.d = d if not use_bert else 768\n",
        "          assert self.d % heads == 0\n",
        "          assert knn_attn_idx < depth\n",
        "\n",
        "          super(MemorizingTransformer, self).__init__()\n",
        "          #self.token_emb = nn.Embedding(num_tokens, self.d) #without BERT\n",
        "          self.token_emb = BertModel.from_pretrained('bert-base-uncased')\n",
        "          self.positional_enc = PositionalEncoding(self.d, max_len = 5000)\n",
        "          self.dim_head = self.d // heads\n",
        "          \n",
        "          self.heads = heads\n",
        "          self.knn_attn_idx = knn_attn_idx\n",
        "          self.depth = depth\n",
        "          self.attn_dropout = attn_dropout\n",
        "          self.hidden_size = hidden_size\n",
        "          self.dropout = dropout\n",
        "          self.max_knn_memories = max_knn_memories\n",
        "          self.num_retrieved_memories = num_retrieved_memories\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "          self.layers = nn.ModuleList([])\n",
        "          for idx in range(depth):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(self.d, heads, batch_size, hidden_size, dropout, is_mem = idx == self.knn_attn_idx)\n",
        "            )\n",
        "\n",
        "          self.to_out = nn.Linear(self.d, num_tokens)\n",
        "    \n",
        "    def create_mask(self, x):\n",
        "      batch_size, seq_len = x.shape\n",
        "      mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "          batch_size, 1, seq_len, seq_len)\n",
        "      return mask    \n",
        "          \n",
        "    def forward(self, x, knn_memory):\n",
        "      mask = self.create_mask(x)\n",
        "      #x = self.token_emb(x) #without BERT\n",
        "      x = self.token_emb(x)[0] #with BERT\n",
        "      x = self.positional_enc(x)\n",
        "\n",
        "      for idx in range(self.depth):\n",
        "          x= self.layers[idx](x, mask, knn_memory = knn_memory if idx == self.knn_attn_idx else None)\n",
        "\n",
        "      return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "F5uqCzrVL569"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ihBnTrPhaiDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "SEQ_LEN = 256\n",
        "SEGMENTS = 5\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS \n",
        "DIM_HEAD_BERT = 768 // HEADS #now it's 96 with bert -> 768/8\n",
        "\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 1\n",
        "CHECKPOINT = 1"
      ],
      "metadata": {
        "id": "ncWOJOkFanTK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "memory = None\n",
        "data = None\n",
        "train_loader_ = None\n",
        "test_loader_ = None"
      ],
      "metadata": {
        "id": "kWjcjNDgEiuS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MemorizingTransformer(\n",
        "    num_tokens = vocabulary,\n",
        "    d = SEQ_LEN,\n",
        "    heads = HEADS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    depth = 4,\n",
        "    knn_attn_idx = 2,\n",
        "    num_retrieved_memories = 32,\n",
        "    use_bert = True #False if you want to try without BERT\n",
        ").to(device)\n",
        "\n",
        "memory = KNNMemory(\n",
        "    dim = DIM_HEAD_BERT,       #substitute with DIM_HEAD if you want to try without BERT\n",
        "    max_memories = 1000,       #maximum number of memories (old ones will be discarded after reaching maximum capacity)\n",
        "    num_indices = BATCH_SIZE   #each batch keeps track of its own memories, expiring when it sees a new document\n",
        ")\n",
        "\n",
        "train_loader_ = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)\n",
        "test_loader_ = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)"
      ],
      "metadata": {
        "id": "1gVvmKCm3J4A"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_string(a):\n",
        "  seq = \"\"\n",
        "  for word in a:\n",
        "    for letter in word:\n",
        "      seq += chr(letter)\n",
        "    seq += \" \"\n",
        "  return seq"
      ],
      "metadata": {
        "id": "e6Apbm_X-ceS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epochs = 5\n",
        "# training\n",
        "\n",
        "perplexity_list = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, data in enumerate(tqdm.tqdm(train_loader_, desc = 'training')):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "\n",
        "    num_seq = 10000 // (SEQ_LEN + 1)\n",
        "    data = data.long().to(device)\n",
        "    for j in range(num_seq):\n",
        "      mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "      seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "      out = model(\n",
        "        seq,\n",
        "        knn_memory = memory\n",
        "      )\n",
        "      loss_item = loss(out, labels)\n",
        "      print(f'training loss: {loss_item}', flush = True)\n",
        "      loss_item.backward() \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "  data = None\n",
        "\n",
        "  if e % EVAL_EVERY == 0:\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      metric = Perplexity().to(device)\n",
        "      for i, data in enumerate(tqdm.tqdm(test_loader_, desc = 'evaluation')):\n",
        "        num_seq = 10000 // (SEQ_LEN + 1)\n",
        "        data = data.long().to(device)\n",
        "\n",
        "        for j in range(num_seq):\n",
        "          mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "          seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "          out = model(\n",
        "            seq,\n",
        "            knn_memory = memory\n",
        "          )\n",
        "          test_loss = loss(out, labels)\n",
        "          metric(out.transpose(1, 2), labels)\n",
        "          #print(f'test loss: {test_loss}', flush = True)\n",
        "\n",
        "      perplexity = metric.compute()\n",
        "      perplexity_list.append(perplexity.to(\"cpu\").item())\n",
        "      print(f'perplexity: {perplexity}', flush = True)\n",
        "\n",
        "  data = None\n",
        "  if e % CHECKPOINT == 0:\n",
        "    torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, 'model_optimizer.pt')\n",
        "    \"\"\"\n",
        "    #Lorenzo\n",
        "    with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity_moreNN.npy', 'wb') as f:\n",
        "      np.save(f, np.array(perplexity_list))\n",
        "    \"\"\"\n",
        "    with open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\n",
        "      pkl.dump(perplexity_list, pklfile)\n",
        "\n",
        "plt.plot(perplexity_list, label = \"Memorizing Transformer Perplexity Plot\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9sF-vlC6koIo",
        "outputId": "47eca98e-126d-43e7-c14e-d9b6600deac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "evaluation: 100%|██████████| 7/7 [05:17<00:00, 45.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 692.0040283203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "evaluation:   0%|          | 0/7 [00:17<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-875e224f78bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LEN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LEN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m           out = model(\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mknn_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-57585271b61a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, knn_memory)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_memory\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn_attn_idx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-eff63d6f1f52>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask, knn_memory)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-dff5ec3eccec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask, knn_memory)\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mmem_kv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_retrieved_memories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mmem_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmem_kv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mknn_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mmem_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-c1d99043efa8>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, queries, topk, nprobe, increment_hits, increment_age)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mall_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mall_key_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_key_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mall_key_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_key_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'... -> ... 1 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mall_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b * n kv d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer decoder training"
      ],
      "metadata": {
        "id": "ayPdgmodFg4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module): #decoder-only architecture of the transformer\n",
        "  def __init__(\n",
        "        self,\n",
        "        num_tokens,\n",
        "        d,\n",
        "        heads = 8,\n",
        "        depth = 4,\n",
        "        hidden_size = 1000,\n",
        "        dropout = 0.3,\n",
        "        batch_size = 16,\n",
        "        use_bert = True\n",
        "    ):\n",
        "      # asserts\n",
        "      self.d = d if not use_bert else 768\n",
        "      assert self.d % heads == 0\n",
        " \n",
        "      super(TransformerDecoder, self).__init__()\n",
        "      self.token_emb = nn.Embedding(num_tokens, self.d)\n",
        "      self.positional_enc = PositionalEncoding(self.d, max_len = 5000)\n",
        "      self.dim_head = self.d // heads\n",
        "      self.heads = heads\n",
        "      self.depth = depth\n",
        "      self.hidden_size = hidden_size\n",
        "      self.dropout = dropout\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      self.layers = nn.ModuleList([])\n",
        "      for idx in range(depth):\n",
        "          self.layers.append(\n",
        "              TransformerBlock(d, heads, batch_size, hidden_size, dropout)\n",
        "          )\n",
        "\n",
        "      self.to_out = nn.Linear(d, num_tokens)\n",
        "    \n",
        "  def create_mask(self, x):\n",
        "    batch_size, seq_len = x.shape\n",
        "    mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "        batch_size, 1, seq_len, seq_len\n",
        "    )\n",
        "    return mask \n",
        "          \n",
        "  def forward(self, x):\n",
        "    mask = self.create_mask(x)\n",
        "\n",
        "    x = self.token_emb(x)\n",
        "    x = self.positional_enc(x)\n",
        "\n",
        "    for idx in range(self.depth):\n",
        "        x= self.layers[idx](x, mask)\n",
        "\n",
        "    return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "lBz91btCHjXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "SEQ_LEN = 256\n",
        "SEGMENTS = 5\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS\n",
        "DIM_HEAD_BERT = 768 // HEADS\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 20\n",
        "CHECKPOINT = 5"
      ],
      "metadata": {
        "id": "sF-Xk7gtKMA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tr_decoder = TransformerDecoder(\n",
        "    num_tokens = vocabulary,\n",
        "    d = SEQ_LEN,\n",
        "    depth = 10,\n",
        "    heads = HEADS,\n",
        "    hidden_size = 5000,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    use_bert = True\n",
        ").to(device)\n",
        "\n",
        "train_loader_ = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)\n",
        "test_loader_ = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False, drop_last = True)"
      ],
      "metadata": {
        "id": "GOz3oBuiGkYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "optimizer = torch.optim.Adam(tr_decoder.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epochs = 5\n",
        "# training\n",
        "\n",
        "perplexity_tr_decoder = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, data in enumerate(tqdm.tqdm(train_loader_, desc = 'training')):\n",
        "    tr_decoder.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "\n",
        "    num_seq = 10000 // (SEQ_LEN + 1)\n",
        "    data = data.long().to(device)\n",
        "    for j in range(num_seq):\n",
        "      mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "      seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "\n",
        "      out = tr_decoder(seq)\n",
        "\n",
        "      loss_item = loss(out, labels)\n",
        "      print(f'training loss: {loss_item}', flush = True)\n",
        "      loss_item.backward() \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "  data = None\n",
        "    \n",
        "\n",
        "  if e % EVAL_EVERY == 0:\n",
        "    tr_decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      metric = Perplexity().to(device)\n",
        "      for i, data in enumerate(tqdm.tqdm(test_loader_, desc = 'evaluation')):\n",
        "        num_seq = 10000 // (SEQ_LEN + 1)\n",
        "        data = data.long().to(device)\n",
        "\n",
        "        for j in range(num_seq):\n",
        "          mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "          seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "\n",
        "          out = tr_decoder(seq)\n",
        "\n",
        "          test_loss = loss(out, labels)\n",
        "          metric(out.transpose(1, 2), labels)\n",
        "          print(f'test loss: {test_loss}', flush = True)\n",
        "\n",
        "      perplexity = metric.compute()\n",
        "      perplexity_tr_decoder.append(perplexity.to(\"cpu\").item())\n",
        "      print(f'perplexity: {perplexity}', flush = True)\n",
        "\n",
        "  data = None\n",
        "  if e % CHECKPOINT == 0:\n",
        "    torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, 'model_optimizer.pt')\n",
        "    \"\"\"\n",
        "    #Lorenzo\n",
        "    with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity_moreNN.npy', 'wb') as f:\n",
        "      np.save(f, np.array(perplexity_list))\n",
        "    \"\"\"\n",
        "    with open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\n",
        "      pkl.dump(perplexity_tr_decoder, pklfile)\n",
        "\n",
        "plt.plot(perplexity_tr_decoder, label = \"Transformer Decoder Perplexity Plot\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tqKuP2z1BeFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "perplexity_tr_decoder = []\n",
        "with open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\n",
        "  perplexity_tr_decoder = pkl.load(pklfile)\n",
        "  pklfile.close()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QcYwi7zKXre0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "89d72de5-e537-4baf-ff4f-1cf5caf6b5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nperplexity_tr_decoder = []\\nwith open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\\n  perplexity_tr_decoder = pkl.load(pklfile)\\n  pklfile.close()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(perplexity_tr_decoder, label = 'Perplexity transformer decoder')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1rb7IdThijCp",
        "outputId": "adb7e5eb-6ed9-4d18-a850-d370c7554260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "zzz"
      ],
      "metadata": {
        "id": "uTPL4pa61mUs"
      }
    }
  ]
}